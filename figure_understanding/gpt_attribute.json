{
    "/data_share/data/acl_parse/figure/2005.eamt-1.38-Figure1-1.png": {
        "HUB": {
            "function": "to act as a central point of communication and integration for the various components such as the Graphic UI, Speech Recognizer, Machine Translator, Speech Synthesizer, and Audio Server.",
            "absolute_position": "in the center of the figure",
            "relative_position": "connected to all other modules displayed around it."
        },
        "Speech Recognizer": {
            "function": "to convert spoken language into text.",
            "absolute_position": "top right",
            "relative_position": "to the right of the HUB."
        },
        "calcium helps prevent osteoporosis (TextRunner : 0.68)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        },
        "Integrator": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W00-1319-Figure1-1.png": {
        "Textual database": {
            "function": "to store and provide access to text-based information for processing by other components in the system.",
            "absolute_position": "bottom center",
            "relative_position": "below the 'Standard search engine' module."
        },
        "Dense": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-0703-Figure3-1.png": {
        "Meaning#2": {
            "function": "to categorize a specific definition or group of definitions relating to the second general meaning of the word 'code'.",
            "absolute_position": "second from the top on the right.",
            "relative_position": "below \"Meaning #1\" and above \"Submit\"."
        },
        "Cellular Apoptosis": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.ltedi-1.29-Figure1-1.png": {
        "Multilingual Transformer": {
            "function": "to process and encode multilingual text data into a representation that can be used for downstream tasks such as classification.",
            "absolute_position": "center-left",
            "relative_position": "between the input 'Text' and the 'Pooled Embedding Vector'."
        },
        "Softmax Layer": {
            "function": "converting the output of the neural network into a probability distribution over predicted output classes.",
            "absolute_position": "bottom right corner of the figure",
            "relative_position": "following the Pooled Embedding Vector and preceding the Predicted Label."
        },
        "Word lists": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        },
        "Organization: organize data for easy access": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P19-1465-Figure1-1.png": {
        "Prediction": {
            "function": "",
            "absolute_position": "top-right",
            "relative_position": "following the module labeled 'Alignment'."
        },
        "Viterbi Decoding": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W07-1110-Figure2-1.png": {
        "ME Classifier": {
            "function": "to categorize semantic relations.",
            "absolute_position": "bottom center",
            "relative_position": "directly below 'Data Preprocessing' and to the left of 'Semantic Relations'."
        },
        "Physical Logical Comprression": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.828-Figure1-1.png": {
        "Position-aware Permutation": {
            "function": "to permute query features in a position-aware manner before further processing.",
            "absolute_position": "Bottom",
            "relative_position": "Below the \"Feature Map ϕ\" module and above the \"PermuteFormer\" module."
        },
        "Output (final spans)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P19-1584-Figure2-1.png": {
        "De-Identification Model": {
            "function": "to remove or obscure personal identifiers from data to protect individual privacy.",
            "absolute_position": "second row from the top, second module from the left.",
            "relative_position": "between the adversary output and the representation model, directly above the representation model."
        },
        "Token + Position Embeddings": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W13-4703-Figure1-1.png": {
        "Tagging": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "NO -> EN Transfer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L16-1114-Figure1-1.png": {
        "find anchor segments": {
            "function": "to identify stable and representative portions of speech from segmented training audio recordings for use in training or improving an acoustic model.",
            "absolute_position": "bottom right corner of the figure",
            "relative_position": "to the right of the \"anchor segments\" and below the \"restricted decoding\" and \"AM\" (acoustic model) modules within the flowchart."
        },
        "Transformer Encoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.clinicalnlp-1.28-Figure3-1.png": {
        "Bi-Directional LSTM": {
            "function": "to process sequences of data in both forward and backward directions to capture past (backward) and future (forward) information at each time step.",
            "absolute_position": "near the bottom of the figure",
            "relative_position": "between the 'Max-over-time' and 'Mean-over-time' modules and the token representation layer at the bottom of the figure."
        },
        "Combine Votes": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L18-1132-Figure1-1.png": {
        "Get all categories": {
            "function": "to retrieve the complete list of categories from the extracted title-categories list.",
            "absolute_position": "right center",
            "relative_position": "to the right of the 'Extract Title-categories list' module and to the left of the 'CKIP Parser' module."
        },
        "supermarket": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.nlptea-1.16-Figure1-1.png": {
        "Pos Tagging": {
            "function": "to assign parts of speech to each word in the text, such as nouns, verbs, adjectives, etc.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Filtered Faroese Treebank (Nor- wegian Bokmal)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W11-3311-Figure4-1.png": {
        "LCRCreationInfo [0..1]": {
            "function": "to provide information about the creation process of the Lexical-Conceptual Resource, including details on the creation mode and the tools used.",
            "absolute_position": "in the center-left part of the figure",
            "relative_position": "under \"LexicalConceptualResourceInfo\" and to the left of \"LCREncodingInfo.\""
        },
        "the whistling fisherman was always out of tuna": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.acl-main.491-Figure2-1.png": {
        "Anchor": {
            "function": "to provide a rule (in this case, the presence of the word 'occasional') that when applied to instances, has a high probability (greater than 95%) of the model predicting the label 'Negative'.",
            "absolute_position": "center right",
            "relative_position": "in the middle of the right-hand side section."
        },
        "Motion Parameters": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C98-1109-Figure6-1.png": {
        "Example-base": {
            "function": "to store structured examples (SSTCs) for use by the example-based parser.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Select instances": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C94-1079-Figure1-1.png": {
        "dynamic data statie data processing module data flow": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "OUTCOME": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W91-0207-Figure1-1.png": {
        "public": {
            "function": "",
            "absolute_position": "on the right side of the image, near the bottom corner.",
            "relative_position": "to the right of the \"PROPERTY\" module and connected to it by a line."
        },
        "BERT Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-1901-Figure1-1.png": {
        "DISCONTINUED": {
            "function": "",
            "absolute_position": "second from the left at the top row",
            "relative_position": "between \"OTHER\" and \"REASON\" modules on the top row."
        },
        "create a guest list": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-7816-Figure1-1.png": {
        "segmenter": {
            "function": "",
            "absolute_position": "bottom left.",
            "relative_position": "before 'Lefff' and 'parser' modules in the processing flow."
        },
        "MG": {
            "function": "",
            "absolute_position": "above the 'Lefff' module, between the 'segmenter' and 'parser' modules, and to the left of the 'TAG' module.",
            "relative_position": "directly connected to the 'TAG' module via an arrow pointing from 'MG' to 'TAG'."
        },
        "Acoustic Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        },
        "MBIC data (1700 sentences)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.754-Figure1-1.png": {
        "Target Context": {
            "function": "to provide the context or passage from which the Question Generation Model generates synthetic questions.",
            "absolute_position": "bottom center",
            "relative_position": "directly below the \"Question Generation Model\" module and to the left of the \"Source QA\" label."
        },
        "Tree Decoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D13-1067-Figure3-1.png": {
        "Collective Factor Graph Modeling": {
            "function": "to integrate and analyze data from profiles and social connections to contribute to sentence scoring and selection in the creation of summarized profiles.",
            "absolute_position": "center-right",
            "relative_position": "between \"Testing Set\" and \"Sentence Scoring\"."
        },
        "Clinical Recommendation B": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-main.350-Figure2-1.png": {
        "Form (lk)": {
            "function": "",
            "absolute_position": "top center",
            "relative_position": "between the \"LSTM\" module on the left and the \"Token (w_n)\" module on the right."
        },
        "rhd 1 pron die1": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/J97-4004-Figure1-1.png": {
        "a/bc/d": {
            "function": "",
            "absolute_position": "center-bottom",
            "relative_position": "in the center at the bottom row."
        },
        "live longer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C18-1075-Figure1-1.png": {
        "Generated Training Data": {
            "function": "to serve as the output of processed and classified data, which is then used to train machine learning models in the subsequent phase.",
            "absolute_position": "right center in the image",
            "relative_position": "at the end of the Training Data Generation Phase."
        },
        "User Utterance Encoder (Bi-GRU)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N10-3011-Figure1-1.png": {
        "Target Output": {
            "function": "to provide the final translated or processed result in a machine translation or similar language processing system.",
            "absolute_position": "the bottom center of the figure.",
            "relative_position": "directly below the 'Decoder' module."
        },
        "PostTest": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-main.228-Figure1-1.png": {
        "Question": {
            "function": "",
            "absolute_position": "top center",
            "relative_position": "above the 'Question Generator' module and to the left of the 'QG-Specific Rewards' module."
        },
        "Correction": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/E93-1007-Figure1-1.png": {
        "Morphological Analysis": {
            "function": "to analyze the structure of words to understand their meanings, parts of speech, and to possibly transform them into other forms or structures.",
            "absolute_position": "on the left side, in the middle",
            "relative_position": "between 'Syllabification' and 'Syntactic Analysis' modules, and directly to the left of the 'Grammars' module."
        },
        "Domain-category Analysis C": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/J86-4002-Figure13-1.png": {
        "DescrA": {
            "function": "",
            "absolute_position": "top-center of the figure.",
            "relative_position": "at the top of the diagram, connected above 'DescrB'."
        },
        "web browser (running Flash or DHTML)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W09-0208-Figure1-1.png": {
        "whirl fly provide": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "unigram": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/I08-2141-Figure1-1.png": {
        "Unicode Blocks": {
            "function": "to define segments of the Unicode standard associated with a particular language or script, indicating the beginning and end of each segment.",
            "absolute_position": "second row, second column",
            "relative_position": "top right."
        },
        "Symmetrize": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-main.166-Figure2-1.png": {
        "Personalized LM": {
            "function": "to generate personalized predictions for the next word in a sequence based on the input provided to it.",
            "absolute_position": "bottom right",
            "relative_position": "inside the dashed box, below the General LM module."
        },
        "PMI": {
            "absolute_position": "bottom right",
            "relative_position": "within the lower right quadrant of the image.",
            "function": "to provide a personalized language model (LM)."
        }
    },
    "/data_share/data/acl_parse/figure/2021.bsnlp-1.11-Figure1-1.png": {
        "Mentions linked to a list of Entities": {
            "function": "entity linking.",
            "absolute_position": "3rd from the top",
            "relative_position": "below \"Mentions with context\" and above \"Mentions converted to their base form\"."
        },
        "RAW use": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N04-1008-Figure3-1.png": {
        "Answer Extraction Algorithm": {
            "function": "to extract the relevant answer from the output provided by the Answer Generation Model.",
            "absolute_position": "at the bottom center",
            "relative_position": "between the Answer Generation Model and Answer/Question Translation Model."
        },
        "Discriminator": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W18-1505-Figure1-1.png": {
        "He got the first prize! Sam got very nervous and lost the game.": {
            "function": "",
            "absolute_position": "top right corner",
            "relative_position": "to the right of the 'Human Inputs' cylinder and above the stick figure with a sad expression."
        },
        "Output processor": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C00-1054-Figure1-1.png": {
        "ASR": {
            "function": "Automatic Speech Recognition.",
            "absolute_position": "second level from the top, first box on the left.",
            "relative_position": "below the \"UI\" box and above the \"Multimodal Parser/Understander\" box, to the left of the \"Gesture Recognizer\" box."
        },
        "Emotions Posture Gestures Facial expressions": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P18-2016-Figure2-1.png": {
        "Sentence-Level Relation Classifier": {
            "function": "to determine the relationship between entities within a sentence.",
            "absolute_position": "in the upper center of the figure, inside the red box.",
            "relative_position": "to the right of the corpus and object pairs, and to the left of the classification confidence and LocatedNear relation scores."
        },
        "Adversarial Implicit Evidence": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.semeval-1.74-Figure3-1.png": {
        "GPT-2": {
            "function": "",
            "absolute_position": "in the center on the right side of the image",
            "relative_position": "between the \"Generated Reason token by token\" text box at the top and the \"Concatenate generated token to the Generated Reason\" text box at the bottom."
        },
        "Token Classifier": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W99-0506-Figure1-1.png": {
        "HTML Templates": {
            "function": "",
            "absolute_position": "bottom right corner of the figure",
            "relative_position": "to the right of the 'Browser' module and below the 'Acquisition Tools' module."
        },
        "MLC:FrameSet": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C18-2016-Figure2-1.png": {
        "Sense Classifier": {
            "function": "to determine the meaning or context of a word (or phrase) within a given text.",
            "absolute_position": "in the center and towards the top of the image",
            "relative_position": "above the \"Tree-LSTM Unit\" and between the \"Merge Score\" and \"Center Classifier\" modules."
        },
        "Abbreviation expansion": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-main.218-Figure1-1.png": {
        "Task N": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "execute()": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W13-0904-Figure1-1.png": {
        "\"Seed\" Articles": {
            "function": "to collect initial relevant Wikipedia articles based on the mapped target concept.",
            "absolute_position": "second from the left",
            "relative_position": "in the middle."
        },
        "Tail MLP": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-5358-Figure1-1.png": {
        "hyp sent": {
            "function": "to represent the hypothetical or predicted semantic roles within a sentence.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Assembly Minutes": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D14-1148-Figure2-1.png": {
        "News documents": {
            "function": "to provide input data in the form of news documents to the neural network.",
            "absolute_position": "at the bottom center of the figure",
            "relative_position": "directly below the Input Layer."
        },
        "New Sentence (2N+1 words)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.177-Figure2-1.png": {
        "Multi-Task Learning": {
            "function": "to facilitate the learning of different but related tasks simultaneously by using shared representations.",
            "absolute_position": "on the bottom right side of the figure, within the lower third section of the image.",
            "relative_position": "within the red box marking, in the central part of the Conversational Structure Aware Graph Network section of the figure."
        },
        "Conversational (C)": {
            "absolute_position": "",
            "relative_position": "",
            "function": "multi-task learning involving a CSRL decoder, an utterance type decoder, and calculations for CSRL loss, Intra-Arg. loss, and UT loss."
        }
    },
    "/data_share/data/acl_parse/figure/W17-2409-Figure1-1.png": {
        "ama, amatya Seed=T": {
            "function": "",
            "absolute_position": "within the lower central part of the figure.",
            "relative_position": "between the \"pramukha, prāmukhya\" module on the left and the \"stu, Stutya Seed = F\" module on the right, and below the \"sodara, sodarya\" module at the top."
        },
        "Global Competency Score": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-2343-Figure1-1.png": {
        "Question classification": {
            "function": "to determine the type or category of a question that has been asked.",
            "absolute_position": "second from the left in the sequence of modules.",
            "relative_position": "immediately after the \"Question analysis\" module and before the \"Rule-based processing\" module."
        },
        "Input data": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to categorize the input question into specific types for further processing."
        }
    },
    "/data_share/data/acl_parse/figure/2020.bucc-1.7-Figure1-1.png": {
        "Exploring E2 with colores node set": {
            "function": "",
            "absolute_position": "3rd from the bottom, 2nd from the right.",
            "relative_position": "bottom right."
        },
        "Reasoning Module: individual IRNs": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/R19-1133-Figure2-1.png": {
        "straeto noun-masc sing-nom-dat -acc": {
            "function": "",
            "absolute_position": "bottom-right",
            "relative_position": "below and to the right of the 'straeto' label."
        },
        "EquityUnderweight": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-5037-Figure1-1.png": {
        "WORD LM": {
            "function": "to provide word-level language modeling for the SMT (Statistical Machine Translation) system.",
            "absolute_position": "bottom center",
            "relative_position": "between NNJM to the left and CHAR LM to the right."
        },
        "Filtering and Spelling Correction": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W06-1008-Figure1-1.png": {
        "Mining for parallel texts": {
            "function": "to identify and extract pairs of texts from English and Japanese sources that are translations of each other.",
            "absolute_position": "bottom-left",
            "relative_position": "left-most."
        },
        "Problem 2 How does the system generate appropriate clarifying questions?": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W18-6541-Figure1-1.png": {
        "Verbalization module": {
            "function": "to transform the Sub RDF Graph into natural language sentences.",
            "absolute_position": "near the center, a little right of the image's midpoint",
            "relative_position": "after the 'Sub Graph Generation' and before the 'Paraphrasing module'."
        },
        "PuBMed Text": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W15-2815-Figure1-1.png": {
        "Text": {
            "function": "",
            "absolute_position": "top-middle",
            "relative_position": "to the left of the \"Dictionary\" module and above the \"Natural Language Processing (Gloss Translate)\" module."
        },
        "Feed-Forward": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.law-1.4-Figure1-1.png": {
        "Step 2b: VerbNet States": {
            "function": "to extract VerbNet sense for each verb token, and if the verb belongs to a list of VerbNet class IDs for states, the verb is assigned STATE.",
            "absolute_position": "left side, towards the top.",
            "relative_position": "directly below the \"Non-Verbal Predication\" module (Step 2a) and to the left of the \"Habitual\" module (Step 3)."
        },
        "Spatial Attention (512)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S14-2050-Figure1-1.png": {
        "nose-picker": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Bindings": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-7810-Figure2-1.png": {
        "Stanford Constituency Parser": {
            "function": "",
            "absolute_position": "top center",
            "relative_position": "between the \"English Parallel Corpus\" and \"Chunk Harmonizer\" modules in the flowchart."
        },
        "Stop": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-long.320-Figure5-1.png": {
        "effusion.": {
            "function": "",
            "absolute_position": "On the bottom right side of the image.",
            "relative_position": "In the 'Findings' section, under the subheading 'Ours,' immediately following item 2, which is \"Possible small left pleural effusion,\"."
        },
        "Word Based (Section 4.2)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P19-1108-Figure2-1.png": {
        "Personal Health Mention Detection": {
            "function": "",
            "absolute_position": "It’s the third box from the left in the sequence of processes shown.",
            "relative_position": "It directly follows the 'Figurative Usage Detection' module and precedes the decision point where it branches into 'True' or 'False'."
        },
        "Behavioral Control": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/R13-1048-Figure1-1.png": {
        "Transform": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "the/DT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/M92-1032-Figure1-1.png": {
        "Semantic Models": {
            "function": "",
            "absolute_position": "third row in the left column",
            "relative_position": "below \"Grammar\" and above \"Concept Hier.\" and \"Mapping Rules\"."
        },
        "Lexical Analysis": {
            "function": "to process and analyze the text to convert it into tokens or meaningful symbols based on the language's syntax.",
            "absolute_position": "top right",
            "relative_position": "first in its column or sequence."
        },
        "All prepro- cessing steps": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        },
        "activation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/O06-4003-Figure16-1.png": {
        "water tank-1": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "MySQL Persistence": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/M92-1034-Figure2-1.png": {
        "Output Template": {
            "function": "",
            "absolute_position": "bottom center of the figure",
            "relative_position": "below the 'Bindings' and 'Reports' modules, within the main boxed area labeled as 'Conceptual Patterns'."
        },
        "(b)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C16-1181-Figure1-1.png": {
        "Dialogue Act": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Scientific term and predicate phrases": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.findings-acl.185-Figure4-1.png": {
        "Z1": {
            "function": "",
            "absolute_position": "in the top row, second from the left, between 'X1' and 'Y1'.",
            "relative_position": "above 'Z2' and to the left of 'Y1'."
        },
        "Parent target topic=\"vehicle\"": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N13-1098-Figure5-1.png": {
        "WOZ (2:0)": {
            "function": "",
            "absolute_position": "lower center of the image",
            "relative_position": "at the bottom of the decision tree structure."
        },
        "Semi-supervised solution": {
            "absolute_position": "bottom left",
            "relative_position": "at the bottom of the decision tree.",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.nlpcovid19-acl.6-Figure1-1.png": {
        "Finding/Contribution": {
            "function": "",
            "absolute_position": "bottom right",
            "relative_position": "below \"Method\" and to the right of \"Other\"."
        },
        "ESPER- ANTO": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2014.iwslt-evaluation.12-Figure3-1.png": {
        "DBNFs Extraction": {
            "function": "",
            "absolute_position": "on the top right side of the figure",
            "relative_position": "to the right of the \"Decoding with Baseline for SAT transform\" module and above the \"Decoding with DBNFs system\" module."
        },
        "Concept-Language Representation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/O06-2002-Figure2-1.png": {
        "Decoder": {
            "function": "",
            "absolute_position": "at the center towards the bottom of the figure",
            "relative_position": "between the \"Front-End Processing\" and the \"Recognized word sequence\" in the speech recognition system diagram."
        },
        "'ragged, broken'": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.iwslt-1.35-Figure1-1.png": {
        "OUTPUT": {
            "function": "",
            "absolute_position": "in the bottom right section of the figure, within the Google MT5 FINETUNED flowchart area.",
            "relative_position": "the last module in the sequence, after the SOFTMAX module and within the red box."
        },
        "t.ts.ting res retrea": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P10-4003-Figure2-1.png": {
        "Diagnoser": {
            "function": "",
            "absolute_position": "the center-top area of the figure",
            "relative_position": "between the Knowledge Base and the Curriculum Planner, above the Dialogue Manager."
        },
        "Feature-Based Opinion Mining": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D12-1084-Figure1-1.png": {
        "sentence-level paraphrases": {
            "function": "to generate different ways to express the same meaning at the sentence level.",
            "absolute_position": "second from the top.",
            "relative_position": "below the \"discourse information + semantic similarity\" module and above the \"word alignments + coref. resolution + dependency trees\" module."
        },
        "Classification preference values": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to provide sentence-level paraphrases from a parallel corpus with parallel discourse structures."
        }
    },
    "/data_share/data/acl_parse/figure/2021.mrl-1.10-Figure1-1.png": {
        "Candidate Synsets and corresponding Senses (Sensekeys)": {
            "function": "listing potential meanings (synsets) and their respective identifiers (sensekeys) for words needing disambiguation in multilingual text processing.",
            "absolute_position": "bottom left",
            "relative_position": "on the left side of the diagram."
        },
        "Pre-Computed Sense Embeddings": {
            "function": "to provide already calculated vector representations for different senses of words that can be used for comparison or selection tasks within a language processing system.",
            "absolute_position": "",
            "relative_position": ""
        },
        "NLG Component": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        },
        "Prototype Representation": {
            "absolute_position": "",
            "relative_position": "",
            "function": "providing pre-computed embeddings for different senses of words to be used by a cross-lingual neural language model."
        }
    },
    "/data_share/data/acl_parse/figure/2020.lrec-1.875-Figure10-1.png": {
        "CHJ": {
            "function": "",
            "absolute_position": "top-left",
            "relative_position": "above and to the left of the cylindrical modules marked with historical periods."
        },
        "Shared stacked self-attention module": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.nlp4convai-1.11-Figure2-1.png": {
        "Skill Catalog": {
            "function": "to provide a list of available skills for consideration by the Shortlister in a skill recommender system.",
            "absolute_position": "bottom left corner",
            "relative_position": "below the 'ASR' module."
        },
        "Create verb Frame": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W16-1622-Figure3-1.png": {
        "know": {
            "function": "",
            "absolute_position": "left-middle side of the figure",
            "relative_position": "between \"forget\" and \"ABOUT\", directly under \"forget\"."
        },
        "QE Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.acl-main.307-Figure1-1.png": {
        "Shared Classifier": {
            "function": "to classify market status based on weighted average features from multiple stocks, which is shared across different time steps/indexes rather than using separate classifiers for each.",
            "absolute_position": "on the right side of figure part (b).",
            "relative_position": "in the upper right quadrant of figure part (b)."
        },
        "mamifero": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W15-2704-Figure1-1.png": {
        "Prosodics at Verse Line Level Based on Mean Durations in msecs": {
            "function": "to analyze the rhythm and phonetic characteristics of poetry by measuring the average length of sounds or syllables at the level of verse lines.",
            "absolute_position": "bottom-center",
            "relative_position": "below 'Rhythming Structure and Metrical Structure of the Poem' and to the left of 'Dependency-based Predicate-Argument Representation of Text'."
        },
        "County-Specific Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W14-5504-Figure1-1.png": {
        "Stem-Suffix Pruner": {
            "function": "to refine the candidate stem-suffix list by removing incorrect or unlikely combinations.",
            "absolute_position": "in the lower left quadrant of the figure, centered horizontally within that quadrant.",
            "relative_position": "below the \"Candidate Stem-Suffix List\" and above the \"Stem-Suffix List\", mainly in the center of those two elements vertically."
        },
        "Criteres": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to refine the candidate stem-suffix list by pruning inappropriate combinations."
        }
    },
    "/data_share/data/acl_parse/figure/L16-1039-Figure1-1.png": {
        "Adaptation": {
            "function": "to modify the system based on feedback from the user to improve future inputs and outputs.",
            "absolute_position": "in the bottom middle of the figure",
            "relative_position": "below the \"System\" block labeled with subscript \"π_i\" and above the \"System\" block labeled with subscript \"π_n\"."
        },
        "TwitIE IE modules": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W16-4211-Figure3-1.png": {
        "<Posemo><=0.0025 n=9 AD:8 HC: 1": {
            "function": "",
            "absolute_position": "bottom right corner of the figure",
            "relative_position": "on the right side, at the lower end of the decision tree."
        },
        "Encoder Core (e.g.CNN, LSTM Transformer)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2007.jeptalnrecital-recital.4-Figure1-1.png": {
        "Ensemble de paraphrases": {
            "function": "to generate a set of paraphrases.",
            "absolute_position": "the bottom center of the figure.",
            "relative_position": "below the cylindrical database and to the left of the \"Forme logique\" module."
        },
        "Video Feature Extractor": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S16-1127-Figure1-1.png": {
        "WIKI": {
            "function": "",
            "absolute_position": "in the center left of the figure",
            "relative_position": "between the \"Query Question\" and \"Weighted Sum\" modules, to the left of the \"TF-IDF\" module."
        },
        "LANGUAGE UNDERSTANDING": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.bea-1.6-Figure1-1.png": {
        "Production of corruption rules": {
            "function": "the creation of guidelines or algorithms to artificially introduce errors into data based on previously studied error patterns.",
            "absolute_position": "3rd from the left",
            "relative_position": "after 'Study of error patterns' and before 'Generation of FakeDaLAJ'."
        },
        "Contrast classifier": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-1595-Figure1-1.png": {
        "Pre Trained Word Embeddings": {
            "function": "to provide a set of fixed word representation vectors that have been learned in advance from a large corpus of text.",
            "absolute_position": "top right quadrant of the image",
            "relative_position": "in the right half of the figure, towards the top and center relative to other elements in that half."
        },
        "identifying words in context, consulting elders, clarifying meanings": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C98-2161-Figure1-1.png": {
        "Possessive Relationships KS": {
            "function": "",
            "absolute_position": "centered at the bottom of the image",
            "relative_position": "between the \"Surface Patterns KS\" and \"Sentence Center KS\" modules."
        },
        "Input speech frames": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P11-2059-Figure1-1.png": {
        "SVM": {
            "function": "to perform classification tasks using the Support Vector Machine algorithm.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Personalized learning": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W01-1813-Figure2-1.png": {
        "Get new rules": {
            "function": "to acquire new rules for the system or process being described in the flowchart.",
            "absolute_position": "bottom center",
            "relative_position": "below 'Learner' and to the left of 'Get none of new rules'."
        },
        "General definition": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W13-3006-Figure6-1.png": {
        "Right Subsequential x RH": {
            "function": "",
            "absolute_position": "inside the \"Regular\" and \"Weakly deterministic\" classifications",
            "relative_position": "between the \"Left Subsequential\" classification and the \"?\" marking on the right, more specifically within the \"Subsequential\" classification."
        },
        "Reference policy": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-main.452-Figure2-1.png": {
        "Reinforcement Learning": {
            "function": "to evaluate and provide feedback on the performance of the model to guide the learning process through reinforcement signals.",
            "absolute_position": "top-right corner",
            "relative_position": "adjacent to the Decoder module on the right side."
        },
        "Synthesiser": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-4914-Figure2-1.png": {
        "Corpus": {
            "function": "to provide the dataset used for training the machine learning models represented by the classifiers in the diagram.",
            "absolute_position": "top center",
            "relative_position": "above all other modules."
        },
        "Siamese Network": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S19-2054-Figure2-1.png": {
        "Multi-dimensional Attention Max Pooling": {
            "function": "to aggregate information by focusing on the most relevant parts of the data representation and combining them to form a fixed-size output irrespective of the input size.",
            "absolute_position": "the top center of the figure",
            "relative_position": "above the \"Concatenate\" layer and at the top of the architecture, connecting to both Bi-LSTM branches."
        },
        "LC MW Representation RC": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/U09-1007-Figure10-1.png": {
        "LEXC": {
            "function": "",
            "absolute_position": "top right",
            "relative_position": "outside the main flowchart, to the right of the \"Stem Lexicon Declaration\" module."
        },
        "Average": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W15-3118-Figure3-1.png": {
        "resource control proxy/account": {
            "function": "",
            "absolute_position": "on the bottom right of the diagram",
            "relative_position": "directly under the 'duplicate removal' module and to the right of the 'crawler controller /entrance' module."
        },
        "Search services, e.g. Inktomi, Lycos, Yahoo": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P03-2018-Figure1-1.png": {
        "Wordnet": {
            "function": "to provide lexical information, such as word meanings and relationships, which can be used in the process of natural language understanding and generation.",
            "absolute_position": "top-center",
            "relative_position": "between \"Link lambda DRS defs\" and \"SL lexicon\" modules, and above \"HPSG sem Generation.\""
        },
        "INITIAL STATE": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/E89-1036-Figure1-1.png": {
        "analysis extraction of IFTs": {
            "function": "",
            "absolute_position": "left-center",
            "relative_position": "first from the left."
        },
        "Translation Memory Service": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/E17-2110-Figure1-1.png": {
        "concatanate": {
            "function": "to combine the outputs of the bidirectional LSTM layers for character embeddings before passing the result to another module or layer in the network.",
            "absolute_position": "in the lower center of the figure, within the third diagram from the top.",
            "relative_position": "within the bi-LSTM section, just above the character embeddings, horizontally centered."
        },
        "Input (Comment/Post)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.wmt-1.127-Figure2-1.png": {
        "Model State Temp. Model Real Dataset Synth. Dataset": {
            "function": "to store the temporary model state, real dataset, and synthetic dataset.",
            "absolute_position": "bottom left",
            "relative_position": "left of Model 3."
        },
        "espouse": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C86-1020-Figure1-1.png": {
        "lexicographer interface": {
            "function": "Unknown.",
            "absolute_position": "in the lower-central part of the figure",
            "relative_position": "below the \"DML-compiler\" and to the right of the \"data/internal schema/LDB\" block, connected via lines indicating a relationship or data flow."
        },
        "Reranking": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.naacl-industry.28-Figure1-1.png": {
        "Topic Constraint Model": {
            "function": "",
            "absolute_position": "top center",
            "relative_position": "above the BERT modules and the Media Categories Classifier."
        },
        "Candidate Generator": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P19-1556-Figure1-1.png": {
        "Aggregation Layer (unshared) Identity Transform F C Layer (unshared)": {
            "function": "to aggregate features and perform identity transformation before passing them to a fully connected layer, with elements specific to certain domains in a neural network architecture.",
            "absolute_position": "on the right side of the figure, second block from the top.",
            "relative_position": "in the bottom half of subfigure (b)."
        },
        "Sentence-Level Prediction": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/E06-1016-Figure2-1.png": {
        "TARGET TEXT": {
            "function": "",
            "absolute_position": "on the left side of the figure",
            "relative_position": "to the left of the diamond-shaped module labeled \"D\" and below the module labeled \"PUBLISHED THESAURUS\"."
        },
        "Animacy": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/E06-2019-Figure1-1.png": {
        "PartsSEM/TM": {
            "function": "",
            "absolute_position": "in the lower central part of the figure, directly above the \"SVM Classifier\" block.",
            "relative_position": "between the \"Domain-Specific Knowledge\" repository and the \"SVM Classifier\" block, receiving input from the \"Multiple Parts\" and \"Domain-Specific Knowledge\" components."
        },
        "Feature Vector": {
            "absolute_position": "",
            "relative_position": "",
            "function": "unknown."
        }
    },
    "/data_share/data/acl_parse/figure/P10-4011-Figure3-1.png": {
        "Dynamic/Static Classification": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Postprocessing": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D17-1317-Figure2-1.png": {
        "Propaganda": {
            "function": "",
            "absolute_position": "in the lower half, slightly left of the center of the figure.",
            "relative_position": "between \"Hoax\" and \"Satire\" along the 'Intention of Author' axis and towards the 'Fake' end of the 'Information Quality' axis."
        },
        "ASR": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D18-1125-Figure2-1.png": {
        "Shared CNN encoder": {
            "function": "to extract genre-shared features from both the source and target inputs for classification and reconstruction purposes in a deep learning model.",
            "absolute_position": "in the center of the image",
            "relative_position": "between the 'Word Embedding' and 'Deconvolution' modules, at the intersection of the 'Source' and 'Target' pathways."
        },
        "Code Convert (Unicode)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W18-6405-Figure1-1.png": {
        "Moses SMT": {
            "function": "to serve as a statistical machine translation engine that uses a translation model and a language model to generate translations.",
            "absolute_position": "in the center-right of the image",
            "relative_position": "between the 'Training Data' and the 'Translations' modules, connected to the 'Decoding' module."
        },
        "Dravidian code-mixed and script-mixed Posts": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/E85-1030-FigureI-1.png": {
        "Fixed price": {
            "function": "",
            "absolute_position": "bottom-right side of the figure",
            "relative_position": "directly below the \"Price\" module and to the right of the \"Sales price\" module within the concept diagram."
        },
        "Out-of- Domain Terms": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/J18-2002-Figure3-1.png": {
        "CollectiveMultiClassifier": {
            "function": "to integrate multiple sources of information or features (denoted as \\(f_i\\) and \\(f_j\\)) to enhance the accuracy of the final prediction using Markov Logic Networks (MLNs).",
            "absolute_position": "at the bottom center.",
            "relative_position": "below all the other decision modules and directly feeding into the 'Prediction' module at the top center."
        },
        "Forwards": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W04-2312-Figure1-1.png": {
        "TnT": {
            "function": "",
            "absolute_position": "top right",
            "relative_position": "above and to the right of the other modules."
        },
        "GB": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W16-3512-Figure1-1.png": {
        "Location-relevant Information Filter": {
            "function": "to filter incoming live traffic incident data to ensure only location-relevant information is passed on to subsequent modules for processing.",
            "absolute_position": "top center",
            "relative_position": "between \"Live Traffic Incident Data\" and \"Generation Model (Data2Text)\", above \"Generation Model (Data2Text)\"."
        },
        "High-performance computing (HPC) Cluster": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N18-1203-Figure3-1.png": {
        "Discourse State hI2": {
            "function": "representing the accumulated context or state from previous turns in a discourse, or conversation, to inform the current response.",
            "absolute_position": "top-center",
            "relative_position": "to the right of the \"Encoder State h3\" and above the \"Attention State c3\" within the flow diagram."
        },
        "Higher process Multimodal hub": {
            "absolute_position": "",
            "relative_position": "",
            "function": "unknown."
        }
    },
    "/data_share/data/acl_parse/figure/W12-4213-Figure4-1.png": {
        "Decoding": {
            "function": "to translate the input Japanese sentences into English by converting the encoded information back into readable text using the trained translation and language models.",
            "absolute_position": "near the bottom center of the figure",
            "relative_position": "below the 'Decoder (Moses)' module and above the 'Evaluation' module."
        },
        "View Processor": {
            "absolute_position": "",
            "relative_position": "",
            "function": "decoding the input sentences using the translation and language models to produce completed sentences."
        }
    },
    "/data_share/data/acl_parse/figure/2022.findings-naacl.80-Figure4-1.png": {
        "PL": {
            "function": "to perform a summation of all the elements in the input sequence 'x'.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Target Classifier": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P99-1028-Figure1-1.png": {
        "Chinese Restriction": {
            "function": "",
            "absolute_position": "on the left side, towards the bottom of the image.",
            "relative_position": "within the lower third of the image, aligned to the left, below the \"A Model\" section and above the \"U Model\" section."
        },
        "negaram": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D14-1007-Figure1-1.png": {
        "Domain Expert (Movie Search)": {
            "function": "to handle queries and provide information related to movie searches.",
            "absolute_position": "center-right in the figure",
            "relative_position": "in the bottom row of the domain experts, second from the left."
        },
        "Pooling": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-4221-Figure3-1.png": {
        "Frequencies in Wikipedia corpus": {
            "function": "to determine the frequency of word splits found in the Wikipedia corpus.",
            "absolute_position": "in the lower center section",
            "relative_position": "between the \"Check for subanalyses\" and \"Contextual search in Wikipedia corpus\" modules."
        },
        "Head direction estimation": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to provide frequency data of word components from the Wikipedia corpus for further analysis in the word splitting process."
        }
    },
    "/data_share/data/acl_parse/figure/I05-1061-Figure1-1.png": {
        "Day [1...31]": {
            "function": "to represent the individual days within a month.",
            "absolute_position": "in the center, slightly to the left on the lower half of the figure.",
            "relative_position": "directly below the 'Month [1...12]' module and at the same level as 'Week [1...53]' but to the left of it within the 'Macro Units' cluster."
        },
        "Bi-GRU": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.eacl-main.320-Figure3-1.png": {
        "ASR System": {
            "function": "automatic speech recognition.",
            "absolute_position": "in the lower right corner of the figure",
            "relative_position": "below the \"BERT-Large\" module and to the right of the \"Speech Subnetwork\" and \"Feed Forward Subnetwork.\""
        },
        "PR (+)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2011.eamt-1.31-Figure1-1.png": {
        "Statistical Word Alignment": {
            "function": "to align words from parallel documents statistically for the purpose of machine translation or similar language processing tasks.",
            "absolute_position": "top right",
            "relative_position": "after the 'Creation of RBMT Trees' module and before the 'Initial Term Pairs' module."
        },
        "CALIMA Output": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.bionlp-1.20-Figure2-1.png": {
        "Entity Embeddings": {
            "function": "to provide vector representations of entities that can be used for tasks such as entity linking within the model.",
            "absolute_position": "on the bottom right within the figure.",
            "relative_position": "below and to the right of the 'Transformers' modules and to the right of the 'Entity Linking' process."
        },
        "Example Device": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W12-2705-Figure1-1.png": {
        "LM adaptation": {
            "function": "to adapt a language model (LM) to a specific domain or task using a background corpus and other processed linguistic information.",
            "absolute_position": "bottom center",
            "relative_position": "below \"Morpheme adaptation\" and above \"Adapted LM\"."
        },
        "where Ginzburg": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-4121-Figure1-1.png": {
        "Selection Engine": {
            "function": "to pick up some instances from the raw corpus for manual annotation.",
            "absolute_position": "third from the top",
            "relative_position": "between 'Required Input Format' and 'Manual Annotation'."
        },
        "Global consensus: 50%": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/K17-3007-Figure3-1.png": {
        "Gate": {
            "function": "",
            "absolute_position": "the lower central part of the image",
            "relative_position": "after the two vertical blue modules (representing Domain 2) and before the red module within the oval that encapsulates Domain 1 and Domain 2."
        },
        "after one week": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-2310-Figure4-1.png": {
        "S_193_kansas_city_missouri_Z": {
            "function": "",
            "absolute_position": "second from the left in the bottom row",
            "relative_position": "directly to the right of the 'S_193_kansas_N' module."
        },
        "static": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.semeval-1.263-Figure2-1.png": {
        "Preprocessing": {
            "function": "to prepare and clean the selected training data for model building.",
            "absolute_position": "the second from the left in the bottom row of the flowchart",
            "relative_position": "directly below the 'Preprocessing' module in the top row."
        },
        "Dependency": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to prepare both testing and training data for subsequent analysis steps in the model building process."
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-acl.139-Figure1-1.png": {
        "The Super Supreme pizza at Pizza Hut is very popular with the customers.": {
            "function": "to provide an example of customer feedback or a popular menu item in an unstructured document base related to Pizza Hut.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Logical Structure 1": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-4107-Figure1-1.png": {
        "Template Module": {
            "function": "",
            "absolute_position": "third from the top, first from the left.",
            "relative_position": "below \"Word Segment\", to the left of \"Translate Module\"."
        },
        "[CLS]": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-5059-Figure2-1.png": {
        "Obtain a score for each answer and rank": {
            "function": "to evaluate and sort answers based on their relevance or correctness.",
            "absolute_position": "3rd",
            "relative_position": "Middle."
        },
        "Newsleak index elastic": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to obtain a score for each answer and rank them."
        }
    },
    "/data_share/data/acl_parse/figure/W13-4601-Figure3-1.png": {
        "Text Normalization Module": {
            "function": "to convert different textual representations into a standard, normalized form.",
            "absolute_position": "It's the second module in the vertical flow of processing modules immediately following the \"input.\"",
            "relative_position": "It's directly after the input and before the \"Character Analysis Module\" and \"External Named Entity Annotation Module.\""
        },
        "Enc": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.emnlp-main.530-Figure1-1.png": {
        "DEFINITIONAL What constitutes \"livability\"?": {
            "function": "to define the term \"livability\" within the context of the diagram.",
            "absolute_position": "bottom left",
            "relative_position": "second from the left."
        },
        "Clause- Level": {
            "absolute_position": "bottom-center",
            "relative_position": "below the main text block.",
            "function": "to identify the definitional relationship between a clause and a question, in this case asking for the definition of a term within the clause."
        }
    },
    "/data_share/data/acl_parse/figure/W14-7012-Figure2-1.png": {
        "Alignment": {
            "function": "to align corresponding elements between parsed segments of a parallel corpus to be used in translation memory for machine translation.",
            "absolute_position": "on the top-right section of the figure.",
            "relative_position": "after the 'Parser' module and before 'Translation Memory' module, connected by arrows indicating the flow of the process."
        },
        "Pooling": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-acl.121-Figure1-1.png": {
        "Language Model": {
            "function": "to process and encode multi-task learning or pre-train tasks in a sequence-to-sequence framework.",
            "absolute_position": "top right corner of the Multi-Task Learning diagram (a).",
            "relative_position": "last in the series of TRM blocks, just before the output arrows indicating \"Pre-train task1\" and \"Pre-train task2.\""
        },
        "What will the [WWEATHER_TYPE] be [TIME_DATE]?": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P19-1364-Figure1-1.png": {
        "Scheduler": {
            "function": "to allocate resources or manage the timing of tasks within the system, given its contextual placement between 'Budget' and other modules.",
            "absolute_position": "in the upper center of the figure, inside the 'Direct Reinforcement Learning' area.",
            "relative_position": "to the right of the 'Budget' module and above the 'Controller' module."
        },
        "Human Conversational Data": {
            "function": "to collect data from interactions between the dialogue agent and the user for use in learning and improving the system.",
            "absolute_position": "top right",
            "relative_position": "to the right of the \"Scheduler\" and above the \"User.\""
        },
        "RE rules with confidence values": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        },
        "Sentence": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C10-2040-Figure2-1.png": {
        "Tagged Corpus for Chunker": {
            "function": "to provide annotated data for training the chunker.",
            "absolute_position": "top right corner of the figure.",
            "relative_position": "to the right of the CRF-based sequence labeler and above the Suffix information module."
        },
        "BiLSTM": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W02-1406-Figure5-1.png": {
        "News": {
            "function": "to provide data for the news annotation process.",
            "absolute_position": "upper-right",
            "relative_position": "above the \"Parameter Estimation\" module and to the right of the \"Seed Names\" module."
        },
        "Token biRNN": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.214-Figure2-1.png": {
        "ACE 2005 EE": {
            "function": "to provide a dataset for event extraction tasks.",
            "absolute_position": "top center",
            "relative_position": "centered above the \"A Unified Training Framework In the MRC Formulation\" text box, within a list of other modules."
        },
        "TWO RESOLUTION ENGINES": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N16-1083-Figure1-1.png": {
        "SP/DP": {
            "function": "",
            "absolute_position": "It is in the bottom center in both the left and right diagrams within the figure.",
            "relative_position": "It is directly below the Wi modules and between Wn and Wn+2 in both the left and right diagrams within the figure."
        },
        "Question-worthy Content Selection": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.jeptalnrecital-recital.4-Figure3-1.png": {
        "WikiSQL": {
            "function": "to provide a dataset for fine-tuning the TAPAS model for English language tasks.",
            "absolute_position": "bottom-right",
            "relative_position": "to the right of the \"Fine Tuning\" diamond and below the \"Modèle témoin (anglophone)\" box."
        },
        "Precision&Recall": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-1164-Figure1-1.png": {
        "Sum & Linear": {
            "function": "",
            "absolute_position": "on the bottom right quadrant of the image",
            "relative_position": "between the \"Multi-Head Attention\" and \"Feed Forward\" blocks within the Transformer model architecture, to the right side of the overall diagram."
        },
        "semantic frame": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-main.469-Figure1-1.png": {
        "2004 United States Grand Prix": {
            "function": "to be an intermediary entity that connects the table-to-text operator and the question generation operator in the diagram, exemplifying a fact extracted from the table to be used in question generation.",
            "absolute_position": "Top-left",
            "relative_position": "Above the Table-to-Text Operator box and to the left of the Question Generation Operator box."
        },
        "kkh:(98,99)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/1991.mtsummit-papers.18-Figure1-1.png": {
        "LPNN SPEECH SYSTEM": {
            "function": "to process English utterances and interface with both connectionist and LR parsers in this speech system diagram.",
            "absolute_position": "top right corner of the diagram.",
            "relative_position": "above the \"LR PARSER.\""
        },
        "Convolutional layer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/I17-1092-Figure1-1.png": {
        "Knowledge Integration Knowledge Base": {
            "function": "to store and provide access to structured information that can be used by other components for language generation and dialogue management.",
            "absolute_position": "",
            "relative_position": ""
        },
        "REF SVM": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y15-1044-Figure2-1.png": {
        "Syntactic arguments": {
            "function": "",
            "absolute_position": "bottom-right",
            "relative_position": "below \"Grammars of syntactic behaviors\" and to the right of \"Contexts by syntactic behavior.\""
        },
        "Personal Info": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/J18-1003-Figure1-1.png": {
        "Dominance Graph": {
            "function": "",
            "absolute_position": "top-center",
            "relative_position": "above the \"Hypernet\" and to the left of the \"Underspecification Graph.\""
        },
        "Reparameterization Trick": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W04-3005-Figure1-1.png": {
        "Phone Strings 5": {
            "function": "",
            "absolute_position": "the bottom right of the figure",
            "relative_position": "directly below 'Phone n-gram model 5'."
        },
        "Need to prepare in advance.": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W09-1325-Figure1-1.png": {
        "Browser": {
            "function": "to provide a page for paper upload and links to uploaded papers, display the paper in dynamic HTML, and enable JavaScript-based annotation with CISP.",
            "absolute_position": "the center-left side of the figure",
            "relative_position": "between the \"User Input\" area on the left and the \"Server\" area on the right."
        },
        "DebiasBERT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.sigmorphon-1.28-Figure1-1.png": {
        "Encoder-Decoder": {
            "function": "",
            "absolute_position": "in the center of the figure",
            "relative_position": "between the top row of nodes/circles and the bottom row of nodes/circles."
        },
        "Text crawler Chosen Users": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.acl-main.229-Figure7-1.png": {
        "Text Attention": {
            "function": "to focus on specific parts of the input text that are relevant to the current context or task.",
            "absolute_position": "near the center of the image, slightly to the upper right",
            "relative_position": "in the 'BabyWalk Policy' section, between the LSTM and Vision Attention modules."
        },
        "Question Rewriting": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L18-1374-Figure5-1.png": {
        "Dataset": {
            "function": "to serve as a centralized collection of data that is related to sign language, dialects, languages, glosses, translations, keywords, videos, and definitions, providing a structured resource for the associated system or application.",
            "absolute_position": "top-center",
            "relative_position": "above all other modules."
        },
        "has-property": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W91-0116-Figure8-1.png": {
        "Precond 1=T": {
            "function": "to indicate that a specific precondition (Precondition 1) has been met or is true ('T').",
            "absolute_position": "lower center part of the figure, within the \"One Precondition holds true\" module.",
            "relative_position": "it is within the green rectangle beneath the \"Rule Activation\" module and to the left of the \"Precond m = T\" module."
        },
        "Action": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.paclic-1.6-Figure2-1.png": {
        "Feature extraction for attention": {
            "function": "to extract relevant features from the input data that are necessary for the subsequent attention mechanism in the neural network.",
            "absolute_position": "top-left corner",
            "relative_position": "first in the processing sequence."
        },
        "Initial class": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to provide feature extraction for attention mechanisms in a neural network."
        }
    },
    "/data_share/data/acl_parse/figure/D16-1121-Figure2-1.png": {
        "hd Sentiment": {
            "function": "sentiment analysis of opinion tweets identified by the hd Opinion Detector.",
            "absolute_position": "second from the bottom, first from the left.",
            "relative_position": "below the \"hd Opinion Detector\" and to the left of \"er Sentiment\"."
        },
        "Semantic Class Induction": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-main.341-Figure2-1.png": {
        "DP-GCN": {
            "function": "to process the input features using Graph Convolutional Networks (GCN) on both dependency and semantic graphs, and to integrate this information, possibly with a selection and rethinking mechanism, to provide enhanced feature representation for the next module.",
            "absolute_position": "It is the central component in the figure, located after the \"Contextual Encoder\" and before the \"Pooling\" modules.",
            "relative_position": "It is immediately to the right of the \"Contextual Encoder\" and to the left of the \"Pooling\" stage, in the central part of the flow diagram, serving as the intermediary processing step."
        },
        "Adaplive Word Lattice Search Algorithm": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.517-Figure2-1.png": {
        "Knowledge Base": {
            "function": "to provide relevant factual information or context relevant to the query for processing by other system components.",
            "absolute_position": "top-middle",
            "relative_position": "left of the Visual Retriever."
        },
        "SYNTACTIC ANALYZER": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-3021-Figure1-1.png": {
        "CRF classification": {
            "function": "to perform classification based on a Conditional Random Field model.",
            "absolute_position": "in the lower left quadrant of the figure.",
            "relative_position": "below the \"CRF model\" and to the left of the \"OR merger\"."
        },
        "Word Embedding Training": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-3306-Figure2-1.png": {
        "System": {
            "function": "",
            "absolute_position": "at the bottom center of the figure.",
            "relative_position": "directly below the 'spacecraft' module."
        },
        "SSUs": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W14-3401-Figure2-1.png": {
        "GenBank Record: Sufficiency Criteria": {
            "function": "",
            "absolute_position": "top-center",
            "relative_position": "above all other modules."
        },
        "Hate <form>=/hate/": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P91-1024-Figure3-1.png": {
        "(3) Generation": {
            "function": "to produce output based on the input received from the previous modules, often involving a creative or synthesis process.",
            "absolute_position": "the bottom right of the diagram.",
            "relative_position": "below the \"(2) Example-Based Transfer\" module and to the right of the \"Thesaurus\" module."
        },
        "Searching": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W04-3009-Figure5-1.png": {
        "Language Model": {
            "function": "",
            "absolute_position": "bottom-left corner of the figure",
            "relative_position": "below the \"Channel Model\" and to the left of the \"Decoding\" module."
        },
        "Veracity Prediction Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-demos.12-Figure2-1.png": {
        "NER + NEL MODEL": {
            "function": "to perform Named Entity Recognition (NER) and Named Entity Linking (NEL).",
            "absolute_position": "bottom right corner of the figure",
            "relative_position": "next to the bottom edge and to the right of the main workflow diagram."
        },
        "Content and Rhetorical Status Selection Systems": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D13-1096-Figure5-1.png": {
        "Matching Feature Extraction": {
            "function": "to extract relevant features from the input text and potential response candidates to be used for matching in the ranking model.",
            "absolute_position": "in the center of the figure, one-third from the left side.",
            "relative_position": "directly after the \"Pre-processing\" module and before the \"Ranking Model\" module in the depicted workflow."
        },
        "Target-Frame MATRIX": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N16-1077-Figure1-1.png": {
        "inflection generation": {
            "function": "to generate the correct inflected form of a word based on provided grammatical information such as case and number.",
            "absolute_position": "centered",
            "relative_position": "in the middle of the figure."
        },
        "Kept as templates": {
            "absolute_position": "",
            "relative_position": "",
            "function": "inflection generation."
        }
    },
    "/data_share/data/acl_parse/figure/W01-1303-Figure3-1.png": {
        "spatial change": {
            "function": "to conceptualize the change of location or position in space.",
            "absolute_position": "on the right side of the figure and it's one of the second-level modules coming from the top right 'invariant: crossing the boundary' module.",
            "relative_position": "directly above the 'crossing the locus: (19)' module and to the left of the 'object change' module."
        },
        "Tracking tool for customers": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P07-2050-Figure1-1.png": {
        "Pivot- Destination Dictionary": {
            "function": "",
            "absolute_position": "center-right",
            "relative_position": "right-middle."
        },
        "Seed Dictionary": {
            "function": "Unknown.",
            "absolute_position": "third from the left and second from the top",
            "relative_position": "center-right."
        },
        "Block identifica-tion": {
            "absolute_position": "center",
            "relative_position": "in the middle of the diagram.",
            "function": ""
        },
        "Parser": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W00-1409-Figure1-1.png": {
        "Dialog act-based Translator": {
            "function": "to translate dialogue based on the classification of speech acts, which are functional units in communication.",
            "absolute_position": "in the lower center of the figure",
            "relative_position": "between the \"Selection\" and \"Case-based Translator\" modules, and below the \"Parser\" module."
        },
        "Are you confident with your answer?": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.acl-demo.18-Figure1-1.png": {
        "Model analysis": {
            "function": "to determine if the generated summary is abstract, factually consistent.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Conditions that aren't strictly hereditary have environmental causes.": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W14-4726-Figure1-1.png": {
        "alligator crocodile cayman": {
            "function": "to provide a semantic field that relates to the concept 'reptile' by listing related terms such as 'alligator,' 'crocodile,' and 'cayman.'",
            "absolute_position": "A1",
            "relative_position": "in the top-middle of the figure."
        },
        "Pre-process": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-1431-Figure2-1.png": {
        "RTr": {
            "function": "",
            "absolute_position": "top center of the figure",
            "relative_position": "right of the Relation-Meta Learner module, above the Query Step label, and to the left of the dashed line connecting to the Embedding Learner module."
        },
        "Hierarchical Co-Attention Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P10-1149-Figure2-1.png": {
        "Bob Dylan": {
            "function": "to represent an entity associated with the \"film_music_contributor-name\" and \"has_attribute:albums\" relationships in the diagram.",
            "absolute_position": "at the bottom center of figure (b).",
            "relative_position": "directly below the 'Johnny Cash' module and to the left of the 'has_attribute:albums' module in figure (b)."
        },
        "PBMT- Unsupervised -wordOrder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2019.rocling-1.22-Figure3.1-1.png": {
        "TLF": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Encoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/1992.tmi-1.20-Figure2-1.png": {
        "Input Text": {
            "function": "to provide the initial data or text that will be processed by the system, starting with the Parser module.",
            "absolute_position": "the top-left corner of the diagram",
            "relative_position": "the first module in the process flow of the Source Language Analysis."
        },
        "Language Generation": {
            "absolute_position": "Bottom center of the image, as part of the 'Target Language Generation' section",
            "relative_position": "After the 'f-structure' and before the 'MAPPER' module within the 'Target Language Generation' section.",
            "function": "to create the surface text from an intermediate representation during the target language generation process."
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-demo.8-Figure3-1.png": {
        "Pooling": {
            "function": "to aggregate the features extracted by the Pre-Trained Transformer (BERT) to form a fixed-size pair representation.",
            "absolute_position": "left-middle in the figure",
            "relative_position": "below 'Pair representation' and above the 'Pre-Trained Transformer (BERT)'."
        },
        "Train, dev, test": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/R13-2008-Figure1-1.png": {
        "VSM Comparison fingerprint-based comparison": {
            "function": "to compare decomposed documents using a vector space model (VSM) approach and fingerprint-based techniques to identify similarities or matches.",
            "absolute_position": "in the middle on the right side of the diagram",
            "relative_position": "after the 'decomposition' process and before the 'knowledge-based post-processing'."
        },
        "listener": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2010.jeptalnrecital-court.36-Figure1-1.png": {
        "Prepare Clean Input": {
            "function": "to prepare and clean the input data for further processing.",
            "absolute_position": "Top-center",
            "relative_position": "The first module after the 'Input'."
        },
        "Stability Analysis": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.semeval-1.204-Figure1-1.png": {
        "candidates generation": {
            "function": "to generate candidate entities or phrases from various sources such as neural models, templates, and Wikipedia lexicon.",
            "absolute_position": "bottom center",
            "relative_position": "inside the feature extractor block, among three sub-modules on the bottom row, positioned on the right."
        },
        "Intra-cell": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.econlp-1.3-Figure2-1.png": {
        "Independent Review": {
            "function": "to provide an impartial assessment of the content or decisions made by the other components in the system.",
            "absolute_position": "on the left side of the figure, between the \"Filtering Standards and FAQs\" and \"Question classification\" modules.",
            "relative_position": "below the \"Filtering Standards and FAQs\" and above the \"Question classification\" modules."
        },
        "Correction": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.183-Figure1-1.png": {
        "I am very well, thank you. How are you today?": {
            "function": "to provide a polite response to a greeting and inquire about the well-being of the other person.",
            "absolute_position": "second from the top",
            "relative_position": "first on the right."
        },
        "tf-idf approach": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P09-2005-Figure1-1.png": {
        "Evaluator": {
            "function": "to assess the performance or outcome of a dialog system based on the dialog logs and produce evaluation results.",
            "absolute_position": "at the bottom center of the figure",
            "relative_position": "below the \"Dialog Logs\" module and to the left of the \"Evaluation Results\" module."
        },
        "Action Encoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L16-1422-Figure1-1.png": {
        "Sentence Raw Sentence Parsed Sentence": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "2 3 4 5": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to provide the raw sentence and its parsed structure."
        }
    },
    "/data_share/data/acl_parse/figure/K15-1008-Figure1-1.png": {
        "unlabeled parallel sentences": {
            "function": "",
            "absolute_position": "centered about one-third from the top of the figure",
            "relative_position": "in the middle of the flowchart, between \"projected dependency arcs\" and \"statistics collection\" as well as \"unlabeled target sentences.\""
        },
        "person": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N10-1100-Figure1-1.png": {
        "Ted Kennedy 4": {
            "function": "",
            "absolute_position": "sixth from the left, first row.",
            "relative_position": "between \"tragedy\" and \"died\"."
        },
        "[Lakers]{LOC} won ...": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P05-3023-Figure1-1.png": {
        "MT English": {
            "function": "English to Farsi and Farsi to English machine translation.",
            "absolute_position": "bottom center",
            "relative_position": "between Dialog Manager and SMT."
        },
        "Decoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/R11-2014-Figure1-1.png": {
        "VectorExtracor": {
            "function": "",
            "absolute_position": "in the middle section of the diagram, just after the 'Stanford POS Tagger' and before 'TiMBL'.",
            "relative_position": "it's the second processing step/module in the depicted workflow, directly following the 'Stanford POS Tagger'."
        },
        "Document Processor Database": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W13-3907-Figure1-1.png": {
        "Lattice search module": {
            "function": "to search through the phone lattice using the language model to find the most probable sentence transcription.",
            "absolute_position": "lower-center part of the figure",
            "relative_position": "between the \"Phone lattice\" and \"Recognised sentence\" steps, also directly below the \"Phone recogniser\" step."
        },
        "Bilingual Sparse Coding (Sec.3.3)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-main.236-Figure2-1.png": {
        "<EOS>": {
            "function": "to signify the end of the output sequence in the diagram.",
            "absolute_position": "the last element in the sequence at the bottom right of the figure.",
            "relative_position": "at the end of the output sequence after the decoders in the transformer architecture diagram."
        },
        "Multiple Classifier": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.conll-shared.7-Figure4-1.png": {
        "HIT-SCIR Parser[EDS]": {
            "function": "",
            "absolute_position": "on the top center, slightly to the left side of the figure.",
            "relative_position": "above the shared stacked self-attention module and to the left of the HIT-SCIR Parser[UCCA] module."
        },
        "average": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D14-1159-Figure1-1.png": {
        "Step 1": {
            "function": "",
            "absolute_position": "top right",
            "relative_position": "above and to the left of the other numbered steps in the sequence, as it appears to be the first step in this flowchart-like diagram."
        },
        "Non-Explicit Relation Sense Classification": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-acl.39-Figure3-1.png": {
        "System Action Decoder": {
            "function": "",
            "absolute_position": "upper right",
            "relative_position": "next to the top right corner."
        },
        "MLP-ATT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C04-1149-Figure1-1.png": {
        "Translation Knowledge Acquisition": {
            "function": "to gather and process translation data to update and improve the Translation Knowledge DB.",
            "absolute_position": "lower center",
            "relative_position": "below the \"Phrase Alignment / Spotting\" module and to the right of the \"Translation Knowledge DB\" module."
        },
        "adv=prep_definite-article_noun": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/E12-1080-Figure4-1.png": {
        "s1t": {
            "function": "",
            "absolute_position": "center top",
            "relative_position": "above S^2_t and O^2_t, and in between S^1_t-1 and S^1_t+1."
        },
        "zh": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C18-1101-Figure1-1.png": {
        "AMR graph": {
            "function": "to visually represent the Abstract Meaning Representation (AMR) of the given sentence.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Word Embedding Matrix Ew": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-emnlp.255-Figure1-1.png": {
        "Passage": {
            "function": "Unknown.",
            "absolute_position": "center-bottom",
            "relative_position": "below the \"First Extraction Iteration\" module and above the \"Second Extraction Iteration\" module."
        },
        "The Fast and the Furious (2001 film)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-acl.427-Figure2-1.png": {
        "Stage 1: Skeleton Construct": {
            "function": "to construct a skeletal structure for the input data using a transformer encoder-decoder architecture that incorporates both table embeddings and token embeddings.",
            "absolute_position": "top-left corner of the figure.",
            "relative_position": "left side, above the 'Stage 2: Surface Realization' module."
        },
        "Utterance Contextualization": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.findings-acl.97-Figure2-1.png": {
        "Feed Forward Self-Attention": {
            "function": "",
            "absolute_position": "on the right side of the figure",
            "relative_position": "in the upper right quadrant of the figure."
        },
        "Embeddings (Zh)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2007.mtsummit-papers.12-Figure1-1.png": {
        "Detection & Recognition & Translation Module": {
            "function": "to detect and recognize objects or text within images and translate the recognized text into different languages.",
            "absolute_position": "top-right",
            "relative_position": "to the right of the 'Capturer Module' and above the 'Interactive Module'."
        },
        "Suffix Association Matrix Generator": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.findings-acl.270-Figure2-1.png": {
        "Hierarchical Cross-Modal Aggregation": {
            "function": "to aggregate and refine multi-level feature representations from different modalities (such as visual and textual features) in a hierarchical manner for enhanced cross-modal understanding.",
            "absolute_position": "right side of the figure",
            "relative_position": "in the upper right quadrant."
        },
        "sameNE": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-5108-Figure1-1.png": {
        "Model Training": {
            "function": "to select relevant features, build the model, fine-tune the hyperparameters, and evaluate the model's performance.",
            "absolute_position": "top right",
            "relative_position": "third module from the left."
        },
        "Concatenation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L18-1541-Figure1-1.png": {
        "auxiliary natural language sentences": {
            "function": "to provide additional natural language context or data that can be utilized to assist other components in the diagram, potentially for tasks like semantic understanding, disambiguation, or enriching the knowledge base.",
            "absolute_position": "top right of the figure",
            "relative_position": "above the \"DR\" module and to the right of the \"NL and KB training triples\" module."
        },
        "Softmax Classifier": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/I08-8006-Figure1-1.png": {
        "SMT": {
            "function": "",
            "absolute_position": "in the center of the figure.",
            "relative_position": "between the ASR module on the left and the SS module on the right."
        },
        "Context encoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W14-5147-Figure1-1.png": {
        "SMT mode": {
            "function": "",
            "absolute_position": "in the 'Online phase' section, right after 'Input doc'.",
            "relative_position": "between 'Input doc' and 'Use best LM'."
        },
        "Stability Analysis": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C12-1169-Figure1-1.png": {
        "Output": {
            "function": "to present the final result after processing input sentences through various stages including the extraction of evaluative expressions, identification of evaluation holder, extraction of evaluation target, determination of evaluation type, and determination of sentiment polarity.",
            "absolute_position": "bottom center",
            "relative_position": "below the \"Determination of sentiment polarity\" module."
        },
        "classes": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.splurobonlp-1.2-Figure2-1.png": {
        "Map-Instructions Fusion": {
            "function": "to integrate and process map information with navigational instructions.",
            "absolute_position": "in the center of the figure",
            "relative_position": "between the 'Fusion of Modalities' part on the left and the components labeled 'Landmark', 'Bearing', and 'Distance' on the right."
        },
        "(Sub-Task 1)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C10-1052-Figure8-1.png": {
        "Subcat. Frames": {
            "function": "",
            "absolute_position": "in the center",
            "relative_position": "between \"Sense Relations\" and \"Sense Examples\"."
        },
        "0..1": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Festival TTS": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        },
        "SRoBERTa": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W12-2031-Figure1-1.png": {
        "Classifier C4: Preposition Selection On, in, to ...": {
            "function": "to select the appropriate preposition (e.g., on, in, to) for a given text context.",
            "absolute_position": "third from the left in the sequence of modules depicted horizontally in the bottom row of the flowchart.",
            "relative_position": "immediately following Classifier C3 and preceding the \"Definite Determiner\" module."
        },
        "Tree2Code+SCT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W07-1205-Figure3-1.png": {
        "S": {
            "function": "",
            "absolute_position": "at the top of the diagram, above the 'VP' module and to the right of the numbers '1 2 3'.",
            "relative_position": "above and to the right of the 'VP' module, which contains 'am not going' and 'today'."
        },
        "ASR Module": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.4-Figure1-1.png": {
        "Encoder": {
            "function": "to convert the input sequence into a higher-level feature representation.",
            "absolute_position": "middle figure, bottom center",
            "relative_position": "between the 'Predictor' and 'Joiner' modules."
        },
        "Use multilingual embedding as auxiliary embedding": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-main.283-Figure1-1.png": {
        "Introduction": {
            "function": "to serve as the first section of the document, usually providing an overview or summary of the content that will follow.",
            "absolute_position": "top left corner",
            "relative_position": "first or earliest in the sequence of sections/modules displayed in the figure."
        },
        "Database": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/O04-1013-Figure10-1.png": {
        "Book Recommendation System": {
            "function": "to suggest books to readers based on certain criteria or algorithms.",
            "absolute_position": "in the center of the image, at the bottom.",
            "relative_position": "between 'WIS' and 'ISO2709' modules, and below 'Reader's Browser'."
        },
        "agentive": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/X93-1018-Figure1-1.png": {
        "OTHER CODING": {
            "function": "",
            "absolute_position": "third from the top",
            "relative_position": "below \"SECONDARY CODING\" and above another \"OTHER CODING\"."
        },
        "Positive Sentiment: exceeds my expectations": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.ccl-1.58-Figure3-1.png": {
        "sentence encoder": {
            "function": "to process the sentence embedding and produce a final representation for further classification tasks.",
            "absolute_position": "in the center of the figure, to the left side",
            "relative_position": "below 'sentence embedding' and above 'final representation'."
        },
        "4.Compu- tation of total scores": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.ccl-1.107-Figure1-1.png": {
        "Enhanced Layer BERT Encoder": {
            "function": "to encode numerical and token information from first course medical records into a meaningful representation that can be utilized in further processing steps.",
            "absolute_position": "in the center of the bottom half of the image",
            "relative_position": "it is below the \"Fusion\" module and at the same level as the \"Diseases weighted Computation\" and \"Entity Linking\" modules, within the larger dashed box that seems to encapsulate an entire workflow or section of the diagram."
        },
        "Reminder (Source)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S18-1110-Figure1-1.png": {
        "Extract time, location participant info": {
            "function": "to extract time, location, and participant information from data.",
            "absolute_position": "in the bottom center of the figure",
            "relative_position": "below the \"Extract event type features\" module and to the left of the \"Retrieve documents\" module."
        },
        "Pseudo-parallel": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to extract time, location, and participant information."
        }
    },
    "/data_share/data/acl_parse/figure/2009.mtsummit-caasl.2-Figure1-1.png": {
        "Test2": {
            "function": "",
            "absolute_position": "right-center",
            "relative_position": "upper-middle."
        },
        "CSC Labels": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2006.eamt-1.7-Figure1-1.png": {
        "Target Language Generation English": {
            "function": "to produce the final translation in English from the processed input of the source language.",
            "absolute_position": "in the lower center of the figure",
            "relative_position": "below the \"From SL to TL\" modules and above the \"English\" output sentence."
        },
        "(a) Proposition Extraction": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W11-3405-Figure1-1.png": {
        "Hybrid Approach": {
            "function": "to combine the statistical approach with rule-based post-processing within a system to potentially improve performance or accuracy.",
            "absolute_position": "it is the central module in the figure, located between the \"Rule-Based Approach\" at the top and \"Errors\" at the bottom.",
            "relative_position": "it is directly below the \"Rule-Based Approach\" and directly above \"Errors\"."
        },
        "Heuristic mappings": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/K19-1036-Figure1-1.png": {
        "Dialogue acts Attention": {
            "function": "",
            "absolute_position": "in the center of the figure",
            "relative_position": "between the 'Utterance representation' layer and the 'Dual-Attention BiGRU' layer."
        },
        "Word Embedding": {
            "function": "to convert words from the input utterance into vectors that represent the semantic meaning of the words in a continuous vector space.",
            "absolute_position": "bottom center of the figure, as it is near the bottom of the image and centrally located from left to right.",
            "relative_position": "within the 'Embedding Layer' section, which is the second segment from the bottom of the architectural diagram."
        },
        "Policy Network": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        },
        "MLPd'": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.finnlp-1.9-Figure2-1.png": {
        "pooling": {
            "function": "to aggregate the features extracted by SRoBERTa from the input sentence into a fixed-size representation.",
            "absolute_position": "second from the top",
            "relative_position": "between 'u' and 'SRoBERTa'."
        },
        "n00691": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-1616-Figure2-1.png": {
        "HAS": {
            "function": "to denote the relationship between the \"OWNER\" and the \"PET\" in the diagram, indicating that the owner possesses or is responsible for the pet.",
            "absolute_position": "top right corner of the diagram",
            "relative_position": "to the right of the \"PET\" module and above the \"IDENTIFICATION\" module."
        },
        "C-Map": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.emnlp-demos.15-FigureA.2-1.png": {
        "Metrics": {
            "function": "",
            "absolute_position": "near the top-right corner of the figure.",
            "relative_position": "between Interpreters and Generators within the top-right section of the diagram."
        },
        "Train NMT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/F13-1029-Figure1-1.png": {
        "MAGEAD_ANA": {
            "function": "",
            "absolute_position": "Center-left of the figure",
            "relative_position": "Directly above the 'MAGEAD_GEN' module and to the left side of the figure."
        },
        "Response Handler": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P15-1132-Figure2-1.png": {
        "the movie is very interesting / S": {
            "function": "to represent a complete sentence in the parse tree.",
            "absolute_position": "top",
            "relative_position": "root of the tree structure."
        },
        "Custom Splitter": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P94-1009-Figure1-1.png": {
        "GENERATION": {
            "function": "to produce discourse responses based on the interpretation and theorem prover's output within the context of discourse expectations.",
            "absolute_position": "top-center of the figure",
            "relative_position": "to the right of the 'INTERPRETATION' module and above the 'THEOREM PROVER' module."
        },
        "SUMTIME- MOUSAM": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.fnp-1.19-Figure1-1.png": {
        "Text processing": {
            "function": "to perform narrative screening and text cleaning and normalization.",
            "absolute_position": "second from the left at the top",
            "relative_position": "after 'Annual Report' and before 'Text Representation'."
        },
        "LC MW Representation RC": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-main.315-Figure1-1.png": {
        "Shared FFNN Layers": {
            "function": "to process the embedding representations and capture complex features that can be used further down the model pipeline.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Ranking engine": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P17-3002-Figure1-1.png": {
        "Modeling from structured resources": {
            "function": "to derive tweet representations using structured data sources or existing knowledge bases.",
            "absolute_position": "third from the left on the top row of modules.",
            "relative_position": "in the center of the figure."
        },
        "signal-1": {
            "absolute_position": "",
            "relative_position": "",
            "function": "modeling from structured resources."
        }
    },
    "/data_share/data/acl_parse/figure/L16-1634-Figure1-1.png": {
        "OGVC": {
            "function": "",
            "absolute_position": "bottom right corner of the figure",
            "relative_position": "below and to the right of the classification model."
        },
        "Decoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2009.jeptalnrecital-long.14-Figure4-1.png": {
        "Generation traduction": {
            "function": "to produce the translation of the term \"anticonstitutionnel\" into French.",
            "absolute_position": "6",
            "relative_position": "bottom right."
        },
        "InfoXtract": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W02-1303-Figure1-1.png": {
        "Index": {
            "function": "",
            "absolute_position": "in the bottom right corner of the figure.",
            "relative_position": "to the right of the 'Inference Rules' and below 'Text Meaning Representations' within the 'Knowledge Resources' section of the diagram."
        },
        "Revised Doc Dt": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-1841-Figure1-1.png": {
        "PERSON-MULTIPLE": {
            "function": "",
            "absolute_position": "lower right corner.",
            "relative_position": "below the \"Person Referent\" module and to the right of the \"PERSON-SINGLE\" module."
        },
        "Filter verses": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/O08-6004-Figure1-1.png": {
        "Article title (sub-heading)": {
            "function": "to target the subcategories or sections within a Wikipedia article during the search process.",
            "absolute_position": "fourth from the top among the main vertical list of modules",
            "relative_position": "directly below the \"Sub-Search\" module and directly above the list that starts with \"1. Heading 1.\""
        },
        "Glimpse gt-1": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.acl-main.316-Figure3-1.png": {
        "Encoder": {
            "function": "to map the input data \\(x\\) to a latent representation \\(e\\).",
            "absolute_position": "in the central part of the figure, close to the left side",
            "relative_position": "between the element labeled 'x' on the left and the element labeled 'e' on the right, above the 'Posterior' block, which is part of a shared structure with other elements in the figure."
        },
        "Marfors Text Editor": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N18-1057-Figure2-1.png": {
        "Attention": {
            "function": "to selectively focus on certain parts of the input data at each step of the output generation in the decoder.",
            "absolute_position": "in the lower central part of the figure, within the dashed outline.",
            "relative_position": "below the \"CNN Decoder\" and above the \"CNN Encoder.\""
        },
        "BERT embeddings e(1:T)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.semeval-1.212-Figure1-1.png": {
        "Posts Containing File": {
            "function": "to store or contain the posts that are to be separated from annotations before being translated.",
            "absolute_position": "second from the left, top row",
            "relative_position": "immediately to the right of the 'Separate Posts and Annotations' module."
        },
        "Le capitaine a rapporte un vase de Chine.": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P84-1014-Figure4-1.png": {
        "employee": {
            "function": "to represent an entity that has attributes such as sex, degree, and salary associated with it.",
            "absolute_position": "bottom middle of the figure",
            "relative_position": "directly below the 'degree' module and above the caption \"Figure A. Interpretation of People and General Knowledge\"."
        },
        "lg_ps_rules": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-4753-Figure1-1.png": {
        "image I": {
            "function": "",
            "absolute_position": "top-right",
            "relative_position": "after \"a corpus of images with target language descriptions\" and before \"target language descriptions of similar images\"."
        },
        "Vocabulary and POS info in informal, ad-hoc format": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C00-2115-Figure1-1.png": {
        "align S1 and S2": {
            "function": "to align sequences S1 and S2.",
            "absolute_position": "on the right side of the flowchart, around the center vertically.",
            "relative_position": "after 'calculate Levenshtein distance' and before 'find lcc' modules, in the same horizontal flow."
        },
        "clusters": {
            "function": "",
            "absolute_position": "in the bottom center of the flowchart.",
            "relative_position": "below the \"cluster bindings\" module and to the left of the \"definitions\" module."
        },
        "[CLS]": {
            "absolute_position": "",
            "relative_position": "",
            "function": "unknown."
        },
        "PROCESSING OPTIONS: HOST PROCESSING ACCELERATOR DSP CHIP ARRAY": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.findings-emnlp.151-Figure1-1.png": {
        "Target Labeled Data": {
            "function": "fine-tuning BERT on target labeled data.",
            "absolute_position": "top-right corner of the figure.",
            "relative_position": "to the right of the \"Standard approach\" section and above the \"Research question\" section."
        },
        "Translation Memory": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.evalnlgeval-1.4-Figure1-1.png": {
        "Fully Connected Neural Network": {
            "function": "to integrate various input scores such as Semantic Similarity Score, Logical Entailment Score, and Sentence Intelligibility to produce an output that feeds into a Calibration module, ultimately contributing to the prediction of a Quality Score for a Candidate Sentence.",
            "absolute_position": "center-right",
            "relative_position": "after the inputs of Semantic Similarity Score, Logical Entailment Score, and Sentence Intelligibility and before the Calibration module."
        },
        "Results Buffer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2005.jeptalnrecital-court.22-Figure3-1.png": {
        "Sortie XML": {
            "function": "to output data in XML format.",
            "absolute_position": "on the right side of the image, in the upper half of the figure and near the center horizontally.",
            "relative_position": "following 'Segmenteur' and 'Étiqueteur' in the workflow diagram, it is the last element in the sequence shown."
        },
        "Entailment scorer (RoBERTa)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-acl.388-Figure3-1.png": {
        "student_course_registrations.course_id": {
            "function": "to specify the foreign key in the 'student_course_registrations' table that references the 'course_id' column in the 'courses' table, used here to join these tables in the SQL query.",
            "absolute_position": "bottom-right corner of the diagram",
            "relative_position": "connected below the \"eq\" node on the right side of the diagram."
        },
        "Device*": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W13-1615-Figure1-1.png": {
        "Learning algorithm": {
            "function": "to adjust the weights within the Neural Network based on some form of feedback to improve the performance of the model over time.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Generation Consultation Link": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2008.tc-1.6-Figure4-1.png": {
        "Customer": {
            "function": "providing publication or market-specific style guides and implicit or explicit expanded style information.",
            "absolute_position": "in the top-center of the diagram, above the \"Corporate memory\" and \"LSP\" ellipses.",
            "relative_position": "above the main process flow, outside of the central system depicted by the ellipses."
        },
        "cold baseball drift ball": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C94-1017-Figure15-1.png": {
        "Transiation server": {
            "function": "",
            "absolute_position": "in the bottom right quadrant of the figure",
            "relative_position": "at the bottom within the right group of modules."
        },
        "Delete Decoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P10-1068-Figure6-1.png": {
        "comparison vath reference description": {
            "function": "to compare the output of different annotation models with a set of reference corpus descriptions to determine consistency and accuracy.",
            "absolute_position": "bottom middle",
            "relative_position": "below the central flow of the diagram, at the bottom."
        },
        "airplane1n": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/K17-2007-Figure4-1.png": {
        "Bidirectional GRU encoder": {
            "function": "to process sequences in both forward and backward directions to capture information from both past and future contexts.",
            "absolute_position": "in the center of the figure, directly below the \"Embedding layer\" and above the \"GRU decoder.\"",
            "relative_position": "third from the top, in a vertical arrangement of modules."
        },
        "PostgreSQL": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.findings-acl.142-Figure1-1.png": {
        "Harry Potter": {
            "function": "to represent a key term in voice-activated searches or commands related to the Harry Potter book series.",
            "absolute_position": "2nd row, 3rd column",
            "relative_position": "bottom right."
        },
        "SOME =hasParents2": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W18-3710-Figure1-1.png": {
        "MLP": {
            "function": "to process the output from the LSTM layer into the predicted output \\( \\hat{y} \\).",
            "absolute_position": "top-right corner of the figure",
            "relative_position": "above the LSTM module."
        },
        "Ontology/Schema Representation of Data": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-2607-Figure1-1.png": {
        "Relevance Score": {
            "function": "",
            "absolute_position": "in the center, slightly to the left side of the figure",
            "relative_position": "centrally located just above the GRU modules which are at the bottom center of the figure."
        },
        "PMI": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-5803-Figure1-1.png": {
        "Cross-lingual Embedding": {
            "function": "to map words or phrases from two or more different languages into a shared embedding space to enable cross-lingual transfer or understanding.",
            "absolute_position": "at the bottom center of the figure",
            "relative_position": "directly beneath the main diagram/process flow and above the Chinese and English words."
        },
        "Task D1": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S17-2048-Figure2-1.png": {
        "Features": {
            "function": "to extract and provide relevant features for translation from the output of the RNN (Recurrent Neural Network) layer.",
            "absolute_position": "in the second row from the top, third column from the left.",
            "relative_position": "to the right of the 'RNN' module and above the 'Fully connected' modules."
        },
        "RELEVANCE SCORE": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P87-1003-Figure1-1.png": {
        "SITUATIONS": {
            "function": "",
            "absolute_position": "top-center",
            "relative_position": "above 'STATES' and 'OCCURRENCES'."
        },
        "Evaluate": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/J12-4005-Figure1-1.png": {
        "Experiments at sense-level": {
            "function": "to perform tests using simple features, binarized features, and grouped features.",
            "absolute_position": "near the bottom left of the figure",
            "relative_position": "following the output from the \"(2)Model_1 (sense-based)\" step and above the \"(3)ADN-Classifier_R1\" step."
        },
        "Auxiliary Tasks": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to conduct experiments at sense-level with simple, binarized, and grouped features."
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-main.462-Figure1-1.png": {
        "(b) K-Step Ahead Prediction": {
            "function": "to predict the output sequence k time-steps in advance in a sequence-to-sequence learning model.",
            "absolute_position": "on the right side of the figure",
            "relative_position": "it is the second module from the left."
        },
        "Hantology (Chinese-Japanese character-based ontology)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.tacl-1.46-Figure3-1.png": {
        "NMT L1->R2": {
            "function": "to perform neural machine translation from language L1 to R2.",
            "absolute_position": "third row, first column.",
            "relative_position": "left side of the third row."
        },
        "Base of the Brain": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/J96-3007-Figure4-1.png": {
        "Select valid Insides by running Inside algorithm topdown": {
            "function": "to select valid Insides by running the Inside algorithm topdown.",
            "absolute_position": "middle right",
            "relative_position": "below \"Compute Inside probability of W\" and above \"Run Outside algorithm\"."
        },
        "Experience": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W15-3802-Figure3-1.png": {
        "Named entity detection and extraction of drug and conditions which occur together in a sentence": {
            "function": "the detection and extraction of drugs and conditions that are mentioned together within the same sentence.",
            "absolute_position": "upper right corner",
            "relative_position": "to the right of the flowchart, adjacent to the last process step before the output ('automatically labelled data')."
        },
        "max_pool": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-short.44-Figure1-1.png": {
        "Projector": {
            "function": "to transform the encoded features to a space where self-supervised learning objectives, such as contrastive loss or feature decorrelation, can be effectively applied.",
            "absolute_position": "in the center on the top row",
            "relative_position": "to the right of the top Encoder and to the left of the Correlation matrix."
        },
        "H0": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L18-1158-Figure1-1.png": {
        "Semantic disambiguation rules/model": {
            "function": "to apply rules or models to resolve ambiguities in meaning within the text.",
            "absolute_position": "to the right of the 'Semantic tagger' module and below the 'External POS taggers' module",
            "relative_position": "between the 'Semantic tagger' and 'Output Formatter' modules, on the right side of the main process flow."
        },
        "music": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P13-1024-Figure2-1.png": {
        "pT": {
            "function": "",
            "absolute_position": "second from the left",
            "relative_position": "between the first module on the left and the third module on the right."
        },
        "BERT-base (Chinese)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D18-1455-Figure2-1.png": {
        "Lacey Chabert": {
            "function": "",
            "absolute_position": "bottom center of the diagram on the left side",
            "relative_position": "inside the LSTM block, below the sequence of LSTM cells."
        },
        "Feature extractor": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P06-2015-Figure3-1.png": {
        "Compound Preposition (CP)": {
            "function": "",
            "absolute_position": "bottom center of the figure",
            "relative_position": "below the \"Incorporation Module\" and above \"Prepositional Phrase (PP)\"."
        },
        "Answer Classifier": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W00-1314-Figure4-1.png": {
        "Computer Aid Translation System": {
            "function": "",
            "absolute_position": "in the lower right-hand corner of the figure.",
            "relative_position": "to the right of the 'Example Based Machine Translation System' module and below the 'Target Text' module."
        },
        "ft": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/O15-2002-Figure1-1.png": {
        "Candidates Re-Ranking": {
            "function": "to re-order the generated correction candidates based on their likelihood or correctness before final decision-making.",
            "absolute_position": "It's the fourth module from the top.",
            "relative_position": "It's right below the \"HMM-based Correction Candidates Generating\" module and above the \"Syntactic Rule based Correction\" and \"Other Rules for Exception\" modules."
        },
        "Accurrulated water": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W01-0907-Figure2-1.png": {
        "Semantic relations extraction": {
            "function": "semantic relations extraction and representation.",
            "absolute_position": "in the second column, second row.",
            "relative_position": "in the middle right side of the figure."
        },
        "Response": {
            "absolute_position": "",
            "relative_position": "",
            "function": "semantic relations extraction and representation."
        }
    },
    "/data_share/data/acl_parse/figure/P19-1319-Figure3-1.png": {
        "Distance function": {
            "function": "to compute the similarity or dissimilarity between the output vectors \\(x'\\) and \\(y'\\) produced by the neural networks.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Target Relation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P17-1165-Figure5-1.png": {
        "economics theorist": {
            "function": "to describe Ralph Borsodi's occupation or field of expertise.",
            "absolute_position": "3rd",
            "relative_position": "middle."
        },
        "Referenced elements": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-emnlp.245-Figure2-1.png": {
        "Polarity Values": {
            "function": "to integrate and assign sentiment polarity scores to the processed textual information in the system.",
            "absolute_position": "in the upper middle section of the figure, to the right of the center.",
            "relative_position": "in the top right corner of both the 'Main Task: ERC' and 'Auxiliary Task: SPIP' sections, to the right of the 'Self-Matching' module."
        },
        "avefilock + BatchNor": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2010.iwslt-papers.10-Figure1-1.png": {
        "Sentence 6": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Feature extractor": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-emnlp.31-Figure2-1.png": {
        "RCNN": {
            "function": "to extract visual features from the input image for further processing in the model.",
            "absolute_position": "",
            "relative_position": ""
        },
        "OperationArgument.": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W07-2421-Figure3-1.png": {
        "2. Apply the corresponding corrector functions": {
            "function": "to apply the corresponding corrector functions to the test limited-bandwidth data to produce pseudo full-bandwidth data.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Web-based collaborative post-editing platform": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.naacl-industry.32-Figure1-1.png": {
        "NAR Decoder": {
            "function": "to decode the encoded input by applying self-attention, encoder-to-decoder attention, and feed-forward neural network layers to generate an output sequence.",
            "absolute_position": "on the right side of the figure, towards the middle.",
            "relative_position": "after the Encoder and before the output including 'Conditional Random Fields' and 'y' vector."
        },
        "need new books": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L16-1599-Figure13-1.png": {
        "NUMBER VALUE=2 two": {
            "function": "to specify the quantity of seasons, indicating two summers.",
            "absolute_position": "second from the left",
            "relative_position": "between the first and third module from the left."
        },
        "Synthesiser": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W04-0914-Figure1-1.png": {
        "Lexica": {
            "function": "",
            "absolute_position": "in the center at the top of the Knowledge Resources section.",
            "relative_position": "directly above the Inference Rules module and to the left of the Onomastica module."
        },
        "Indirect-Deliberate-Untruth": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D18-2020-Figure2-1.png": {
        "WIKIDATA": {
            "function": "to provide structured data to support the entity linking and QA (Question Answering) model, possibly serving as a knowledge base.",
            "absolute_position": "bottom right",
            "relative_position": "below “QA model” and to the right of “Entity linking”."
        },
        "Model Quantization": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W11-1012-Figure3-1.png": {
        "Derivation not allowed because the predicate argument is not complete": {
            "function": "to indicate an error in the syntactic parsing process where the derivation is not allowed due to incomplete predicate argument structure.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Pooling": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.semeval-1.216-Figure1-1.png": {
        " RoBERTa": {
            "function": "to process the input text \"Nothing is so contagious as example\" through fine-tuning and hyperparameter search with cross validation as part of a natural language processing task.",
            "absolute_position": "on the bottom right of the figure",
            "relative_position": "next to GPT-2, at the far right within the list of modules."
        },
        "can the evaluation be expressed at the determiner level?": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/H89-1013-Figure1-1.png": {
        "BBN's JANUS System": {
            "function": "",
            "absolute_position": "at the center bottom of the figure.",
            "relative_position": "below \"Lexical Semantics\" and \"Domain Model\", and to the left of \"Application System 1\" and \"Application System N\". It is connected to \"END USER\"."
        },
        "KREME": {
            "function": "",
            "absolute_position": "near the top left corner of the figure.",
            "relative_position": "to the left of the \"PCL Class Hierarchy\" and above the \"Lexical Syntax\" module."
        },
        "Dialogue Manager": {
            "absolute_position": "in the center at the bottom part of the diagram, encapsulated within a rectangular box",
            "relative_position": "central in relation to the other components, with arrows indicating interactions with 'Lexical Syntax,' 'Lexical Semantics,' 'Domain Model,' 'Application Mapping Rules,' and directly connected to the 'END USER.' It is also positioned directly below 'KNACQ.'",
            "function": ""
        },
        "NarrativeRole": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W11-0409-Figure2-1.png": {
        "crush different minerals in water": {
            "function": "",
            "absolute_position": "top right",
            "relative_position": "to the right of the central concept \"crush.\""
        },
        "Commonsense Knowledge Base": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W13-1502-Figure1-1.png": {
        "Difficut Concepts Detection": {
            "function": "to identify and flag concepts within a given content that may be challenging for users to understand.",
            "absolute_position": "in the center and at the bottom of the diagram.",
            "relative_position": "below the \"Image Web Service\" and in the middle of the modules that it is connected to, specifically \"Document Indexing,\" \"Name Entity Recognition,\" \"ImageNet,\" \"Word Sense Disambiguation,\" and between \"Image Retrieval\" and the other connected components."
        },
        "Candidates": {
            "absolute_position": "in the center of the diagram",
            "relative_position": "below \"Image Web Service\" and above \"Name Entity Recognition,\" \"Word Sense Disambiguation,\" and \"ImageNet.\"",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W16-5414-Figure1-1.png": {
        "Matches in lemma form": {
            "function": "to provide matched multiword expressions in their base or dictionary form.",
            "absolute_position": "third in the sequence from the left.",
            "relative_position": "immediately after 'Matcher'."
        },
        "Processing": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-5809-Figure1-1.png": {
        "Question Pattern Identification": {
            "function": "to identify the pattern of the question being addressed.",
            "absolute_position": "in the center",
            "relative_position": "between \"Question Focus Estimation\" and \"Question Decoding.\""
        },
        "advertising_7": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P19-1548-Figure1-1.png": {
        "LOF Unknown Intent Detection": {
            "function": "to detect intents in the input data that are not known or previously defined in the system.",
            "absolute_position": "on the right-hand side of the figure, near the bottom corner.",
            "relative_position": "after the Discriminative Deep Features section and before the Loss Layer (LMCL) and Known Intent Class sections."
        },
        "Observation window of length l": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/1990.tc-1.1-Figure1-1.png": {
        "Text Preparation in restricted vocabularies and styles": {
            "function": "text preparation within predetermined vocabulary and stylistic constraints.",
            "absolute_position": "top-right",
            "relative_position": "beside \"Input texts\" and above \"Pre-Editing\"."
        },
        "TLF": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/I11-1064-Figure2-1.png": {
        "Knowledge Base": {
            "function": "to provide necessary information to generate the Candidate Sense List for a word form W in the context of a sentence or a paragraph.",
            "absolute_position": "on the bottom right side of the figure",
            "relative_position": "to the right of the \"Candidate Sense List\" and below the \"Highest Score Senses Filtering\"."
        },
        "Specialization model (non-linear regression)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/X98-1016-Figure1-1.png": {
        "Reference Resolution": {
            "function": "to determine the correct referent of words or phrases in a text that refer back to previously mentioned entities, such as pronouns or definite articles.",
            "absolute_position": "towards the lower center of the figure.",
            "relative_position": "below the \"Events\" module and above the \"Discourse Inference\" module. It's connected downstream to the \"Discourse Inference\" and seems to feed into \"Output Generation\" eventually."
        },
        "Original Samples": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/J95-1002-Figure9-1.png": {
        "Grasp-Action": {
            "function": "to represent the action where the actor, the hearer, grasps the handset.",
            "absolute_position": "bottom left section of the figure",
            "relative_position": "second from the left among the bottom modules."
        },
        "Match Block (shared)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P19-1128-Figure1-1.png": {
        "Cast member": {
            "function": "to represent the relationship between an individual and their role or involvement in the film \"Léon: The Professional\".",
            "absolute_position": "on the right-hand side of the image, near the top.",
            "relative_position": "to the right of the \"Léon\" module and to the left of the \"Luc Besson\" module."
        },
        "Run Chkgloss": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L18-1101-Figure2-1.png": {
        "...here iPhone will do me VERY well today...": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Linked Data Platform": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W04-1401-Figure2-1.png": {
        "Processing though Human Language Technologies + Team of Corporate Linguists": {
            "function": "incorporating human language technologies and a team of corporate linguists to process translation content.",
            "absolute_position": "on the right side of the figure, towards the upper part, beneath the \"Corporate Content Management System\" and above \"Domain Experts.\"",
            "relative_position": "following the flow from the \"Corporate Content Management System\" to the \"Domain Experts,\" it is positioned as an intermediary step within the Translation process."
        },
        "BC": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-4349-Figure2-1.png": {
        "XML Predictions Per turn & dialogue": {
            "function": "to read XML predictions for each turn and dialogue.",
            "absolute_position": "bottom center",
            "relative_position": "below the \"Dialogue Corpus\" and to the left of the \"ML Framework.\""
        },
        "Compilation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-5618-Figure2-1.png": {
        "Multi-Task NMT": {
            "function": "to perform neural machine translation while simultaneously handling multiple tasks such as translation, syntactic parsing, and semantic parsing.",
            "absolute_position": "bottom center of the figure",
            "relative_position": "below the 'Adaptive Importance Weights' module and at the end of the flow diagram."
        },
        "Number Agreement": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.nlp4prog-1.5-Figure2-1.png": {
        "CoTexT": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Anchor word: poetictheme": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C16-1264-Figure1-1.png": {
        "Model Visual": {
            "function": "to learn the visual representation of data for the attribute 'Has legs?' during the learning phase and to use this knowledge to predict the same attribute for new, unseen data during the testing phase.",
            "absolute_position": "upper half of the figure",
            "relative_position": "between the 'Learning' section on the left and the 'Testing' section on the right."
        },
        "Task Description d": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to learn visual representations (using CNN—Convolutional Neural Network) with respect to the attribute in question (e.g. \"Has legs?\") during the learning phase and to make predictions during the testing phase."
        }
    },
    "/data_share/data/acl_parse/figure/1992.tc-1.7-Figure4-1.png": {
        "Flement of Competence": {
            "function": "",
            "absolute_position": "second from the top within the dashed-line oval",
            "relative_position": "directly below the module labeled 'Performance Criteria' that is at the top of the stack inside the dashed-line oval."
        },
        "body|θ": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2002.jeptalnrecital-tutoriel.4-Figure6-1.png": {
        "Analyse en contexte": {
            "function": "to analyze the context within a dialogue or comprehension framework.",
            "absolute_position": "in the center-right area within the COMPREHENSION section.",
            "relative_position": "to the right of \"Analyse Statique\" and below \"Historique,\" within a set of interconnected modules related to dialogue processing or natural language understanding."
        },
        "auxiliary corpus": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.acl-main.104-Figure3-1.png": {
        "Linear Layer": {
            "function": "to apply a linear transformation to the input data.",
            "absolute_position": "in the center of the image",
            "relative_position": "in the top middle section of the center part of the image."
        },
        "Thme": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W18-5613-Figure3-1.png": {
        "Index": {
            "function": "",
            "absolute_position": "bottom center",
            "relative_position": "below the \"Event\" module."
        },
        "Veracity Prediction Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2017.iwslt-1.16-Figure2-1.png": {
        "(eos)": {
            "function": "",
            "absolute_position": "bottom row, second from the left.",
            "relative_position": "directly below the 'X' module in the middle row."
        },
        "Organization": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W98-1422-Figure5-1.png": {
        "HPSG Grammar": {
            "function": "",
            "absolute_position": "bottom center.",
            "relative_position": "between 'Tree combination (adjoining and substitution)' and 'Inflection' in the flowchart diagram."
        },
        "Zero-shot activity recognition": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/1999.mtsummit-1.10-Figure3-1.png": {
        "MT Transtation": {
            "function": "to perform machine translation of text from one language to another.",
            "absolute_position": "fourth from the top and fourth from the bottom.",
            "relative_position": "between \"TMX Converter (TM Import)\" and \"TMX Translation Unit Variant\" with text in French."
        },
        "Final Result": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to perform machine translation on the text."
        }
    },
    "/data_share/data/acl_parse/figure/W96-0204-Figure2-1.png": {
        "After pivot": {
            "function": "Unknown.",
            "absolute_position": "in the lower-middle section of the figure, near the center.",
            "relative_position": "After the 'Before pivot' module and before the 'Turn end' module, connected to both 'Before pivot' and 'Turn end' within the flowchart."
        },
        "CLOUD fitbit": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P09-3005-Figure2-1.png": {
        "CHEMorph": {
            "function": "",
            "absolute_position": "at the top center of the figure",
            "relative_position": "to the right of the 'name' module and to the left of the 'semantic representation' module."
        },
        "A stack-LSTM that encodes buffer (i.e., input tokens)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y09-2037-Figure1-1.png": {
        "Document Re-ranking": {
            "function": "to adjust the order of relevance of initially ranked documents before presenting the final ranking.",
            "absolute_position": "center left",
            "relative_position": "between the Initial Ranking Documents and Final Ranking Documents."
        },
        "cat": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-4012-Figure5-1.png": {
        "Dictionary L1 EC1 for L1 Rules L1": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Parsing & Alignment System": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W14-1015-Figure1-1.png": {
        "Morfological Generation": {
            "function": "to generate the correct morphological form of words in the target language during the translation process.",
            "absolute_position": "in the bottom right corner of the triangle diagram.",
            "relative_position": "to the right of the \"Structural Transfer\" module and below the \"Lexical Transfer\" module, near the \"TARGET LANGUAGE\" label."
        },
        "HPO succeeds": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-2915-Figure3-1.png": {
        "Syntactic/linear order effect dominates": {
            "function": "to indicate a condition where the syntactic or linear order of elements in a sentence predominantly influences the interpretation or response.",
            "absolute_position": "on the right side near the bottom of the flowchart.",
            "relative_position": "after the 'FALSE' branching from the SVO/OVS correlation module and before the 'FALSE' branching leading to the Syntax-pragmatics interaction."
        },
        "AsdeCopas": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2002.jeptalnrecital-recitalposter.4-Figure1-1.png": {
        "Representation Linguistique": {
            "function": "to transform the analyzed message into a format suitable for classification by a neural network.",
            "absolute_position": "fourth from the left",
            "relative_position": "between 'Analyse' and 'classification'."
        },
        "Thread 2 task manager": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-1188-Figure1-1.png": {
        "Model Adapter": {
            "function": "",
            "absolute_position": "top-center",
            "relative_position": "above the Encoder-Decoder module."
        },
        "KLT Term Extractor": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W14-3623-Figure1-1.png": {
        "Extract Sentiment Scores": {
            "function": "to extract sentiment scores from the provided input or data flow.",
            "absolute_position": "bottom center",
            "relative_position": "below EWN 2.1 and to the left of ESWN 3.0."
        },
        "SoftMax Dense Layer (2)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2013.iwslt-evaluation.11-Figure3-1.png": {
        "Acoustic Model Word lattice generation Pruned LM": {
            "function": "to generate a word lattice from audio input using the acoustic model and a pruned language model.",
            "absolute_position": "3rd place in the flowchart",
            "relative_position": "after \"Acoustic Model\" and before \"Lattice rescoring\"."
        },
        "hygrophyte1n": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-1209-Figure1-1.png": {
        "REFER Module": {
            "function": "to generate attention weights based on the question to guide the vision-language interaction in the model.",
            "absolute_position": "in the lower central portion of the figure.",
            "relative_position": "to the left of the FIND Module, and below the \"Dialog History,\" \"Question,\" and \"Image\" sections."
        },
        "York": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N19-4016-Figure1-1.png": {
        "Web Interface": {
            "function": "to provide a user interface for inputting topics and configurations and displaying the generated storylines and stories.",
            "absolute_position": "top-left corner",
            "relative_position": "first module from the left."
        },
        "Classifier": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C10-2054-Figure1-1.png": {
        "Keyword Extraction": {
            "function": "to extract relevant keywords from source documents.",
            "absolute_position": "in the center",
            "relative_position": "second from the left in the sequence of modules."
        },
        "General Lexicon": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W07-0103-Figure1-1.png": {
        "object (animal)": {
            "function": "to represent the noun or noun phrase that receives the action of the verb or completes the meaning of the sentence; specifically, it denotes the animal in this context.",
            "absolute_position": "the bottom right of the figure.",
            "relative_position": "to the right of the \"verb (is)\" module and below it, forming part of a diagram likely representing a sentence structure."
        },
        "det- definite- article": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.semeval-1.37-Figure1-1.png": {
        "Feature Extraction": {
            "function": "to extract relevant characteristics or attributes from the input data.",
            "absolute_position": "top right",
            "relative_position": "second from the top right."
        },
        "Relation-Meta Learner": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C10-2047-Figure6-1.png": {
        "Y:person": {
            "function": "",
            "absolute_position": "top center",
            "relative_position": "above all other modules."
        },
        "Stochastic approaches": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.acl-long.357-Figure5-1.png": {
        "yes / no": {
            "function": "to determine a yes/no answer based on the processed information.",
            "absolute_position": "bottom center",
            "relative_position": "directly below the 'Aggregator (pooling/RNN)' module in the central column of the figure."
        },
        "lexis:Sense": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-demo.3-Figure9-1.png": {
        "Annotation": {
            "function": "",
            "absolute_position": "Top",
            "relative_position": "Center."
        },
        "Ingestion of Directive in GATE": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/J19-3005-Figure1-1.png": {
        "lexicalized Model": {
            "function": "to be trained with word-aligned bitext in order to be utilized for parsing and translation tasks within the given workflow.",
            "absolute_position": "in the top-center of the image.\n   -",
            "relative_position": "right after the step (3) 'project' in the Annotation projection process.\n\n2. In the bottom part of the figure, within section c) Translation:\n   - Its absolute position is: at the bottom-center of the image.\n   -"
        },
        "Knowledge Bases": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/J94-3004-Figure16-1.png": {
        "Program Table": {
            "function": "",
            "absolute_position": "center-right side of the figure",
            "relative_position": "between the 'Possible protoforms' module on the left and the 'Dictionary of Tukche' module on the right, above the 'List of modern forms which fail to reconstruct' module at the bottom."
        },
        "Translate model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.lrec-1.596-Figure1-1.png": {
        "Evaluating Ontology": {
            "function": "assessing the quality and effectiveness of the ontology that has been constructed.",
            "absolute_position": "near the bottom center of the figure",
            "relative_position": "below the \"building Ontology\" module and above the \"Arabic infectious diseases ontology\" module."
        },
        "Correction- tagging Models": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2006.jeptalnrecital-poster.7-Figure8-1.png": {
        "Structure XML courante": {
            "function": "",
            "absolute_position": "in the top-center of the figure",
            "relative_position": "above the \"Réseau\" module and between the \"Formulaire XHTML vide\" module on the left and the \"Décodage par CGI\" module on the right."
        },
        "Posterior": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W08-1603-Figure1-1.png": {
        "Causality recognition": {
            "function": "to recognize causality within a given text.",
            "absolute_position": "bottom left",
            "relative_position": "inside the 'Causality identification' module."
        },
        "Semantic Space": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-7201-Figure3-1.png": {
        "all decoded": {
            "function": "to store the hidden states of all steps of the decoding process in a sequence-to-sequence model.",
            "absolute_position": "in the center towards the top-right corner of the diagram",
            "relative_position": "in the middle of the decoder section, above the LSTM layers and below the context vectors and attention scores."
        },
        "PERSON": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2015.tc-1.4-Figure1-1.png": {
        "many more aspects...": {
            "function": "to indicate that there are additional aspects of quality that are not listed in the diagram.",
            "absolute_position": "on the lower right side of the image",
            "relative_position": "directly to the right of the \"Definitions of quality\" central module."
        },
        "Models (Dev tune)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W09-2103-Figure3-1.png": {
        "0DA": {
            "function": "",
            "absolute_position": "top left",
            "relative_position": "before 1DA and after 4DA in the cycle."
        },
        "DBMS (network server)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W93-0311-Figure2-1.png": {
        "Word Hypothesizer": {
            "function": "to generate potential word candidates based on input syllables as part of a Chinese language processing system.",
            "absolute_position": "central",
            "relative_position": "between the 'Chinese Lexicon' and the 'Score Function', aligned horizontally."
        },
        "PRIODOC DESC: XX CLMS: XX": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.acl-long.196-Figure3-1.png": {
        "Knowledge-aware Contrastive Explanation Generator": {
            "function": "to generate contrastive explanations utilizing external knowledge from ConceptNet and GPT-2 for explaining why one label is chosen over another.",
            "absolute_position": "",
            "relative_position": ""
        },
        "NE-Table": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.acl-demos.16-Figure1-1.png": {
        "Adversarial Training": {
            "function": "to enhance the model's robustness by training it with adversarial examples that introduce small perturbations to the input data to improve its generalization capabilities.",
            "absolute_position": "bottom center",
            "relative_position": "between Single-task Knowledge Distillation and Multi-task Knowledge Distillation."
        },
        "Tennis Racket": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-emnlp.379-Figure2-1.png": {
        "Self-attention": {
            "function": "to allow the model to weigh the importance of different elements in the input data, focusing on the relevant parts needed to perform a specific task.",
            "absolute_position": "in the center of the figure, slightly towards the right.",
            "relative_position": "between the 'VGG-19' box and the 'Intra-modality attention' box on the top pipeline, and between 'DistilBERT' and 'Intra-modality attention' on the bottom pipeline."
        },
        "coffee chicken diamond tin newsstang wellhead calf after-market palm-oil winter-wheat meat milk timber...": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L18-1416-Figure1-1.png": {
        "VPstB": {
            "function": "",
            "absolute_position": "bottom center",
            "relative_position": "below NPstB and between VBase and VInfl."
        },
        "Monolingual Data": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L16-1707-Figure4-1.png": {
        "Refresh OLiA": {
            "function": "to update or synchronize the Ontologies of Linguistic Annotations models (OLiA models) within the system or workflow depicted.",
            "absolute_position": "lower left corner of the figure",
            "relative_position": "below 'Fetch all OLiA Models' and above 'OLiA LM / AM / RM'."
        },
        "Click and hold to start": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W16-3812-Figure3-1.png": {
        "'PAST'": {
            "function": "",
            "absolute_position": "second from the left",
            "relative_position": "between the first and third modules."
        },
        "onco": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P14-2136-Figure2-1.png": {
        "Classifier": {
            "function": "to categorize or label data based on learned patterns.",
            "absolute_position": "near the center of the figure, slightly towards the right side.",
            "relative_position": "after the \"Text representation\" stage and before the \"Results\" stage, in the process flow depicted in the diagram."
        },
        "replace vowel consonant pairing with v g": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/J11-3005-Figure4-1.png": {
        "Test Chinese Review": {
            "function": "to provide data for evaluating the performance of the Chinese Sentiment Classifier.",
            "absolute_position": "top-right",
            "relative_position": "above the 'Chinese Sentiment Classifier'."
        },
        "Affichage RA": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P16-3018-Figure1-1.png": {
        "\"The nearby food outlets serve fresh local breakfast, and are also cheaper.\"": {
            "function": "to provide an example of an implicit suggestion.",
            "absolute_position": "top-left",
            "relative_position": "above the central figure and to the left of the Suggestion bubble."
        },
        "Inter-rater agreement": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D18-1050-Figure1-1.png": {
        "3.3  Normalize tokenize, lowercase, strip markdown": {
            "function": "to standardize the text by tokenizing, converting to lowercase, and removing markdown formatting.",
            "absolute_position": "second from the left on the top row",
            "relative_position": "in the middle of the flowchart, between the 'Pre-filter' and 'OOV filter OPTIONAL' modules."
        },
        "Ranking": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to tokenize, lowercase, and strip markdown from text data."
        }
    },
    "/data_share/data/acl_parse/figure/W98-1007-Figure3-1.png": {
        "Variation Rules": {
            "function": "",
            "absolute_position": "fourth from the top",
            "relative_position": "below \"Intersect Rules.\""
        },
        "Post Prosessing of Predicted Summary": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C08-1111-Figure1-1.png": {
        "Building emotion-provoking event corpus (section 3.2)": {
            "function": "to create a database of events that elicit specific emotions for use in sentiment analysis or emotion detection tasks.",
            "absolute_position": "near the top center of the image",
            "relative_position": "to the left of the \"Emotion-provoking event corpus (EP corpus)\" section, and above the \"Sentiment polarity classification (section 3.3)\" and \"Emotion classification using EP Corpus (section 3.4)\" modules."
        },
        "Female": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W12-4516-Figure1-1.png": {
        "Mention Detection": {
            "function": "to identify instances where entities are mentioned in a text.",
            "absolute_position": "second from the top in the list of modules",
            "relative_position": "between the \"Pre-processing\" module and the \"Mention Clustering\" module."
        },
        "Reverse Seq2Seq Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/H91-1005-Figure3-1.png": {
        "Forced Recognition": {
            "function": "",
            "absolute_position": "top-center",
            "relative_position": "below \"Initialise Models\" and above \"Training\"."
        },
        "Pivotal sentence": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W09-0617-Figure2-1.png": {
        "CARD -hasParent2": {
            "function": "",
            "absolute_position": "the bottom right corner of the figure",
            "relative_position": "to the right of the \"SOME + <empty>\" module and below the \"VALUE\" module."
        },
        "WORLD MODEL": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W08-0619-Figure1-1.png": {
        "List of ids whose term contains AB": {
            "function": "to display a list of identifiers (ids) associated with terms that contain the sequence \"AB\".",
            "absolute_position": "x1, y3",
            "relative_position": "bottom left."
        },
        "Graph Initialization": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.dravidianlangtech-1.21-Figure1-1.png": {
        "Training Data": {
            "function": "to provide the necessary input data for training machine learning models.",
            "absolute_position": "top-center",
            "relative_position": "above \"Data Preprocessing\"."
        },
        "Target language": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/I17-2004-Figure1-1.png": {
        "NMT Lattice Search": {
            "function": "",
            "absolute_position": "third from the left end of the sequence",
            "relative_position": "immediately after the 'Search Graph' module and before the 'Target translation' in the sequence."
        },
        "Wruns": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-srw.34-Figure1-1.png": {
        "F-RCNN": {
            "function": "object region detection.",
            "absolute_position": "near the bottom center of the figure, below the \"Text Encoder\" and to the left of the \"OCR\" modules.",
            "relative_position": "within the \"Image Encoder\" section, as part of the overall architecture diagram."
        },
        "Extract relations and attributes of the entity from InfoBox and normalize them": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/A88-1003-Figure2-1.png": {
        "Gender Agreement": {
            "function": "",
            "absolute_position": "bottom-left corner",
            "relative_position": "directly below the 'Number Agreement' module and to the left of the 'Animacy' module."
        },
        "Annotations": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C10-1052-Figure1-1.png": {
        "synset id = ID category=<text>": {
            "function": "to represent a group of lexical units that express a distinct concept identified by an ID and categorized by a type of meaning or usage.",
            "absolute_position": "center-left",
            "relative_position": "second from the left."
        },
        "Document retrieval": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W01-1011-Figure1-1.png": {
        "E-Mail Prep": {
            "function": "to prepare the email message for further processing.",
            "absolute_position": "top-center",
            "relative_position": "at the beginning of the process flow, before \"Tokenization\"."
        },
        "Pick most frequent form for each modifier": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.naacl-main.306-Figure2-1.png": {
        "Graph Formation": {
            "function": "to create a structured representation of data by establishing connections between different entities, often in the form of nodes and edges, to facilitate subsequent analysis like relational reasoning or pattern recognition.",
            "absolute_position": "the center",
            "relative_position": "in the middle, between the \"Context Extractor\" module on the left and the \"Relational-GCN + GraphTransformer\" module on the right."
        },
        "Generation": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to create a graph structure that represents the relationships between different parts of the data."
        }
    },
    "/data_share/data/acl_parse/figure/O08-1016-Figure1-1.png": {
        "D2": {
            "function": "to filter or process a frequency band of noisy speech between 1000-2000Hz.",
            "absolute_position": "it is the second module from the left in the top row of modules.",
            "relative_position": "it is situated to the right of D1 and to the left of D3 in the diagram's flow."
        },
        "emac": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P13-2048-Figure3-1.png": {
        "SenseAxis id=<s124> pos=<n>": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "JSON Representation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W07-1014-Figure1-1.png": {
        "Restrict to MeSH": {
            "function": "to filter or limit the UMLS concepts to only those that correspond to MeSH (Medical Subject Headings) terms.",
            "absolute_position": "center left",
            "relative_position": "between \"UMLS concepts\" and \"MeSH Main Headings\"."
        },
        "Training Module": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P16-2093-Figure2-1.png": {
        "Concat": {
            "function": "to concatenate multiple feature vectors into a single feature vector.",
            "absolute_position": "in the center bottom part of the figure",
            "relative_position": "below the word embeddings, POS tags, and additional features, and above the function h(M1 × ⋅)."
        },
        "XPP to CLAUSE": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.lrec-1.672-Figure1-1.png": {
        "Chatbot: social interaction management": {
            "function": "social interaction management.",
            "absolute_position": "bottom right",
            "relative_position": "lower right within the 'Response generation' section."
        },
        "GIA WOALDBOOK": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P06-2121-Figure2-1.png": {
        "Observation window of length l": {
            "function": "to define the range of elements being observed at one time in a sequential process.",
            "absolute_position": "",
            "relative_position": ""
        },
        "OpenAI GPT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/1999.mtsummit-1.29-Figure2-1.png": {
        "Gs": {
            "function": "source grammar.",
            "absolute_position": "in the center towards the bottom of the figure.",
            "relative_position": "between 'GR0' on the right and 'PT(S|S)' to the left, below 'NR1s' and above the descriptive text 'Gs: source grammar'."
        },
        "Fine-tune (Source Data) OR Multi-task Learning (Source Data * Few-shot Target Data)": {
            "absolute_position": "",
            "relative_position": "",
            "function": "source grammar."
        }
    },
    "/data_share/data/acl_parse/figure/2011.mtsummit-wpt.4-Figure3-1.png": {
        "Selected Rule Subset2": {
            "function": "to represent the rules chosen from the second subset after the feedback selection process.",
            "absolute_position": "right-middle side of the figure",
            "relative_position": "to the right of the 'Feedback Selecting' module and below the 'Selected Rule Subset 1' module."
        },
        "Alignments: Source Position : Target Position": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C02-2023-Figure1-1.png": {
        "Prompt for score assignment for elements & alternatives": {
            "function": "to request input for the assignment of scoring values to identified elements and their possible alternatives.",
            "absolute_position": "4th",
            "relative_position": "below \"Confirm elements & search Wordnet for alternatives\" and above \"Create regex & store in database.\""
        },
        "Inter.": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to prompt for score assignment for elements and alternatives."
        }
    },
    "/data_share/data/acl_parse/figure/2022.clinicalnlp-1.6-Figure2-1.png": {
        "Clinical Data DE": {
            "function": "to represent a dataset or database of clinical data that has been translated or otherwise prepared in the German language (DE stands for Deutsch, which is German in English).",
            "absolute_position": "at the bottom center of the figure, below the main diagram and to the left.",
            "relative_position": "directly to the right of the \"Clinical Data EN (high quality annotations)\" module and to the left of the \"align\" arrow that points towards \"BOS (beginning of sentence).\""
        },
        "Harnwegsinfektion": {
            "function": "to represent the term \"urinary tract infection\" in German as \"Harnwegsinfektion\" within the diagram, indicating a translation or linguistic equivalence within the clinical data context.",
            "absolute_position": "in the upper-center part of the figure",
            "relative_position": "to the left of the \"Diseases Drugs\" module and above the \"Clinical Data DE\" module with \"BOS\" written below it."
        },
        "1e": {
            "absolute_position": "the bottom-center of the image",
            "relative_position": "directly below the \"embedding\" and \"Encoder output\" in the flow diagram.",
            "function": ""
        },
        "Diseriminator": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D18-2003-Figure1-1.png": {
        "Backend": {
            "function": "to handle model training, model revision, and text generation processes.",
            "absolute_position": "on the left side of the figure",
            "relative_position": "in the center left of the figure, surrounded by other components."
        },
        "Gaussian Mixture Modeling": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W12-3213-Figure1-1.png": {
        "Context Annotator": {
            "function": "",
            "absolute_position": "top right corner",
            "relative_position": "to the right of the XML Merger module and above the Annotated PDF module."
        },
        "Stanford parser": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2012.eamt-1.54-Figure1-1.png": {
        "lexical selection": {
            "function": "to choose the correct target language words or phrases corresponding to their source language counterparts during the translation process.",
            "absolute_position": "in the center of the figure",
            "relative_position": "between the 'lexical transfer' module on the left and the 'structural transfer' module on the right."
        },
        "Language Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to choose the appropriate words in the target language during the machine translation process."
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-industry.29-Figure2-1.png": {
        "Layer 3": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Colour": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.semeval-1.138-Figure1-1.png": {
        "Preprocesing removing unnecessary signs + making a substitute": {
            "function": "preprocessing the text data by removing unnecessary characters and signs, and performing replacements where necessary.",
            "absolute_position": "second from the left",
            "relative_position": "immediately to the right of the \"Feature generation based on frequent English bigrams\" module."
        },
        "Distilling knowledge": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-long.294-Figure3-1.png": {
        "CLS": {
            "function": "to serve as a special token used by the model to aggregate sequence information, often used as the representation of the entire input sequence for classification tasks.",
            "absolute_position": "the bottom left of the figure",
            "relative_position": "the first module on the left in the bottom row of the architecture diagram."
        },
        "Get Data (usage)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.conll-1.43-Figure1-1.png": {
        "Compare airfares": {
            "function": "to evaluate and contrast different flight prices.",
            "absolute_position": "bottom row, second from the left",
            "relative_position": "between \"Set locations and dates\" and \"Purchase a ticket\"."
        },
        " Japanese Template": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-1038-Figure1-1.png": {
        "Cross-Lingual Mapping": {
            "function": "to map embeddings from the target language into the embedding space of the English language.",
            "absolute_position": "third from the left",
            "relative_position": "between 'Target Embeddings' and 'English Embeddings'."
        },
        "sentence encoder with second sentence": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D13-1173-Figure1-1.png": {
        "Parallel": {
            "function": "",
            "absolute_position": "top-right.",
            "relative_position": "above 'TM'."
        },
        "EPR": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.findings-acl.144-Figure5-1.png": {
        "HGAT BLOCK": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Emotion Template Matching": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.acl-main.648-Figure1-1.png": {
        "Less Frequent Embeddings Accumulated Gradients": {
            "function": "",
            "absolute_position": "in the lower right quadrant of the image",
            "relative_position": "to the right of the 'Stacked LSTM Layers' module and below the 'Top-k embeddings' module."
        },
        "StoreType": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.emnlp-main.627-Figure1-1.png": {
        "Final Verdict": {
            "function": "to aggregate the outcomes of multiple verdicts to reach a conclusive decision on a claim.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Iterative Editor": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/A88-1016-Figure1-1.png": {
        "Rhythm Computation": {
            "function": "",
            "absolute_position": "fifth from the top.",
            "relative_position": "immediately after Prosody marking and before Generation of LPC frames modules."
        },
        "Prediction": {
            "absolute_position": "",
            "relative_position": "",
            "function": "rhythm computation."
        }
    },
    "/data_share/data/acl_parse/figure/N06-4009-Figure3-1.png": {
        "City": {
            "function": "to represent the classification or type of the object \"Washington-DC\" as a \"City\" in the diagram.",
            "absolute_position": "on the bottom right corner of the graph area.",
            "relative_position": "to the right of the \"cns object\" module and below the \"Washington-Dc\" module."
        },
        "Relative Head-position tag-sequence decoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/K17-1021-Figure1-1.png": {
        "Abstract Vector": {
            "function": "",
            "absolute_position": "Bottom center",
            "relative_position": "Directly below the 'Concatenate' module and to the left of the 'Features' module."
        },
        "employee": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-3510-Figure1-1.png": {
        "Crawling in Twitter": {
            "function": "to collect data from Twitter.",
            "absolute_position": "second from the left",
            "relative_position": "between \"Pages and keywords enumeration\" and \"Tweets Filtering.\""
        },
        "Pages and keywods enumeration": {
            "function": "to list and categorize pages and keywords relevant to the topic of interest.",
            "absolute_position": "1st from the left",
            "relative_position": "first in the sequence."
        },
        "Benefits targeted Usefulness Usability": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        },
        "MSE": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.emnlp-main.161-Figure1-1.png": {
        "Temporal Transformer": {
            "function": "to process and capture temporal relationships and dynamics in data over time.",
            "absolute_position": "in the right-center part of the figure",
            "relative_position": "right next to the 'Cosine Similarity' block within the 'Masked Frame Modeling' section."
        },
        "Average": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.ecnlp-1.22-Figure1-1.png": {
        "Gradient": {
            "function": "",
            "absolute_position": "bottom middle",
            "relative_position": "below 'Substitute' and to the left of 'Exploration'."
        },
        "I3:passen I2:pron": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W16-4909-Figure4-1.png": {
        "Simplified to Traditional&Word Segmentation & POS tagging": {
            "function": "to convert simplified Chinese characters to traditional Chinese characters, segment text into words, and assign part-of-speech tags to each word.",
            "absolute_position": "in the center and slightly to the left side of the image, at the bottom third portion.",
            "relative_position": "below the 'Train the CRF model' module and to the left of the 'Evaluate the System' module."
        },
        "Feedback Database": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W13-5405-Figure2-1.png": {
        "fang 'house'.": {
            "function": "to represent the concept of 'house' in a diagram that demonstrates word composition in the formation of the compound Chinese word 'fangche,' which means 'recreational vehicle.'",
            "absolute_position": "top left",
            "relative_position": "above and to the left of the module labeled 'fangche `recreational Vehicle`'."
        },
        "Large-scale LM": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S19-2154-Figure1-1.png": {
        "Encoder": {
            "function": "to transform the internal representation into a mathematical representation that can be processed by the Z3 Solver.",
            "absolute_position": "third from the left",
            "relative_position": "in the center."
        },
        "Text Narrative": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-main.246-Figure1-1.png": {
        "Critics Similar to Users": {
            "function": "to identify critics who have similar tastes or preferences to the users.",
            "absolute_position": "in the top-right quadrant of the figure, near the center.",
            "relative_position": "to the right of the 'Sentiment Estimate for Seen Movies' module and above the 'Earth Movers' and 'Cosine Similarity' modules."
        },
        "Whitney worked as a farm laborer and school teacher to save money.": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W02-0108-Figure3-1.png": {
        "Cancel": {
            "function": "to close the dialog without saving any changes made.",
            "absolute_position": "bottom-right corner of the window",
            "relative_position": "to the left of the \"OK\" button."
        },
        "Classifier": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-acl.69-Figure3-1.png": {
        "Additive Attention": {
            "function": "to calculate attention weights to modulate which features from a set should be focused on.",
            "absolute_position": "it is in the center area towards the right side of the image, within the 'Integration' section.",
            "relative_position": "it is located after the 'Conv Block' and 'Self-attention' components within the flow diagram and before the 'Output Fusion' component."
        },
        "MITE": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.semeval-1.228-Figure2-1.png": {
        "Transformation": {
            "function": "to apply a specific operation or a set of operations that convert input data into a different form or representation.",
            "absolute_position": "bottom-center",
            "relative_position": "below \"Bilinear Attention\" and above \"x_{wij}^{(l)}\"."
        },
        "\"Students reflections\"": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y05-1024-Figure1-1.png": {
        "Telephone Service Module": {
            "function": "",
            "absolute_position": "bottom-left corner of the figure",
            "relative_position": "below the \"Web Service Module\" and to the left of the \"Index\" and \"Text Retrieval Module\"."
        },
        "Value2": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.vardial-1.22-Figure1-1.png": {
        "Emb 896": {
            "function": "",
            "absolute_position": "third from the left in the top row of modules",
            "relative_position": "last on the visible modules on that row."
        },
        "RELATIVE CL.": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-3510-Figure2-1.png": {
        "Fat women": {
            "function": "",
            "absolute_position": "third row, second column.",
            "relative_position": "below 'Fat people' and to the right of 'Women'."
        },
        "D1": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-1415-Figure2-1.png": {
        "Morphnet full analysis prediction": {
            "function": "",
            "absolute_position": "at the bottom right corner of the figure",
            "relative_position": "below the VERB block and to the right of the TRANSLITERATION Venn diagram."
        },
        "Fully connected layer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W02-2101-Figure4-1.png": {
        "Summary": {
            "function": "to aggregate or condense 140 input features from four different contexts into a compact representation for use in machine learning models.",
            "absolute_position": "on the left side of the figure",
            "relative_position": "at the beginning or start of the sequence of modules or elements shown in the figure."
        },
        "agnt": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C00-2159-Figure1-1.png": {
        "comparable corpus": {
            "function": "to provide text pairs in different languages that are not direct translations but convey the same or similar information, for use in corpus-based cross-language information retrieval (CLIR).",
            "absolute_position": "at the bottom center of the figure",
            "relative_position": "below the \"corpus-based CLIR\" module."
        },
        "Word Candidate": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/E14-4040-Figure1-1.png": {
        "Boehner": {
            "function": "",
            "absolute_position": "top-left",
            "relative_position": "to the left of 'Obama' and above 'Republican Party'."
        },
        "Freebase": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W08-0120-Figure3-1.png": {
        "{fo-fi}": {
            "function": "",
            "absolute_position": "in the center at the top",
            "relative_position": "directly below the root frame state \\( f_0 \\) and to the left of \\( f_1 \\) within the hierarchy."
        },
        "Question weight (dynamic) Declaration weight (dynamic)": {
            "absolute_position": "upper center",
            "relative_position": "directly below the 'Root Frame State \\( f_0 \\)' and to the left of \\( f_1 \\) module.",
            "function": "to process dynamic weighting of a question's influence at a particular time frame based on user input within a decision-making or state evolution model depicted in the diagram."
        }
    },
    "/data_share/data/acl_parse/figure/W00-1014-Figure2-1.png": {
        "Dialogue tree": {
            "function": "to outline the potential pathways and choices available in a conversation within the system.",
            "absolute_position": "",
            "relative_position": ""
        },
        "hyperwords": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-long.107-Figure1-1.png": {
        "Pruned model": {
            "function": "to reduce the complexity of a fine-tuned BERT model by eliminating certain elements to improve efficiency without significantly compromising performance.",
            "absolute_position": "roughly in the center of the image",
            "relative_position": "in the center-right part of the diagram."
        },
        "Query Word: Acquitted": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-long.417-Figure3-1.png": {
        "T5": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "143": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/K19-1045-Figure3-1.png": {
        "Inference": {
            "function": "to perform the process of drawing conclusions from the given model, using the input data to produce the estimated output \\(\\hat{Y}\\).",
            "absolute_position": "top-center",
            "relative_position": "above the 'Constraints' module and in between the 'Model' label on the left and the predicted output on the right."
        },
        "200d tanh layer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/E95-1004-Figure1-1.png": {
        "usa": {
            "function": "Unknown.",
            "absolute_position": "bottom middle",
            "relative_position": "below the 'City of Saint-Louis' module and to the left of the 'feeding' module."
        },
        "Mapping relation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2007.jeptalnrecital-poster.4-Figure1-1.png": {
        "Minimiser les cout associes d la realisation de la tache": {
            "function": "to reduce the costs associated with the completion of the task.",
            "absolute_position": "in the bottom right quadrant of the figure.",
            "relative_position": "to the right of \"Maximiser la réalisation de la tâche\" and above \"Mesure de la qualité de la tâche\"."
        },
        "QA server": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/U16-1009-Figure1-1.png": {
        "Selectors": {
            "function": "to choose a phoneme for generating text based on training vocabulary statistics.",
            "absolute_position": "top right",
            "relative_position": "above the central flow diagram, on the right side of the figure."
        },
        "Semantic parsing for sentences": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-7512-Figure5-1.png": {
        "atiparoksa": {
            "function": "",
            "absolute_position": "third from the left under the \"Indirect Evidence\" category.",
            "relative_position": "immediately to the right of \"paroksa\" within the \"Indirect Evidence\" branch."
        },
        "paroksa": {
            "function": "",
            "absolute_position": "the third node from the left on the bottom tier of the hierarchy under \"Indirect Evidence\".",
            "relative_position": "directly below \"Indirect Evidence\" and to the left of \"atiparoksa\" within the hierarchy."
        },
        "noisy channel": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        },
        "di": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W02-2205-Figure2-1.png": {
        "S$(...j)": {
            "function": "",
            "absolute_position": "top-right.",
            "relative_position": "to the right of the NP(i)(Beans) module and at the same level as the NP(i)(Beans) module within the tree structure."
        },
        "Decs for passage-level text": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W98-1433-Figure3-1.png": {
        "Diphone synthesis": {
            "function": "to generate speech audio by concatenating diphone sounds, which are pairs of adjacent phonemes.",
            "absolute_position": "",
            "relative_position": ""
        },
        "atten": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-main.63-Figure2-1.png": {
        "Intent Decoder Hidden": {
            "function": "",
            "absolute_position": "bottom-center",
            "relative_position": "below the 'G' and 'Linear' modules and to the left of the 'Key-value Memory' module."
        },
        "Classification des schemes (22)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.findings-emnlp.159-Figure1-1.png": {
        "Decoder": {
            "function": "to convert the processed information from the encoder into output text.",
            "absolute_position": "in the center",
            "relative_position": "below the \"Encoder\" module and above the \"Output Text\" label, inside of the \"Realization\" dotted box."
        },
        "International Legal Resources": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.ecnlp-1.14-Figure2-1.png": {
        "Index subwords": {
            "function": "to index the subwords or subunits of words for efficient searching or processing.",
            "absolute_position": "top-right.",
            "relative_position": "second from the top, on the right side."
        },
        "GIZA++-/ METEOR-/ TER- alignment": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/I17-4032-Figure1-1.png": {
        "Dense": {
            "function": "to output the final prediction for a binary classification, typically indicating 'Yes' or 'No'.",
            "absolute_position": "bottom-center of the figure",
            "relative_position": "after the addition operation that combines the outputs of the LSTM and Attention layers."
        },
        "Step 2:Inference word ratings for empathy or distress": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P18-1170-Figure2-1.png": {
        "sleep": {
            "function": "",
            "absolute_position": "third from the left",
            "relative_position": "bottom center of the figure."
        },
        "Transformer Encoder Layer B": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.eacl-main.314-Figure1-1.png": {
        "Deep Representation": {
            "function": "to create an abstracted form of data input that captures higher-level semantic meanings, which is often used in tasks like question answering (QA), natural language inference (NLI), and paraphrase detection (PAWS).",
            "absolute_position": "in the center of the figure",
            "relative_position": "between \"Conceptual Representation\" and \"Semantic Sharing.\""
        },
        "Heading direction": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-0601-Figure1-1.png": {
        "Synchronization DB (Django)": {
            "function": "to synchronize data between a version control system (Git) and a wiki platform (Mediawiki).",
            "absolute_position": "",
            "relative_position": ""
        },
        "Interface de navigation/recherche": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.612-Figure4-1.png": {
        "Cosine similarity": {
            "function": "to calculate the similarity between the meaning embeddings of sentence 1 and sentence 2.",
            "absolute_position": "top-center",
            "relative_position": "above both 'Meaning embedding' modules."
        },
        "Joint training (big transformer)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W96-0512-Figure2-1.png": {
        "ONTOLOGY": {
            "function": "",
            "absolute_position": "top right",
            "relative_position": "to the right of \"CIA WORLD BOOK\"."
        },
        "Question Answering (QA) User-initiative": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/A92-1007-Figure3-1.png": {
        "(c) The surface structure": {
            "function": "to illustrate the arrangement and grammatical relationships between parts of sentences in the generated text.",
            "absolute_position": "bottom left",
            "relative_position": "third from the left, bottom row."
        },
        "Acoustic Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.semeval-1.131-Figure1-1.png": {
        "BERT": {
            "function": "to encode the \"Sentence - before\" and \"Edit words\" into vector representations that can be utilized in downstream processing tasks.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Sentence Pattern Table": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.findings-acl.265-Figure2-1.png": {
        "Unigram Auto-encoder": {
            "function": "to encode unigram (single word) frequency information from a bag of words representation into a continuous vector space and possibly reconstruct the original bag of words from this encoding.",
            "absolute_position": "top left",
            "relative_position": "leftmost."
        },
        "Knowledge-based Phone confusion": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P19-1415-Figure2-1.png": {
        "SEQ2SEQ": {
            "function": "to take an input sequence consisting of a paragraph and a question, encode it into an intermediate representation, and then decode it to produce an output, which can include identifying unanswerable questions.",
            "absolute_position": "top left",
            "relative_position": "left side of the figure."
        },
        "Morpho Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/K15-1017-Figure1-1.png": {
        "Stem": {
            "function": "to represent the base form of a word to which affixes are added.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Pattern finding": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-long.451-Figure5-1.png": {
        "MLM": {
            "function": "",
            "absolute_position": "in the center of the figure",
            "relative_position": "after the input representations and before the entailment logits."
        },
        "VoiceXML Gateway in U.S.A DemandVoice": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P15-1105-Figure1-1.png": {
        "Speech and Prosody Features": {
            "function": "to analyze the characteristics of speech such as intonation, tone, stress, and rhythm.",
            "absolute_position": "bottom right corner of the flowchart.",
            "relative_position": "to the left of the 'FA Features' module and below the 'Machine Learning Models' module."
        },
        "Ranking": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/A00-2043-Figure2-1.png": {
        "EXTENSION.04": {
            "function": "",
            "absolute_position": "below the \"COMPUTER-SYSTEM_02\" node and to the left of the \"SDRAM-MODULE_03\" node.",
            "relative_position": "directly beneath the \"EXTENSION-PATIENT\" node and above the \"MODALITY\" node."
        },
        "Simulator (Language independent)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2015.jeptalnrecital-long.18-Figure1-1.png": {
        "Traits": {
            "function": "to extract feature vectors from the test corpus and training corpus for further classification.",
            "absolute_position": "centrally placed towards the top of the diagram",
            "relative_position": "between the \"Corpus de Test\" and the \"Classifieur\"."
        },
        "Recognition": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to extract feature vectors from both test and training text corpora."
        }
    },
    "/data_share/data/acl_parse/figure/O08-1003-Figure1-1.png": {
        "Random Walk on Semantic Label Assignment": {
            "function": "to categorize uncategorized collocates using a random walk algorithm based on semantic labels.",
            "absolute_position": "in the center towards the right side of the figure",
            "relative_position": "between \"Uncategorized Collocates\" and \"A Collocation Thesaurus.\""
        },
        "Pseudo Word Lexicon": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.dravidianlangtech-1.24-Figure2-1.png": {
        "Embeddings on translated and transliterated text": {
            "function": "to generate numerical representations (embeddings) for translated and transliterated text data which can then be used for downstream machine learning tasks.",
            "absolute_position": "fourth from the left in the sequence of modules",
            "relative_position": "directly after the \"Translation and Transliteration\" module."
        },
        "Conversation Planner": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N10-3003-Figure1-1.png": {
        "Summary Extractinon": {
            "function": "to extract a summary from the input articles by selecting the most relevant sentences based on their ranking.",
            "absolute_position": "",
            "relative_position": ""
        },
        "qualification": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.lrec-1.145-Figure2-1.png": {
        "sell": {
            "function": "",
            "absolute_position": "inside the bottom left section of the BERT representation, between the tokens \"hooker\" and \"[SEP].\"",
            "relative_position": "between the first and second [SEP] tokens in the BERT sequence, after the word \"hooker\" and before \"we.\""
        },
        "Full Decoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/I11-1012-Figure1-1.png": {
        "Coreference Results": {
            "function": "to display the outcome of coreference resolution processes applied on input texts, after resolving various types of mentions and forming chains using spectral partitioning.",
            "absolute_position": "at the bottom center of the diagram.",
            "relative_position": "below the 'Chain Formation using Spectral Partitioning' module and at the end or bottom of the flowchart."
        },
        "Customer relationships": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.paclic-1.15-Figure1-1.png": {
        "Section": {
            "function": "",
            "absolute_position": "third from the left, second row.",
            "relative_position": "immediately to the right of 'Division' and to the left of 'Word'."
        },
        "m2": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/J99-3004-Figure4-1.png": {
        "Plan Ranking": {
            "function": "to rank the set of candidate discourse plans.",
            "absolute_position": "on the right side of the diagram, after the middle.",
            "relative_position": "to the right of the 'Top-down Plan Recognition' and 'Hypothesis Generation' modules, and directly following the arrow that points from these modules."
        },
        "MNB Baseline output": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/A94-1002-Figure3-1.png": {
        "Content Planner (Lisp)": {
            "function": "to organize and structure the content for generating text.",
            "absolute_position": "3rd from the left",
            "relative_position": "in the middle."
        },
        "Authentic de<->cs": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to organize and structure the content information to be included in a text."
        }
    },
    "/data_share/data/acl_parse/figure/2021.sigdial-1.35-Figure5-1.png": {
        "Oracle: train leaveat 13:45 train departure kings lynn": {
            "function": "to provide the correct information or answer in a dialogue system, serving as a ground truth or reference for comparing against the predicted responses generated by the system.",
            "absolute_position": "bottom left",
            "relative_position": "below and to the left of the central module."
        },
        "In-group members": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L16-1300-Figure2-1.png": {
        "MySQL": {
            "function": "to store annotations and the domain model.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Marry": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C10-2022-Figure3-1.png": {
        "Input SMS (S with tokens S": {
            "function": "to provide the initial set of tokens from an SMS text as input for further processing in the system.",
            "absolute_position": "top-center",
            "relative_position": "first (topmost) in the flowchart."
        },
        "News Article": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.fnp-1.14-Figure1-1.png": {
        "Multi-word terms": {
            "function": "to identify and extract phrases consisting of multiple words that are likely to represent key concepts or entities within the text.",
            "absolute_position": "third from the left at the top row",
            "relative_position": "immediately following the 'Preprocessing' module."
        },
        "BERT [CLS]": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-long.390-Figure2-1.png": {
        "Source Encoder": {
            "function": "to process and encode the input sequence adding positional information to prepare for further attention-based processing.",
            "absolute_position": "on the left side of the image, roughly one-third of the way down from the top.",
            "relative_position": "it is the third block from the bottom of the figure, located directly above \"Positional Encoding\" and \"Input Embedding\", and below the \"Multimodal Aggregation Module\"."
        },
        "[CLS]": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P17-1043-Figure2-1.png": {
        "Softmax and Concatenation": {
            "function": "to merge the outputs of previous layers and apply a softmax function to the merged output for probability distribution.",
            "absolute_position": "at the bottom center of the figure",
            "relative_position": "below all the other elements or modules in the figure."
        },
        "Document management": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.lrec-1.270-Figure1-1.png": {
        "water": {
            "function": "to represent the location where the earliest plants were constrained to for receiving sunlight for photosynthesis.",
            "absolute_position": "bottom center of the image",
            "relative_position": "to the left of the 'layer' module and below the 'plant' module within the graph."
        },
        "Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/J97-2003-Figure21-1.png": {
        "cheap models": {
            "function": "to generate an approximate lattice for further processing by more detailed models.",
            "absolute_position": "on the left side of the figure",
            "relative_position": "the first module in the sequence."
        },
        "English dictionary": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N09-1015-Figure1-1.png": {
        "Target Text": {
            "function": "to represent the output of the machine translation process.",
            "absolute_position": "in the lower right corner of the figure.",
            "relative_position": "to the right of the \"SMT Decoder\" and below the \"Filtered Model,\" at the end of the process flow."
        },
        "b)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W05-0308-Figure1-1.png": {
        "target frame id:t10 text anchor:people are happy because Chavez has fallen": {
            "function": "to define the context or situation that the associated attitude is referring to, specifically indicating that people are happy due to the event of 'Chavez has fallen'.",
            "absolute_position": "top right",
            "relative_position": "above the bottom right module and to the right of the top middle module."
        },
        "VF": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y14-1015-Figure2-1.png": {
        "Function Sentence Identification": {
            "function": "to identify whether which sentence is Given or Change or Result.",
            "absolute_position": "top-left",
            "relative_position": "first/leftmost in the sequence."
        },
        "Equation Generator": {
            "function": "using the prediction to generate an equation as part + part = whole.",
            "absolute_position": "Top right corner of the figure",
            "relative_position": "After 'Sign Prediction' and 'Function Sentence Identification'."
        },
        "Sentence-Level Pattern Matcher": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to identify whether the sentence is Given, Change, or Result."
        },
        "Agent N3": {
            "absolute_position": "",
            "relative_position": "",
            "function": "using the prediction to generate an equation as part + part = whole."
        }
    },
    "/data_share/data/acl_parse/figure/W18-5306-Figure1-1.png": {
        "Training": {
            "function": "to optimize the model's parameters through gradient-based optimization using a binary cross-entropy loss function in order to accurately classify input data.",
            "absolute_position": "bottom-right corner",
            "relative_position": "to the right of the \"Gradient Based Optimization\" block and below the \"Inference\" block."
        },
        "Classification": {
            "absolute_position": "in the right part of the image, after the linear layer and sigmoid function, before the \"Binary Cross-Entropy Loss\" module",
            "relative_position": "it follows the sequence of modules from the \"Embed\" up to the \"σ\" function and precedes the \"Binary Cross-Entropy Loss\" and \"Thresholding\" in the processing pipeline shown for the model architecture.\n\nSince the term 'Classification' is not specifically mentioned, my interpretation is based on the standard components of machine learning models as depicted in the image.",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.acl-long.89-Figure2-1.png": {
        "Task2 knowledge source": {
            "function": "to provide domain-specific information or data that supports the execution or processing of Task2.",
            "absolute_position": "bottom center",
            "relative_position": "below the \"Task2 passage encoder\" and to the left of \"Task2 passage index\"."
        },
        "Temporal entity": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/E99-1004-FigureI-1.png": {
        "Travel Expert": {
            "function": "to provide specialized knowledge or services related to travel.",
            "absolute_position": "it is the second module from the left in the set of modules that are directly connected to the 'Expert' module.",
            "relative_position": "it is between the 'Event Expert' and 'Place Expert' modules within the same hierarchy level."
        },
        "Context vector": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W18-5604-Figure2-1.png": {
        "Regression or Classification": {
            "function": "to determine the type of predictive modeling approach to be applied based on the nature of the output variable.",
            "absolute_position": "3rd in the sequence from top to bottom",
            "relative_position": "directly after 'Pre-processing' and before 'Summary'."
        },
        "Input speech recognizer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/J15-1003-Figure10-1.png": {
        "βthe": {
            "function": "",
            "absolute_position": "bottom left corner",
            "relative_position": "below the center of the image."
        },
        "Toponyms in context.": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P13-4021-Figure1-1.png": {
        "Explicit Sem. Analysis": {
            "function": "to analyze the semantic similarity between texts in an explicit manner as part of the text similarity measures within a text processing system.",
            "absolute_position": "bottom-right",
            "relative_position": "last in the \"Text Similarity Measures\" list."
        },
        "Maslow's needs": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.mtsummit-asltrw.2-Figure1-1.png": {
        "MT engineering": {
            "function": "",
            "absolute_position": "center",
            "relative_position": "between 'error handling' and 'consulting' modules, inside the 'PE soft skills'."
        },
        "Segment news Classify news Rank news": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D13-1094-Figure1-1.png": {
        "Arg2 (R1) Arg1 R2": {
            "function": "",
            "absolute_position": "center",
            "relative_position": "between 'Arg1 (R1)' on the left and 'Arg2 (R2)' on the right."
        },
        "Cluster=2": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/U04-1020-Figure6-1.png": {
        "Clause": {
            "function": "to represent the overall structure of a sentence that includes a subject noun phrase and a dominant verb phrase.",
            "absolute_position": "top-center",
            "relative_position": "above \"Dominant VP\"."
        },
        "Expert Knowledge (Triples T)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/E14-2005-Figure3-1.png": {
        "SCRDR tree": {
            "function": "",
            "absolute_position": "bottom center of the figure",
            "relative_position": "below 'Rule selector' and above 'Object-driven dictionary'."
        },
        "DISCOURSE CONTEXT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-5932-Figure1-1.png": {
        "Slot Span Prediction (Attention + Softmax)": {
            "function": "identifying the start and end positions of relevant information within a text passage using attention mechanism and probability distribution (softmax).",
            "absolute_position": "top-right",
            "relative_position": "to the left of the 'Slot Type Prediction (Dense + Softmax)' module and above the 'Dialog Embedding Vector'."
        },
        "Context Generator": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P08-1072-Figure4-1.png": {
        "LINKS": {
            "function": "to list the nodes that potentially follow the current node within an agenda graph, along with the probabilities of transitioning to each of those nodes.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Generation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.ecnlp-1.21-Figure4-1.png": {
        "Generate word vector using character embeddings": {
            "function": "to create a numerical representation of a word based on the individual characters that make up the word.",
            "absolute_position": "Bottom-right corner of the figure",
            "relative_position": "To the right of the decision point \"No.\""
        },
        "Generate a particle using BERT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.stoc-1.3-Figure3-1.png": {
        "LSTM": {
            "function": "to process sequential data and maintain long-term dependencies by using its self-recurrent connections.",
            "absolute_position": "second from the left in the series of LSTM modules.",
            "relative_position": "directly between the first LSTM on the left and the next LSTM on the right within the sequence shown."
        },
        "Analysis TL-dep.": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.ranlp-1.85-Figure3-1.png": {
        "Multi Layer Perceptron": {
            "function": "to transform the feature vector of each word in a sentence (W_i) into an output vector (O_i) through one or more layers of computation.",
            "absolute_position": "near the bottom center of the figure",
            "relative_position": "after the 'Word Level Encoding' module and before the output vector labeled 'Oi'."
        },
        "Software Agent": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P18-1229-Figure2-1.png": {
        "Path LSTM Encoder": {
            "function": "to encode the dependency paths between terms in a sentence using an LSTM (Long Short-Term Memory) network.",
            "absolute_position": "bottom center",
            "relative_position": "below the Average Pooling module and to the left of the Two-layer Feedforward Network module."
        },
        "sous la direction de": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P16-1052-Figure2-1.png": {
        "Definition_ Functionality": {
            "function": "",
            "absolute_position": "bottom center",
            "relative_position": "directly below the central dividing line."
        },
        "Lexicon- specificity": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C16-1133-Figure2-1.png": {
        "ensemble output": {
            "function": "to aggregate the outputs of individual expert systems (NMT systems) to produce a combined output.",
            "absolute_position": "top-center",
            "relative_position": "above the expert modules and to the right of the gating network."
        },
        "Schema N": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2010.iwslt-evaluation.18-Figure1-1.png": {
        "MERT tuning": {
            "function": "to optimize the parameters of a statistical machine translation system to improve its performance on a development set.",
            "absolute_position": "in the bottom right corner of the figure.",
            "relative_position": "to the right of both the \"Language model\" and the \"Translation model,\" and below the \"Development test\"."
        },
        "Transitive generator": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W16-5209-Figure2-1.png": {
        "Translator": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Source": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2001.tc-1.7-Figure8-1.png": {
        "Document Administration System": {
            "function": "managing and overseeing the documents within the system.",
            "absolute_position": "top left corner of the figure",
            "relative_position": "above the 'MT-GUI' and 'Translation Queue' modules within the 'Multi Framework' area."
        },
        "Label more words": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.acl-demo.10-Figure1-1.png": {
        "Linking to similar cases": {
            "function": "to identify and associate the current case with past cases that are similar.",
            "absolute_position": "second from the right, second from the top.",
            "relative_position": "to the right of 'Risk level prediction (Ensemble)' module and above the 'Similar cases' output."
        },
        "Sentence-Level Error": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.icon-main.47-Figure1-1.png": {
        "Training with MobileNetV2 + RNN": {
            "function": "to process and learn from the sequential data extracted from video frames to predict words using the combination of the MobileNetV2 architecture and Recurrent Neural Network (RNN).",
            "absolute_position": "bottom center",
            "relative_position": "between the \"Frame Sequence Generator with Data Augmentation\" and \"Predicted word\" steps in the workflow diagram."
        },
        "Cosine": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P16-2061-Figure1-1.png": {
        "Report Section": {
            "function": "",
            "absolute_position": "second from the top",
            "relative_position": "in the middle."
        },
        "Edges Generation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.paclic-1.72-Figure4-1.png": {
        "Hierarchical Co-Attention Model": {
            "function": "to jointly attend to both visual and textual inputs to generate a coherent output relevant to both modalities.",
            "absolute_position": "third from the left",
            "relative_position": "immediately after Preprocessing and before Output."
        },
        "AUTHOR": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-1909-Figure1-1.png": {
        "Sentence splitting": {
            "function": "to divide the text in the articles into individual sentences.",
            "absolute_position": "third from the left in the second row",
            "relative_position": "immediately following the 'Detect enumerations and abbreviations' module."
        },
        "Recognition Search": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/K19-2014-Figure4-1.png": {
        "self-attention 1": {
            "function": "to allow the model to weigh the importance of different parts of the input data differently and to enable each part of the input to interact with the rest.",
            "absolute_position": "inside the encoder layer, at the bottom.",
            "relative_position": "the first module within a series of self-attention modules in the encoder layer of the architecture."
        },
        "Transfer Database": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.ldl-1.6-Figure1-1.png": {
        "CoNLL Parser": {
            "function": "to parse documents and convert them to the CoNLL format.",
            "absolute_position": "right side, third from the top within the central column of modules.",
            "relative_position": "to the right of the 'XML Parser' and to the left of the 'Conversion to CoNLL' process."
        },
        "Conv1D Kernel:1": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2004.iwslt-evaluation.12-Figure1-1.png": {
        "Center controller": {
            "function": "",
            "absolute_position": "in the middle of the image",
            "relative_position": "centrally located among the other elements within the diagram, with connections to multiple other modules (Preprocessor, TBMT, IBMT, and SMT)."
        },
        "nose-picker": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W13-1502-Figure3-1.png": {
        "Topic Inferencer": {
            "function": "to determine the topics present in the data processed by the system.",
            "absolute_position": "bottom center",
            "relative_position": "directly above \"Model 1,\" \"Model 2,\" and \"Model 3.\""
        },
        "Post-processing Consistence Checking Taxonomy Adjustment": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D13-1062-Figure1-1.png": {
        "Z=f(x)": {
            "function": "",
            "absolute_position": "in the middle right of the figure",
            "relative_position": "between the \"TaggerPPD\" and \"Output: f(x)\" blocks, and to the right of both."
        },
        "UD treebanks": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2019.ccnlg-1.5-Figure5-1.png": {
        "Elements": {
            "function": "",
            "absolute_position": "bottom-center",
            "relative_position": "at the bottom of the left column."
        },
        "Observation/ Ethnography": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.naacl-main.65-Figure4-1.png": {
        "the group": {
            "function": "",
            "absolute_position": "left-center",
            "relative_position": "left of 'reach' and above 'a small shop'."
        },
        "Decoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C86-1061-Figure1-1.png": {
        "CONFLICT RESOLUTOR": {
            "function": "to resolve conflicts.",
            "absolute_position": "in the lower central part of the figure, below the \"MATCHER\" module and above the \"EXECUTOR\" module.",
            "relative_position": "central to the overall structure, acting as an intermediary between the \"MATCHER\" module and the \"EXECUTOR\" module."
        },
        "Translation Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-7540-Figure1-1.png": {
        "Acronym Expansion": {
            "function": "to expand acronyms into their full form.",
            "absolute_position": "center",
            "relative_position": "between the input and output sections."
        },
        "Similarity Feature Calculation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N18-4006-Figure1-1.png": {
        "Universal": {
            "function": "",
            "absolute_position": "bottom right corner of the figure",
            "relative_position": "inside the Stanford Dependency Contexts section."
        },
        "<V:K>": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2012.eamt-1.10-Figure5-1.png": {
        "tool.sh": {
            "function": "",
            "absolute_position": "bottom center",
            "relative_position": "center bottom."
        },
        "LSTM / BiLSTM": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P11-1108-Figure2-1.png": {
        "STOP": {
            "function": "",
            "absolute_position": "top-left",
            "relative_position": "above and to the left of the central module labeled 'O'."
        },
        "Linear Classifier": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D18-2024-Figure1-1.png": {
        "OpenKE": {
            "function": "to provide a framework for knowledge embedding with components for handling datasets, memory management, model settings, parameters, training strategies, and for performing training and evaluation of models.",
            "absolute_position": "on the right side of the image",
            "relative_position": "centered vertically within its side of the image."
        },
        "Diachronic Anchor Word Detection": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2013.iwslt-evaluation.6-Figure3-1.png": {
        "ROVER": {
            "function": "to combine the outputs of multiple automatic speech recognition systems to produce a better transcription, usually by voting or averaging.",
            "absolute_position": "at the bottom center of the figure.",
            "relative_position": "below the MMI, SGMM, and DNN modules and at the convergence point of the arrows coming from these modules."
        },
        "Transcripts": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.83-Figure1-1.png": {
        "ReGen": {
            "function": "bidirectional generation of text and graphs leveraging Reinforcement Learning.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Gen-LM": {
            "absolute_position": "in the lower center part of the figure",
            "relative_position": "between \"Automatic_construction_of_relevant_knowledge_bases\" and \"function.\"",
            "function": "\"Bidirectional generation of text and graphs leveraging Reinforcement Learning.\""
        }
    },
    "/data_share/data/acl_parse/figure/2022.findings-naacl.57-Figure1-1.png": {
        "Contextual Knowledge Retriever": {
            "function": "to select top-k triples using input-triple and input-relation similarity.",
            "absolute_position": "in the center left side of the figure",
            "relative_position": "below the 'NER Tagger' and above the step labeled with the number (5)."
        },
        "Contrastive Loss": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L18-1182-Figure2-1.png": {
        "timeseries matching": {
            "function": "to compare and align sequences of data points collected over time to identify similar patterns or trends within a dataset.",
            "absolute_position": "second column in the second box from the top",
            "relative_position": "first from the top within its group (Document Alignment)."
        },
        "doc2vec auto-encoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W02-1033-Figure1-1.png": {
        "Tile N-Grams": {
            "function": "to filter N-Grams.",
            "absolute_position": "bottom center",
            "relative_position": "below the \"Rewrite Query\" module and above the \"N-Best Answers\" list."
        },
        "Effectuation Part": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W06-2107-Figure2-1.png": {
        "intralocal": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Destination 1": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.semeval-1.99-Figure2-1.png": {
        "Humour Sub-Class classification": {
            "function": "to categorize different types of humor within content processed by the system.",
            "absolute_position": "on the bottom right of the figure",
            "relative_position": "at the end of the process flow, right before the final \"Output.\""
        },
        "Morph. analysis": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.acl-main.394-Figure1-1.png": {
        "BiLSTM": {
            "function": "to process sequential data in both forward and backward directions to capture past and future information.",
            "absolute_position": "bottom center of the figure, inside the dashed line box labeled \"Stacked BiLSTM Encoder\".",
            "relative_position": "below the attention module and to the left of the \"Auxiliary task Prediction\" block."
        },
        "Textual Entailment Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/I17-2042-Figure1-1.png": {
        "Embedding Layer": {
            "function": "to convert input data into a continuous, dense vector representation that can be processed by neural network layers.",
            "absolute_position": "bottom",
            "relative_position": "last/below all other layers."
        },
        "wielki 3'(jak)": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to map words into vectors of real numbers in a high-dimensional space where semantically similar words are mapped to points close to each other."
        }
    },
    "/data_share/data/acl_parse/figure/2021.eacl-main.166-Figure2-1.png": {
        "Multilingual entities": {
            "function": "to store or process entities in multiple languages after translation from English.",
            "absolute_position": "third from the left in the bottom row",
            "relative_position": "directly to the right of the 'machine translation' module."
        },
        "(b) Step2: Multilingual MT training with parallel data": {
            "absolute_position": "in the center of the image",
            "relative_position": "between the \"machine translation\" box on the left and the \"Wikipedia article\" box on the right.",
            "function": "to train machine translation models using parallel data."
        }
    },
    "/data_share/data/acl_parse/figure/2022.repl4nlp-1.16-Figure1-1.png": {
        "Original Samples": {
            "function": "to provide the initial data that is used in the various steps of the construction process, such as training the classifier, generating text attacks, creating explanations, and training the adversarial detector.",
            "absolute_position": "on the right side of the figure, in part (b) labeled \"Construction Steps.\"",
            "relative_position": "second from the top within the sequence of four modules in the \"Construction Steps\" section."
        },
        "ChexBERT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.semeval-1.15-Figure1-1.png": {
        "Classification": {
            "function": "to determine whether the inputs have the same meaning or different meanings.",
            "absolute_position": "top center",
            "relative_position": "above the central diagram and arrows."
        },
        "Lexi Base Heuristic Rule Base": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/O12-2001-Figure1-1.png": {
        "Generate: 5-letter code (toneless) Code-to-item index": {
            "function": "to generate a 5-letter code without tone and to index code to item.",
            "absolute_position": "on the top left side of the figure",
            "relative_position": "directly above the \"Romanization input: 5-letter code (toneless)\" module and to the left of the \"Extract full entry\" module."
        },
        "Finding and Discussing Conflicts": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S17-2058-Figure1-1.png": {
        "Permutation probability loss": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "SenseN": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-main.37-Figure6-1.png": {
        "Table Title: Casper Elgaard": {
            "function": "to display the racing career summary of Casper Elgaard, including years, teams, co-drivers, cars, classes, number of laps, finishing positions, and class positions.",
            "absolute_position": "top left",
            "relative_position": "first row, spanning multiple columns in the table header."
        },
        "(b) 1st Stage": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.findings-emnlp.354-Figure3-1.png": {
        "Multi-View Queries": {
            "function": "to enhance the query representation by incorporating different perspectives such as dialogue history, relevant passages, and reformulated queries using GPT-2.",
            "absolute_position": "the bottom-most module on the left side of the figure",
            "relative_position": "directly below the 'Question Reformulation using GPT-2' module inside the 'Question Expansion using Dialog History' box."
        },
        "Realisation of Media Objects": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S18-1055-Figure1-1.png": {
        "Sentiment Lexicon": {
            "function": "to provide a list of words associated with their sentiment values, used for determining the sentiment expressed in the text.",
            "absolute_position": "top-left",
            "relative_position": "inside the 'Feature Extraction' component, to the left."
        },
        "Parser": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Q18-1031-Figure1-1.png": {
        "The food here is ok but not worth the price .": {
            "function": "to serve as a prototype sentence for text generation.",
            "absolute_position": "lower center",
            "relative_position": "center."
        },
        "tyagaragahasa...6.1.216": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P19-1560-Figure3-1.png": {
        "Recog Network": {
            "function": "to infer the latent representation z from the input data x.",
            "absolute_position": "top-left",
            "relative_position": "above the \"Explanations Encoder\" and to the left of the \"Prior Network\"."
        },
        "LAYER (h+1) CLASSIFIER": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W11-2033-Figure3-1.png": {
        "Top policy (finite-state)": {
            "function": "to manage the high-level decision making in a system.",
            "absolute_position": "top-center",
            "relative_position": "above the 'Bottom policy (POMDP)' module."
        },
        "Quotation Encoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W08-2114-Figure1-1.png": {
        "context selectors": {
            "function": "to calculate the relatedness of target selectors with context selectors in the process of ranking noun senses.",
            "absolute_position": "on the right side of the figure, within the lower half.",
            "relative_position": "in the bottom-center of the right-hand side module labeled \"Rank Senses.\""
        },
        "Text Normalization": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W16-4311-Figure1-1.png": {
        "Storage": {
            "function": "to store data gathered from the Twitter crawling process for subsequent personality and linguistic analysis.",
            "absolute_position": "in the bottom center of the figure.",
            "relative_position": "below the \"Twitter\" module and to the left of the \"Personality analysis\" and \"Linguistic analysis\" modules, within the dashed-line boundary that possibly represents a system or process flow."
        },
        "Selection des attributs": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W04-0911-Figure1-1.png": {
        "OMEGA": {
            "function": "to act as a mathematical proof assistant.",
            "absolute_position": "bottom right corner of the figure",
            "relative_position": "within the \"Mathematical Proof Assistant\" section, to the right of \"Mathematical Knowledge Base (MBASE)\" and below the \"Dialog Manager\" section."
        },
        "Common features": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.osact-1.1-Figure2-1.png": {
        "Correctly Classified": {
            "function": "to determine which instances from the test set were accurately predicted by the model.",
            "absolute_position": "bottom center",
            "relative_position": "below \"Compare\" and above \"Re-train\"."
        },
        "Dictionary": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W11-3708-Figure4-1.png": {
        "language Y": {
            "function": "sentence filtering.",
            "absolute_position": "In the bottom left corner of the figure, right above the legend.",
            "relative_position": "It is the last module in the vertical process sequence depicted in the figure."
        },
        "WordAligner": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.fnp-1.18-Figure1-1.png": {
        "Produced summary": {
            "function": "to generate a condensed version of the original document, capturing the most important information.",
            "absolute_position": "bottom-right",
            "relative_position": "below the 'Abstraction using T-5' module and to the right of the 'Ground truth summary' module."
        },
        "linguistic deduction": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-5926-Figure1-1.png": {
        "A person is packing a bag and then looking into the mirror.": {
            "function": "to provide a summary of the actions being performed by the person in the video.",
            "absolute_position": "second row, first column",
            "relative_position": "top left."
        },
        "Transition": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W02-0507-Figure2-1.png": {
        "Paragraph Table": {
            "function": "to store data about individual paragraphs, including a unique identifier, the document they belong to, and the paragraph text itself.",
            "absolute_position": "Bottom-left corner",
            "relative_position": "Between the Document Table and Posting Table."
        },
        "yeoseong(female)/NNIN": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W16-0805-Figure2-1.png": {
        "Green": {
            "function": "",
            "absolute_position": "bottom right corner",
            "relative_position": "below Blue, to the right of Red."
        },
        "Grouping by query terms": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P19-1223-Figure2-1.png": {
        "Input self attention layer": {
            "function": "to focus on different parts of the input data by assigning different weights to various sections of the data in order to help the model better understand the relationships within the input.",
            "absolute_position": "in the lower center of the image, within the Entailment Module.",
            "relative_position": "after the 'Entailment scorer' and before the 'Decision classifier'."
        },
        "U6:It is great.": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N10-1135-Figure1-1.png": {
        "bilingual vector space": {
            "function": "to map semantically similar words or phrases from different languages into a shared vector space for cross-linguistic alignment.",
            "absolute_position": "center-bottom of the figure",
            "relative_position": "between the \"German triple\" on the left and the \"English triple\" on the right."
        },
        "Emotion Template Matching": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y10-1027-Figure1-1.png": {
        "Candidate Event type & Trigger clusters": {
            "function": "to identify and group potential event types and their associated triggers from the data.",
            "absolute_position": "the third row from the top, first column from the left",
            "relative_position": "directly below \"Event Trigger Clustering\" and to the left of \"Event Cluster Ranking.\""
        },
        "Context Encoder (BERT)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W14-0617-Figure2-1.png": {
        "4 NER for attestations, etymology etc": {
            "function": "Named Entity Recognition for attestations, etymology, etc.",
            "absolute_position": "4",
            "relative_position": "After '3 Finer-grained structure mark-up' and before '5 Grounding, etymology linking'."
        },
        "What color is the grass?": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/K18-1019-Figure1-1.png": {
        "GAN2": {
            "function": "to provide rewards to the Generator G' based on the performance of generated samples as evaluated by the Discriminator D'.",
            "absolute_position": "right side of the figure",
            "relative_position": "top-right in the figure."
        },
        "Masked LM": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.globalex-1.18-Figure4-1.png": {
        "Lexicon P'": {
            "function": "",
            "absolute_position": "the bottom center of the figure.",
            "relative_position": "below Lexicon A and Lexicon P, and to the left of Lexicon B."
        },
        "Rules applied on text": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W06-3303-Figure3-1.png": {
        "metabolism": {
            "function": "to represent the set of life-sustaining chemical reactions in organisms.",
            "absolute_position": "in the center of the figure, slightly toward the bottom right.",
            "relative_position": "between \"homeostasis\" on the left and \"metabolic process\" on the right; it is also directly below \"physiological process\"."
        },
        "Content Presentation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N15-3005-Figure1-1.png": {
        "Entity Detection": {
            "function": "to identify and categorize entities within text into predefined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc.",
            "absolute_position": "bottom right corner",
            "relative_position": "below the NLP Component and to the right within the Relation Extraction box."
        },
        "j-to-e": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C18-1305-Figure1-1.png": {
        "Argmax": {
            "function": "to select the argument (e.g., index of an array) that gives the maximum value of a function or array of numbers.",
            "absolute_position": "near the top center, slightly to the right.",
            "relative_position": "in the sequence of operations after the 'Sample' module and before the output of the second 'Decoder Stacks'."
        },
        "Training Corpus": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-1508-Figure2-1.png": {
        "Symptom Recognition": {
            "function": "to identify and extract symptoms from the input data using machine learning models, likely including a Bi-LSTM (Bidirectional Long Short-Term Memory) network and a CRF (Conditional Random Field) layer for sequence tagging.",
            "absolute_position": "",
            "relative_position": ""
        },
        "sytactic tree of h": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.emnlp-main.131-Figure1-1.png": {
        "Rory Gates": {
            "function": "",
            "absolute_position": "in the upper right quadrant of part (a) of the figure.",
            "relative_position": "to the right of 'Bill Gates' and below 'Melinda Gates' within the conceptual map."
        },
        "Word_x": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.semeval-1.261-Figure1-1.png": {
        "HIERARCHICAL ATTENTION MODULE": {
            "function": "to focus on different parts of the input text data (i.e., tweet) when processing it to understand its hierarchical structure for better representation before passing it to the subsequent layers for classification.",
            "absolute_position": "in the middle of the figure, horizontally centered.",
            "relative_position": "after the 'GLOVE EMBEDDINGS' block and before the 'Task-specific FC layers,' it is placed as the intermediary processing module between the input and the final output layers."
        },
        "What do you think about the ostrich, where should that card be?": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S17-2044-Figure1-1.png": {
        "Arabic and English Medical Terminology": {
            "function": "to provide a bilingual medical terminology resource as part of the preliminary step in a text processing or classification system.",
            "absolute_position": "top right of the figure",
            "relative_position": "at the beginning of the flow chart, to the right of the \"Preliminary step\" and above the other modules connected to it."
        },
        "LTP": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N18-2071-Figure4-1.png": {
        "CNN": {
            "function": "to extract visual features from the input sub-images for further processing.",
            "absolute_position": "in the lower central part of the figure, inside the Bidirectional Attention box.",
            "relative_position": "after the first FC (fully connected layer) and Attention block, and before the second MAX operation within the Bidirectional Attention box."
        },
        "sense inventory": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2005.sigdial-1.11-Figure2-1.png": {
        "PARADISE User Satisfaction": {
            "function": "",
            "absolute_position": "top-center",
            "relative_position": "above all other modules."
        },
        "Communism": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.conll-shared.2-Figure2-1.png": {
        "e2": {
            "function": "",
            "absolute_position": "bottom right",
            "relative_position": "second from the bottom, farthest right."
        },
        "Emotion Classification": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.emnlp-main.445-Figure3-1.png": {
        "Indexing": {
            "function": "to select and retrieve data from a dataset or database according to specified criteria or keys.",
            "absolute_position": "",
            "relative_position": ""
        },
        "CONVENTIONAL": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P18-1129-Figure1-1.png": {
        "Exploration policy": {
            "function": "to determine how to choose new actions or strategies to gather more diverse or informative data for training purposes.",
            "absolute_position": "the lower right quadrant of the figure",
            "relative_position": "below the \"Distillation loss\" and to the right of \"Training data\"."
        },
        "Attention network": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.acl-short.7-Figure1-1.png": {
        "Positive Sentiment": {
            "function": "to identify or generate sentences that convey a positive sentiment regarding the subject.",
            "absolute_position": "the bottom module",
            "relative_position": "the last module."
        },
        "EquityUnderweight": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.isa-1.5-Figure1-1.png": {
        "ABS": {
            "function": "",
            "absolute_position": "in the top center of the figure, within the green rectangle.",
            "relative_position": "above the \"Annotation Structures\" and to the left of the \"Model with PREDs defined Higher-order logic.\""
        },
        "10285313": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.sustainlp-1.6-Figure1-1.png": {
        "SpaceX": {
            "function": "token prediction.",
            "absolute_position": "in the center, at the top",
            "relative_position": "the second module from the left."
        },
        "Bluefly.com Designer- Trench-Coats": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-4110-Figure1-1.png": {
        "message from user": {
            "function": "to receive and provide the initial input for the system to process.",
            "absolute_position": "at the top-center of the figure",
            "relative_position": "above all other modules and elements in the flowchart."
        },
        "Form/Lemma": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.blackboxnlp-1.3-Figure3-1.png": {
        "explanation-first GPT-2": {
            "function": "generating explanations for predictions made by a model before the model's final predictions are determined through majority voting.",
            "absolute_position": "top-right",
            "relative_position": "above the \"majority voting\" block and to the right of \"model 1\" through \"model 3\" blocks."
        },
        "det": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-1235-Figure4-1.png": {
        "Attention Scores (AE)": {
            "function": "to calculate the importance weights of different aspects in a text for sentiment analysis.",
            "absolute_position": "top right",
            "relative_position": "above the Sentiment Scores (Sβ) and to the right side of the diagram."
        },
        "Adversarial model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.starsem-1.3-Figure1-1.png": {
        "Contradiction": {
            "function": "to identify inconsistencies between two statements.",
            "absolute_position": "in the lower right-hand side of the diagram",
            "relative_position": "below the \"Proving\" and \"Neutral\" modules and to the right of the \"Abduction\" module."
        },
        "RAINBOW": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P99-1050-Figure2-1.png": {
        "Information extractor": {
            "function": "to extract structured information from a lemmatized and tagged corpus using a database of lexico-syntactic patterns.",
            "absolute_position": "in the middle-right side of the figure",
            "relative_position": "directly following the 'Shallow parser + classifier' module and preceding the 'Lexico-syntactic patterns' module."
        },
        "Multi-Stream Transformer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.148-Figure1-1.png": {
        "KGI": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Initial class": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to generate structured knowledge from textual evidence."
        }
    },
    "/data_share/data/acl_parse/figure/W15-4609-Figure4-1.png": {
        "NarrativeRole": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "DOMAIN ADAPTATION": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-short.56-Figure1-1.png": {
        "Agent": {
            "function": "",
            "absolute_position": "Bottom center of the figure, within the lower part of the red dashed box.",
            "relative_position": "To the right of the \"o_t\" element and to the left of the connection leading to the \"Environment\" module."
        },
        "Morphological and Syntax Analyzer + Structural Pattern Recognition Modules": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-long.7-Figure1-1.png": {
        "Target-aware prototypical graph CL": {
            "function": "contrastive learning using a graph structure to pull similar target-aware prototypes (positive samples) closer together and push dissimilar ones (negative samples) further apart.",
            "absolute_position": "top center",
            "relative_position": "above the 'Classifier' and to the right of the 'Prototypes Generation.'"
        },
        "Encoder": {
            "function": "to transform the input data from the training set into hidden vectors that can be used for further processing in the model.",
            "absolute_position": "on the bottom left corner of the figure",
            "relative_position": "below the \"Hidden vectors\" and to the left of the \"Mini-batch\" module."
        },
        "Question Review & Paraphrase": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        },
        "BOS": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-main.371-Figure1-1.png": {
        "Co-attention Encoder": {
            "function": "",
            "absolute_position": "in the center of the figure, just above the bottom edge.",
            "relative_position": "below the LSTM layers and above the XLM-R Encoder layer, in the middle of the architecture diagram."
        },
        "Src. ASR": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.acl-main.187-Figure3-1.png": {
        "Template": {
            "function": "to serve as a placeholder for constructing SQL queries, where users can substitute actual column names and table names into the template to form a complete SQL statement.",
            "absolute_position": "in the middle of the figure",
            "relative_position": "above the \"Explanation\" section and below the first SQL query code block."
        },
        "occ-time(S,T)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C94-1047-Figure3-1.png": {
        "Finite State Machine (FSM) formalism": {
            "function": "compression.",
            "absolute_position": "center",
            "relative_position": "between \"Full surface forms\" and \"Physical Logical Compression\"."
        },
        "Integration into the ontology": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P19-1340-Figure1-1.png": {
        "Self-Attention (75M)": {
            "function": "to compute the representation of each token by aggregating information from all tokens proportionally to their relevance.",
            "absolute_position": "third from the left",
            "relative_position": "in the middle."
        },
        "[CLS] paragraph[SEP]]": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.semeval-1.253-Figure2-1.png": {
        "Class prediction": {
            "function": "to output the category to which a given tweet text belongs, based on the features extracted and learned through the preceding text preprocessing, embedding, and classification steps in the machine learning or deep learning model pipeline.",
            "absolute_position": "bottom center",
            "relative_position": "below the \"Classification(ML/DL)\" module."
        },
        "Compute the relationship between sentences": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P92-1007-Figure7-1.png": {
        "entry-point functional syntactic features features": {
            "function": "to serve as the starting point for the traversal of the functional network and the TAG (Tree Adjoining Grammar) network in order to select a tree based on functional and syntactic features.",
            "absolute_position": "it is located toward the bottom center of the figure, within a larger dashed box labeled \"subregion r_2\".",
            "relative_position": "it is below another module labeled \"entry-point,\" \"functional features,\" and \"syntactic features,\" which is within a similarly structured dashed box labeled \"region r_1\". It is connected to two processes or modules to its right labeled \"traversal of the functional network\" and \"traversal of the TAG network,\" each leading to another module labeled \"tree selected.\""
        },
        "knowledge representation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N16-1045-Figure3-1.png": {
        "c_int": {
            "function": "to integrate the current input and the previous hidden state to update the cell state in an LSTM memory block.",
            "absolute_position": "the center of the image",
            "relative_position": "at the core of the LSTM (Long Short-Term Memory) memory block diagram, between the input, forget, and output gates."
        },
        "Manual Annotation and Feedback": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.naacl-main.13-Figure1-1.png": {
        "What is the intended use of my dataset?": {
            "function": "to determine the purpose for which the dataset was created.",
            "absolute_position": "top",
            "relative_position": "first."
        },
        "Expert Lexicons": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-srw.19-Figure2-1.png": {
        "Transformers m-BERT Bangla-BERT XLM-R": {
            "function": "to use transformer-based models such as multilingual BERT (m-BERT), Bangla-BERT, and XLM-R for processing input texts to produce output predictions.",
            "absolute_position": "top-right",
            "relative_position": "third from the left on the top row of modules."
        },
        "The Little Prince English-AMR": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.acl-long.43-Figure4-1.png": {
        "distributed alignment": {
            "function": "to analyze and correlate different parts of an image with relevant textual descriptions, aligning them in a distributed way for cross-modal interpretation.",
            "absolute_position": "top-right corner of the figure",
            "relative_position": "between the central module (\"visual self-attention\") and the rightmost module (\"visual self-attention from cross-modal view\")."
        },
        "Manual Features": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D18-1201-Figure1-1.png": {
        "tabby": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Affect- Cognition- Sociolinguistics (ACS)-based Sarcasm Feature Model &Analyzer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.acl-main.106-Figure2-1.png": {
        "This is a supernice superminecraft game. I love the nicesque affirmation of minecraftesque.": {
            "function": "",
            "absolute_position": "left-most part of the figure",
            "relative_position": "first item from the left in the sequence of elements presented in the figure."
        },
        "MSE": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-1629-Figure6-1.png": {
        "opposite change out-of-para": {
            "function": "",
            "absolute_position": "top-right corner of the figure",
            "relative_position": "between \"change out-of-para\" and \"opposite change in-para.\""
        },
        "DATA OF SOURCE SPEAKER": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D18-1248-Figure4-1.png": {
        "sentence encoder": {
            "function": "to convert a sequence of words into a sentence embedding.",
            "absolute_position": "in the bottom center of the figure.",
            "relative_position": "directly below the \"sentence embedding\" vector and above the words and \"type\" annotations, positioned centrally in the figure."
        },
        "Reverse Seq2Seq Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P17-1021-Figure2-1.png": {
        "KB Embedding Matrix Ek": {
            "function": "to provide a representation of knowledge base entities for integration into the model's attention mechanism.",
            "absolute_position": "bottom right corner",
            "relative_position": "below the A-Q Attention Model and to the right of the Word Embedding Matrix Ew."
        },
        "Cheese?": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N07-1059-Figure3-1.png": {
        "KV Extraction": {
            "function": "to extract key-value pairs from the inputs provided to it, which appear to be processed by language understanding and language generation components.",
            "absolute_position": "on the right side of the figure.",
            "relative_position": "after the 'Language Generation' module and before the 'Key–Value Comparator' module."
        },
        "ES JSON": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W12-2423-Figure1-1.png": {
        "Huber Classifier": {
            "function": "to classify data using the Huber loss function, which is less sensitive to outliers in data than traditional squared error loss.",
            "absolute_position": "on the right side of the figure",
            "relative_position": "to the right of the 'Priority Model' and 'Semantic Model' boxes, and it is one of the last elements in the processing pipeline before reaching 'Sentence Scores'."
        },
        "comida": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S13-2083-Figure1-1.png": {
        "Preprocess": {
            "function": "to clean and prepare the input data (tweets) for further processing and analysis.",
            "absolute_position": "second from the top in the central vertical line of modules.",
            "relative_position": "directly below the 'Tweets' module and above the 'Coarse-WSD' module."
        },
        "Evaluations": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C14-1042-Figure1-1.png": {
        "SMT Decoding": {
            "function": "to translate the input text from one language to another using statistical methods.",
            "absolute_position": "6th from the top",
            "relative_position": "directly below \"Name Classing\" and above \"NAME/OOV Transliteration,\" within the \"Post-processing\" stage."
        },
        "Language Detection Module": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.jeptalnrecital-taln.14-Figure1-1.png": {
        "(B) Regression multi-taches": {
            "function": "performing multiple tasks, which likely include predicting age group as well as determining a class such as whether an individual is an adult or a child.",
            "absolute_position": "top right",
            "relative_position": "second from the top or second in a vertical set of four modules."
        },
        "<W, CMLE> or <W,CMLN>": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.71-Figure2-1.png": {
        "SVD": {
            "function": "dimensionality reduction or feature extraction from the conceptual information provided by ConceptNet.",
            "absolute_position": "in the lower center part of the figure",
            "relative_position": "between the conceptual information from ConceptNet on the left and the Integration Network on the right."
        },
        "LM": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-8667-Figure2-1.png": {
        "QDG Algorithm": {
            "function": "to generate quantified expressions based on the input from the Pre-processor using the Common Knowledge Base.",
            "absolute_position": "in the center of the figure, slightly to the right.",
            "relative_position": "to the right of the \"Pre-processor\" and to the left of the \"Realiser\"."
        },
        "Exploration": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.ijclclp-1.0-Figure6-1.png": {
        "Is it a coniunctiye adverbial?": {
            "function": "to determine whether a given element in a sentence is a conjunctive adverbial.",
            "absolute_position": "top-center of the flowchart",
            "relative_position": "the first module/question."
        },
        "Lexicalized HMMs": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-acl.176-Figure3-1.png": {
        "Hellstorm": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Graph Encoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/1996.amta-1.38-Figure1-1.png": {
        "Glossary Transfer": {
            "function": "transferring lexical information from the source language to the target language in a machine translation process.",
            "absolute_position": "at the top center of the figure",
            "relative_position": "between the \"Analyzed Source Tree\" on the left and the \"Partial Target Tree\" on the right."
        },
        "Concatenate generated token to the Generated Reason": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-main.26-Figure1-1.png": {
        "Graph Representation Learning": {
            "function": "to convert the information from the Taxonomy Graph into a useful numerical format that can be processed by machine learning models.",
            "absolute_position": "top center",
            "relative_position": "to the right of the 'Taxonomy Graph' and to the left of the classifiers represented by 'RF', 'MLP', and 'BNN'."
        },
        "hes": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W15-2704-Figure5-1.png": {
        "PROSODIC MODULE RECURSIVE COMPUTATION ANALOGICAL PARAMETERS FROM PROSODIC RULES TRIGGEREDBY INPUT INFORMATION": {
            "function": "to perform recursive computation on analogical parameters derived from prosodic rules, which are activated by input information.",
            "absolute_position": "it is the central module in the bottom row of modules.",
            "relative_position": "it is directly below the \"TOP LEVEL PM\" module and to the left of the \"TEXT-TO-SPEECH READER\" module."
        },
        "Statistics": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.naacl-main.218-Figure2-1.png": {
        "Multi-head Self Attention": {
            "function": "to process token representations through multiple attention mechanisms in parallel to capture various contextual relationships within the input data.",
            "absolute_position": "",
            "relative_position": ""
        },
        "10:": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.sigdial-1.37-Figure4-1.png": {
        "DST": {
            "function": "Dialog State Tracking.",
            "absolute_position": "in the center on the right side of the figure",
            "relative_position": "below the \"Dialog Act\" module and to the right of the \"State\" module."
        },
        "Slot Value Predictor": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-acl.43-Figure2-1.png": {
        "Objective Function": {
            "function": "to evaluate the performance of a model or algorithm by mathematically summarizing the difference between predicted values and actual values.",
            "absolute_position": "top right corner of the figure",
            "relative_position": "above the \"Weighted Vector\" and to the right of the \"Vector Reconstruction\"."
        },
        "Transformer Layer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D18-1428-Figure1-1.png": {
        "average": {
            "function": "to calculate the mean value of the inputs it receives.",
            "absolute_position": "top-center",
            "relative_position": "above the dashed arrows and the grey boxes, centered horizontally with respect to the diagram."
        },
        "n-best list based. ensemble learning": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W15-5119-Figure3-1.png": {
        "Synset 07064715": {
            "function": "",
            "absolute_position": "bottom right corner",
            "relative_position": "below and to the right of the 'Synset 14696793' module."
        },
        "BAKED-FOOD": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W14-4710-Figure2-1.png": {
        "Candidates": {
            "function": "",
            "absolute_position": "Second from the top, on the right",
            "relative_position": "To the right of the 'Candidate criteria' module and above the 'seeds' input to a subsequent operation."
        },
        "Session-level Item Embeddings": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W16-4620-Figure1-1.png": {
        "The design and characters of the circuit were explained": {
            "function": "to serve as the target sentence for a machine translation model to identify and parse for training purposes.",
            "absolute_position": "top-left",
            "relative_position": "above and to the left of the main diagram."
        },
        "MODELLING AND INFERENCE (computer scientists)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-6013-Figure4-1.png": {
        "Commonsense Knowledge Base": {
            "function": "the extraction of causal relations between action verbs and result verbs.",
            "absolute_position": "top-right corner of the figure",
            "relative_position": "to the right of the main flowchart and above the 'Web-search using template (Vr+NP) by (Va+*)' module."
        },
        "Target Sentence": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W95-0101-Figure4-1.png": {
        "SUPERVISED LEARNER": {
            "function": "to learn from labeled data to make predictions or decisions.",
            "absolute_position": "bottom right quadrant of the figure.",
            "relative_position": "below \"SUPERVISED TRANSFORMATIONS\" and to the right of \"MANUALLY TAGGED TEXT\"."
        },
        "Top policy (finite-state)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S15-2150-Figure3-1.png": {
        "Spatial Relation Classification and Argument Labeling": {
            "function": "to determine the types of spatial relations and assign roles to entities involved in those relations.",
            "absolute_position": "in the center of the figure",
            "relative_position": "between the 'Candidate Tuple Generation' process on the left and a list of spatial relations on the right."
        },
        "Credibility (intormation sources)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-2307-Figure1-1.png": {
        "Lucene Indexer": {
            "function": "indexing documents for efficient search and retrieval.",
            "absolute_position": "the top center",
            "relative_position": "between the \"Document list\" and \"Medline Documents\" components on the diagram."
        },
        "NMT L1->R2": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W07-0312-Figure1-1.png": {
        "Language Understanding": {
            "function": "to interpret and understand the meaning of spoken or written language input.",
            "absolute_position": "",
            "relative_position": ""
        },
        "AT&T WATSON SPEECH PLATFORM": {
            "absolute_position": "top right",
            "relative_position": "to the right of 'Speech Recognition' and above 'Language Generation'.",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.reinact-1.3-Figure4-1.png": {
        "Colour": {
            "function": "to represent the attribute of a fruit concerning its color.",
            "absolute_position": "lower right",
            "relative_position": "to the right of \"Shape\" and below \"Fruit\"."
        },
        "Port cities": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-main.206-Figure1-1.png": {
        "text-to- subdomain classification": {
            "function": "to classify text into one of the previously identified subdomains based on its contents.",
            "absolute_position": "near the top right corner within the Inference phase.",
            "relative_position": "to the right of the Topic mixture (TM) inference module and above the Fine-tuned subdomain #k model."
        },
        "What colors do the school whereDonald Stanley Marshall is grad student use?": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W11-0121-Figure1-1.png": {
        "enter-S1.2": {
            "function": "to register formally as a participant or member.",
            "absolute_position": "top right corner",
            "relative_position": "to the right of \"enter-S1.1\" and above \"enter-S2.\""
        },
        "Candidates embeddings": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.ecnlp-1.8-Figure2-1.png": {
        "Writer": {
            "function": "",
            "absolute_position": "center left",
            "relative_position": "between the 'KimCNN' and 'Message' modules."
        },
        "Document database": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.fever-1.5-Figure1-1.png": {
        "Imagined Evidence": {
            "function": "to generate or hypothesize evidence that may be used in the next step of reasoning or information retrieval in the system's process.",
            "absolute_position": "in the center towards the bottom of the figure",
            "relative_position": "below the \"Predicted Label\" module and above the \"Hop n+1\" level, central among the components at the bottom portion of the figure."
        },
        "Fruit": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.628-Figure1-1.png": {
        "Feature Extractor": {
            "function": "to extract relevant features from input data that are then used for further classification tasks.",
            "absolute_position": "on the left side of the figure",
            "relative_position": "upstream of both the 'Target Classifier' and the 'Attacker Classifier', and to the left of the 'Gradient Reversal' module."
        },
        "GEF Environment @ SfS": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W11-3301-Figure2-1.png": {
        "TextualDescription": {
            "function": "described by FeatureStructure.",
            "absolute_position": "lower-right corner.",
            "relative_position": "below the \"FeatureStructure\" module to the right."
        },
        "Classification model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D08-1009-Figure2-1.png": {
        "calcium helps prevent osteoporosis (TextRunner : 0.68)": {
            "function": "to indicate the relationship between calcium and osteoporosis prevention with an associated confidence score derived from TextRunner.",
            "absolute_position": "in the right-center part of the image.",
            "relative_position": "in the bottom right corner of the right-hand side cluster related to broccoli."
        },
        "Test Set": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-main.380-Figure3-1.png": {
        "Democrats": {
            "function": "to represent the political party, the Democrats, and their anticipated performance in maintaining legislative seats during elections.",
            "absolute_position": "bottom left in panel (b) Graph overview",
            "relative_position": "to the left and below the 'Republicans' module."
        },
        "hit": {
            "absolute_position": "in the bottom left quadrant of the graph overview",
            "relative_position": "below and slightly to the left of the center of the image.",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C10-2047-Figure2-1.png": {
        "Hatoyama Kunio33-no": {
            "function": "",
            "absolute_position": "second from the top on the right side.",
            "relative_position": "to the right of the \"Hatoyama Yukio^32-wa\" module and above the \"Minshuto^3-no\" module."
        },
        "Score-frontier": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W02-2204-Figure1-1.png": {
        "Structural sentence": {
            "function": "",
            "absolute_position": "on the left side of the image, approximately in the center.",
            "relative_position": "within the larger red profile outline (which resembles a human head outline), towards the bottom center of this profile."
        },
        "Al-Qaeda": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W12-1102-Figure1-1.png": {
        "linguistic patterns": {
            "function": "to identify and extract structured information from unstructured text based on predefined or learned patterns in the language.",
            "absolute_position": "bottom center of the figure",
            "relative_position": "below the module labeled \"n-grams\" and above the module labeled \"multiword expressions\"."
        },
        "BERT embeddings": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.naacl-main.405-Figure1-1.png": {
        "DogeCoin": {
            "function": "to indicate the subject or topic related to the tweets highlighted in the diagram, which in this case is Dogecoin.",
            "absolute_position": "",
            "relative_position": ""
        },
        "dependencies (object properties)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.acl-main.87-Figure2-1.png": {
        "Translator": {
            "function": "to translate text from one language to another.",
            "absolute_position": "in the center, at the top of the image.",
            "relative_position": "between the \"Source QP pair\" on the left and the \"Translated QP pair\" on the right."
        },
        "learn phrases": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-5515-Figure1-1.png": {
        "PARATAXIS": {
            "function": "",
            "absolute_position": "top-right",
            "relative_position": "to the right of the ROOT module."
        },
        "Bi-LSTMs": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/M95-1018-Figure1-1.png": {
        "NameTag SGML Text": {
            "function": "processing the output from the NameTag module and converting it into SGML (Standard Generalized Markup Language) format text.",
            "absolute_position": "second from the left",
            "relative_position": "immediately to the right of the \"NameTag\" module."
        },
        "Key": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L18-1694-Figure1-1.png": {
        "Feminine Singular rule : remove1 add -a": {
            "function": "to transform a masculine singular word into its feminine singular form by removing the last character and adding \"-a\".",
            "absolute_position": "bottom center",
            "relative_position": "below the \"Feminine Singular: bella\" module and to the right of the \"LEMMA bello\" module."
        },
        "Knowledge base construction": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.ltedi-1.26-Figure1-1.png": {
        "Predictions": {
            "function": "to output the results generated by the machine learning model after processing the test data.",
            "absolute_position": "at the bottom of the flowchart",
            "relative_position": "below the \"Albert Base V1\" module."
        },
        "HAL Vector of the Ambiguous word": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-long.224-Figure2-1.png": {
        "Constrained Decoding": {
            "function": "to generate candidate final responses for each snippet of knowledge, ensuring they adhere to constraints while maintaining language model fluency and knowledge fidelity.",
            "absolute_position": "the third module from the left",
            "relative_position": "after 'Knowledge Selection' and before 'Ranking'."
        },
        "Relationship Discovery": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P09-1066-Figure1-1.png": {
        "Source sentence": {
            "function": "to provide the input text that the decoders will translate or process.",
            "absolute_position": "Bottom center of the figure",
            "relative_position": "Directly below the \"decoder1\" and \"decoder2\" modules within the dashed outline."
        },
        "Jacob": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D08-1008-Figure2-1.png": {
        "Semantic pipeline": {
            "function": "to perform sense disambiguation, argument identification, and argument labeling as part of natural language processing.",
            "absolute_position": "at the center left of the image",
            "relative_position": "following the \"Syntactic dependency parsing\" block and preceding the \"Global semantic model\" block."
        },
        "Polarity Marker": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.eacl-srw.23-Figure1-1.png": {
        "FC": {
            "function": "",
            "absolute_position": "bottom left corner of the diagram.",
            "relative_position": "to the left side of the \"Generator(LSTM)\" module and directly under the \"Prior Dist.\" text label."
        },
        "Error": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-4007-Figure3-1.png": {
        "Trained Model(Weighted Phoneme Chunks)": {
            "function": "",
            "absolute_position": "at the bottom center of the figure",
            "relative_position": "directly below the 'Constituent phoneme chunks' module and above the 'Ranked Bhojpuri Transductions' module."
        },
        "Clubs and Organizations": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P93-1023-Figure1-1.png": {
        "COMBINE SIMILARITIES": {
            "function": "to aggregate or merge the similarity data or outputs from multiple similarity modules into a single representation or result.",
            "absolute_position": "below the SIMILARITY MODULE 1, 2, ..., n and above CLUSTER WORDS in the flowchart.",
            "relative_position": "it is the module that combines the output from SIMILARITY MODULES 1 to n before passing it on to CLUSTER WORDS."
        },
        "Eval A:Sensitivity of. causal effects to design. decisions and hyperparameters": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C16-1107-Figure1-1.png": {
        "Distractor generation": {
            "function": "to create plausible incorrect answer choices for multiple-choice questions.",
            "absolute_position": "in the lower central part of the figure",
            "relative_position": "below the \"Questions\" module and to the left of the \"Multiple-choice questions\" module."
        },
        "SYMP": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.case-1.14-Figure1-1.png": {
        "Event Clusters: [[2], [1,7]]": {
            "function": "to identify and group together sentences from the article that are related to the same event occurrences.",
            "absolute_position": "",
            "relative_position": ""
        },
        "(root, think)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.tlt-1.1-Figure1-1.png": {
        "Sentencizer": {
            "function": "segmenting text into individual sentences.",
            "absolute_position": "4th",
            "relative_position": "after Tagger and before Parser."
        },
        "Control file": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C16-1162-Figure1-1.png": {
        "softmax": {
            "function": "",
            "absolute_position": "at the bottom right corner of the figure.",
            "relative_position": "after the 'L2R' block and before the 'Update Translation Model' in the flow diagram, indicated as step 7 in the figure's flow."
        },
        "like_goto": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W03-1905-Figure2-1.png": {
        "Composition": {
            "function": "",
            "absolute_position": "top-right.",
            "relative_position": "to the right of \"MLC:SemU\" and below \"MLC:FrameSet\"."
        },
        "UNRELATED (1)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W06-1609-Figure3-1.png": {
        "Tuple Extraction": {
            "function": "to extract structured information in the form of tuples from aligned text data.",
            "absolute_position": "3",
            "relative_position": "after the 'Word Aligner' module and before the 'LM toolkit'."
        },
        "Rotting": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/X93-1013-Figure1-1.png": {
        "ACTIVITY": {
            "function": "",
            "absolute_position": "near the center-right of the image",
            "relative_position": "to the right of the ENTITY module and above the INDUSTRY module."
        },
        "Verbalizer template": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-main.67-Figure3-1.png": {
        "planing": {
            "function": "",
            "absolute_position": "in the center",
            "relative_position": "between 'accused' and 'charged,' below 'bomb,' and to the left of 'complained'."
        },
        "Term-Ger-A": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-5114-Figure1-1.png": {
        "Default Conflict": {
            "function": "to resolve conflicting information or assertions.",
            "absolute_position": "bottom-right corner of the figure",
            "relative_position": "below the 'Default Inference' module and to the right of another 'Default Conflict' module."
        },
        "Greenplum": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/H94-1033-Figure1-1.png": {
        "Sentence-Level Pattern Matcher": {
            "function": "to identify and interpret patterns within sentences to facilitate the understanding or processing of text.",
            "absolute_position": "lower middle of the image",
            "relative_position": "below the \"Semantic Interpreter\" and above \"Discourse\"."
        },
        "Term vectors": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W16-6329-Figure1-1.png": {
        "gam": {
            "function": "",
            "absolute_position": "bottom row, third from the left.",
            "relative_position": "directly under \"grāmām,\" which is in the second row, second from the left."
        },
        "Candidate An- swer Extraction": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-long.569-Figure1-1.png": {
        "A molecule that binds to a hydrophobic surface.": {
            "function": "to provide a complex definition of surfactants from journal abstracts.",
            "absolute_position": "on the right side of the figure, below the \"Journal Abstracts\" box.",
            "relative_position": "to the right of the \"Output\" label and below the \"Journal Abstracts\" box."
        },
        "Negative Sampling": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.findings-acl.273-Figure1-1.png": {
        "book": {
            "function": "as a placeholder for an input token in the sequence used for language model training or adaptation.",
            "absolute_position": "in the upper right quadrant of the image, roughly at the center horizontally and towards the top vertically.",
            "relative_position": "in the sequence of text modules, it is the sixth module from the left in the top row of text modules."
        },
        "Montreal": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N15-1040-Figure7-1.png": {
        "arrest": {
            "function": "representing the action or concept that connects the agent (police) with the object or result of the action, indicated by ARG0.",
            "absolute_position": "",
            "relative_position": ""
        },
        "<eos>": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C90-1002-Figure2-1.png": {
        "SYMBOLIC": {
            "function": "",
            "absolute_position": "center-right",
            "relative_position": "to the right of the CONNECTIONIST module."
        },
        "c_int": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/J97-1006-Figure1-1.png": {
        "Computer Response Selection Algorithm": {
            "function": "to determine the appropriate response from the computer based on the current computer goal, user focus, and dialog mode to achieve the selected task goal.",
            "absolute_position": "in the center of the diagram",
            "relative_position": "between the inputs on the left and the output on the right."
        },
        "Transformed Surface Strings": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D15-1075-Figure3-1.png": {
        "200d tanh layer": {
            "function": "to apply a hyperbolic tangent activation function to a 200-dimensional vector, which may be part of a neural network processing sequence data.",
            "absolute_position": "third from the top",
            "relative_position": "middle layer in the stack of tanh layers."
        },
        "y=h(x,f(x))": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2005.mtsummit-osmtw.4-Figure1-1.png": {
        "Re-formatter": {
            "function": "to format the output of the translation process into the target text with the proper formatting.",
            "absolute_position": "at the bottom of the figure.",
            "relative_position": "the last module in the process flow before the \"Target text.\""
        },
        "Neural-based Tag Confirmation and Annotation (Section 3.5.2)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.findings-emnlp.170-Figure2-1.png": {
        "Generator Gθ": {
            "function": "to generate multimodal attention-based gestures from input audio and transcript data.",
            "absolute_position": "the lower center of the figure",
            "relative_position": "below the \"Discriminator D_θ\" module and above the labels \"Audio\" and \"Transcript.\""
        },
        "repeated apply-dialog-task-spec-update update-dialog-task-state(result_available)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.sigmorphon-1.14-Figure7-1.png": {
        "Decoder": {
            "function": "to translate the encoded input into the desired output, often in the form of a sequence of tokens or characters, typically using attention mechanisms to focus on different parts of the input during the translation process.",
            "absolute_position": "right-center in the figure",
            "relative_position": "to the right of the 'Attention' module and below the 'Inflected Form' module."
        },
        "RERANKER": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2008.jeptalnrecital-long.13-Figure1-1.png": {
        "Phonetisation": {
            "function": "to convert graphemes (written units) to phonemes (spoken sounds).",
            "absolute_position": "in the lower right quadrant of the figure.",
            "relative_position": "between 'Graphe alphabétique' and 'Graphe phonétique', and to the right of 'Dictionnaire inverse'."
        },
        "CONTEXT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.lrec-1.285-Figure2-1.png": {
        "Main topic classifications": {
            "function": "to serve as the highest-level categories that organize various subtopics within a hierarchical structure.",
            "absolute_position": "at the top center of the figure",
            "relative_position": "above all the other elements and topics depicted in the diagram."
        },
        "table de correspondances": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P11-2090-Figure1-1.png": {
        "oluwasanmi": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Conventional features of phrase-based SMT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N19-3013-Figure1-1.png": {
        "Batch Normalization": {
            "function": "to normalize the input layer by adjusting and scaling the activations.",
            "absolute_position": "bottom center",
            "relative_position": "after the 'MFCC Sample 100' input and before 'GRU 100'."
        },
        "Evaluation CodaLab": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y09-2032-Figure3-1.png": {
        "Category prediction function": {
            "function": "to output the predicted category based on input features processed through decision trees, heuristic functions, or neural networks.",
            "absolute_position": "bottom center of the figure",
            "relative_position": "below the 'Heuristic function' module and to the left of another 'Category prediction function' module."
        },
        "display": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P01-1055-Figure2-1.png": {
        "Rule-based NERC": {
            "function": "to apply predefined rules for named entity recognition and classification.",
            "absolute_position": "top-center",
            "relative_position": "between 'New Corpus' and 'Identify disagreements'."
        },
        "Parser": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.semeval-1.168-Figure1-1.png": {
        "Translator": {
            "function": "to convert the text from one language to another.",
            "absolute_position": "In figure b, second from the left.",
            "relative_position": "Between the input documents (marked as \"1\" and \"2\") and the BERT Transformer module."
        },
        "situation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-5224-Figure1-1.png": {
        "food": {
            "function": "word-level LSTM processing for the word \"food.\"",
            "absolute_position": "second from the left in the word-level outputs.",
            "relative_position": "between 'The' and 'is' at the word level."
        },
        "\"Students reflections\"": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P19-3009-Figure3-1.png": {
        "- Add the confirmation signals": {
            "function": "to add the confirmation signals.",
            "absolute_position": "the last decision block on the right side, before the \"Unknown intent\" block.",
            "relative_position": "it's the module directly above the \"Unknown intent (for fallback policy)\" module."
        },
        "Matching Feature Extraction": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.naacl-main.251-Figure2-1.png": {
        "Cross-View Transformer": {
            "function": "",
            "absolute_position": "it is the central module in the right half of the figure outlined in red.",
            "relative_position": "it is located between the 'Multi-View Encoding' module on the left and the 'Classification Layer' on the right."
        },
        "Maletti & Engelfriet (2012)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-main.221-Figure2-1.png": {
        "GCN-based Decoder": {
            "function": "to decode the learned embeddings or features back into the graph space, presumably for graph reconstruction or generating a new graph structure based on learned representations.",
            "absolute_position": "to the right-hand side of the image",
            "relative_position": "at the end of the flowchart, following the \"GCN-based Encoder.\""
        },
        "Summarize": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W05-1103-Figure3-1.png": {
        "Turn": {
            "function": "",
            "absolute_position": "top center",
            "relative_position": "above all other modules."
        },
        "Look at screen": {
            "function": "to visually review or observe the content displayed on a screen.",
            "absolute_position": "third from the left on the top row",
            "relative_position": "between \"Choose design\" and \"Describe design.\""
        },
        "GROt": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        },
        "document embedding": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-long.226-Figure1-1.png": {
        "Build Index": {
            "function": "to organize the training data in such a way that it can be efficiently searched or retrieved during the model training process.",
            "absolute_position": "in the upper center of the figure",
            "relative_position": "above the 'Retrieve' module and to the left of the 'Model Training and Inference' module."
        },
        "Transformer Encoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W15-3203-Figure4-1.png": {
        "ArSenL": {
            "function": "",
            "absolute_position": "bottom center",
            "relative_position": "below \"Stored Tweets\" and to the left of the \"Decision tree model\" in the diagram."
        },
        "NN daughter": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.privatenlp-1.4-Figure2-1.png": {
        "MSE LoSs": {
            "function": "to measure the mean squared error loss between the predicted semantic scores and the actual scores to evaluate the performance of the model.",
            "absolute_position": "top right",
            "relative_position": "above the 'Semantic Score' and 'Cosine Similarity' modules, and to the right of all other modules."
        },
        "Semantic structures with colored fonts (structure-specific colors)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2011.eamt-1.11-Figure3-1.png": {
        "lang_es": {
            "function": "to process or handle the Spanish language (es) within the workflow.",
            "absolute_position": "top right corner of the figure",
            "relative_position": "to the right of the 'url_tl' module and above the 'europarl_sentence_splitter_2' module."
        },
        "Target Text": {
            "absolute_position": "top-right",
            "relative_position": "to the right of the \"url_tl\" module and above the \"europarl_sentence_splitter_2\" module.",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y16-2015-Figure1-1.png": {
        "(engine, car)": {
            "function": "to serve as an example of a new instance in the diagram, illustrating the relationship where an engine is part of a car.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Time-Series Summarisation System": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/U07-1006-Figure1-1.png": {
        "Document Repository": {
            "function": "to store documents that are processed and used during various stages of the analysis.",
            "absolute_position": "top-center",
            "relative_position": "to the left of the Annotation Repository module and above the Normalisation module."
        },
        "Trained parser P": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.ijclclp-2.1-Figure1-1.png": {
        "Predict prefix structure": {
            "function": "to identify and outline the structure of prefixes in a given word.",
            "absolute_position": "towards the bottom center of the figure",
            "relative_position": "below the 'Generate writing form according to the transformation rules' module and to the left of the 'Morphological structure' module."
        },
        "Bridge Entity": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to predict prefix structure."
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-acl.252-Figure1-1.png": {
        "Weighting Module": {
            "function": "to evaluate and assign significance to different generated out-of-domain (OOD) utterances based on certain criteria.",
            "absolute_position": "bottom center",
            "relative_position": "below the Generating Module."
        },
        "Action models": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-4157-Figure2-1.png": {
        "Triggering Word And Max-Noun Phrase Identification": {
            "function": "to identify the triggering word and the longest noun phrase in the given text.",
            "absolute_position": "third from the left",
            "relative_position": "immediately following the \"Word sequences with POS\" module."
        },
        "reservation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.eacl-main.289-Figure1-1.png": {
        "Strength Classification": {
            "function": "to categorize the degree or level of a certain characteristic, such as the intensity or confidence associated with a statement.",
            "absolute_position": "3rd from the top",
            "relative_position": "below 'Relation Phrase Labeling' and above 'Exaggeration Detection'."
        },
        "Parser": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D17-1062-Figure1-1.png": {
        "Simplicity Model": {
            "function": "",
            "absolute_position": "on the right half of the image",
            "relative_position": "the first box on the left among the three horizontally aligned boxes above the \"REINFORCE algorithm\" label."
        },
        "Simplified Chinese:": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W16-6319-Figure5-1.png": {
        "Eliminator": {
            "function": "",
            "absolute_position": "in the top right quadrant of the figure, following the 'Phrase Reordering' module and preceding the 'Stemming' module.",
            "relative_position": "it is the module between 'Phrase Reordering' and 'Stemming' in the sequence of processes shown in the figure."
        },
        "dictionary": {
            "absolute_position": "bottom-right corner of the image",
            "relative_position": "to the right of the 'Word to HamNoSys' and below the 'ISL String' modules.",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-main.266-Figure6-1.png": {
        "AM-ADV": {
            "function": "",
            "absolute_position": "Second row, third column",
            "relative_position": "at the intersection of the 'Baseline' row and the third column header (which is not fully visible, but based on context it appears to be the header for the 'AM-ADV' column)."
        },
        "Pseudo Paralld Data": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2007.tmi-papers.29-Figure4-1.png": {
        "for distributing additives": {
            "function": "for distributing additives during the process of taking out the blood.",
            "absolute_position": "(x)",
            "relative_position": "fifth in the sequence from left to right."
        },
        "Task Data Downloadable from the task website": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P17-1012-Figure1-1.png": {
        "LSTM": {
            "function": "to process sequential data, maintain long-term dependencies, and generate the next output in the sequence for a sequence-to-sequence prediction task such as machine translation.",
            "absolute_position": "in the lower central part of the figure",
            "relative_position": "within the LSTM Decoder section, below the Attention Weights and Conditional Input Computation, and to the left of the 'h' and 'c' output arrows."
        },
        "Uvama Urubu Detection": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.dlg4nlp-1.2-Figure1-1.png": {
        "Tuesday": {
            "function": "to specify the day of the week within the context of the diagram.",
            "absolute_position": "bottom right corner of the figure",
            "relative_position": "to the right of \"meet-03\" and below \"data-entity.\""
        },
        "Query": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P16-1036-Figure2-1.png": {
        "Similarity Metric": {
            "function": "to compare the term vector of a question with the term vector of a relevant answer to determine how similar they are.",
            "absolute_position": "at the top center of the figure",
            "relative_position": "above both branches of the neural network structure, likely indicating that it is a component that compares or combines outputs from the two branches."
        },
        "Embeddings": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L16-1188-Figure1-1.png": {
        "Phase 1: Automatic annotation (elongation identification)": {
            "function": "the automatic identification of elongated words in a corpus of texts.",
            "absolute_position": "top center",
            "relative_position": "first in the workflow/process diagram."
        },
        "Observation window of length l": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/H92-1037-Figure1-1.png": {
        "NN 2": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "htgt": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W03-1604-Figure3-1.png": {
        "Knowledge Base": {
            "function": "to store and provide information for processing queries and generating answers.",
            "absolute_position": "fourth from the left",
            "relative_position": "between 'Linguistic Analysis' and 'Document'."
        },
        "TEN": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2003.eamt-1.19-Figure1-1.png": {
        "Tractability ? Quasi-NL ?": {
            "function": "",
            "absolute_position": "middle center",
            "relative_position": "in the central column, between the \"Full Fracas Test Suite\" box at the bottom and the \"Further McLogics\" box at the top."
        },
        "Filter verses": {
            "absolute_position": "bottom middle",
            "relative_position": "between the \"Full Fracas Test Suite\" section on the left and the \"Constraints that show\" section on the right.",
            "function": "unknown."
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-long.322-Figure2-1.png": {
        "85A": {
            "function": "",
            "absolute_position": "in the lower-middle part of the figure",
            "relative_position": "below the '83A' module and above the '87A' module."
        },
        "Tokenizer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.acl-long.303-Figure5-1.png": {
        "Edge Self-Attention": {
            "function": "to calculate attention scores for the graph edges to prioritize the most relevant connections for downstream tasks.",
            "absolute_position": "",
            "relative_position": ""
        },
        "DATA BASES": {
            "absolute_position": "bottom left",
            "relative_position": "below the \"Sentence Representation\" module and to the left of the \"Edge Self-Attention\" module.",
            "function": "to store triples of source node, target node, and their relationship for input sentence information processing."
        }
    },
    "/data_share/data/acl_parse/figure/W17-2308-Figure4-1.png": {
        "sentence reduction": {
            "function": "to condense the information from sentence embeddings into a more compact representation.",
            "absolute_position": "top center",
            "relative_position": "between the word embeddings and the relu module."
        },
        "input": {
            "absolute_position": "",
            "relative_position": "",
            "function": "unknown."
        }
    },
    "/data_share/data/acl_parse/figure/W11-1403-Figure3-1.png": {
        "Document Planner": {
            "function": "to create a document plan and generate sentence trees as part of a text generation process.",
            "absolute_position": "at the top",
            "relative_position": "above the Microplanner and Surface Realizer modules."
        },
        "Vectorization": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-6607-Figure1-1.png": {
        "Processing": {
            "function": "to analyze or manipulate the pre-processed text data to extract information or produce a result that will later be evaluated.",
            "absolute_position": "third",
            "relative_position": "middle."
        },
        "Selected targets": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W18-5709-Figure3-1.png": {
        "Query Encoder": {
            "function": "to encode the query information for the system to generate an appropriate response.",
            "absolute_position": "bottom center",
            "relative_position": "between the Image Encoder of Context 2 and the Entity Encoder."
        },
        "Valerie_Trierweiler": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D13-1072-Figure1-1.png": {
        "Action models": {
            "function": "to generate associations between objects and scenes, as well as actions (verbs) with scenes and objects, to suggest possible actions.",
            "absolute_position": "in the center top area of the figure",
            "relative_position": "between the 'Input images' on the bottom and the 'Suggested actions' on the right."
        },
        "ht": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C00-2091-Figure3-1.png": {
        "IIparis": {
            "function": "",
            "absolute_position": "bottom center of the figure on the right side, labeled as (b) After cut-elimination.",
            "relative_position": "second from the bottom in the vertical stack of modules on the right side of the figure."
        },
        "SVM predictions": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.inlg-1.1-Figure1-1.png": {
        "Prediction:": {
            "function": "to output the final sequence of predicted tokens or words based on the transformation from the graph structure to the textual representation.",
            "absolute_position": "bottom right corner of the figure",
            "relative_position": "inside the Text Decoder box, below the Transformer Decoder module."
        },
        "Persuasive writing task": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S19-2008-Figure1-1.png": {
        "BiLSTM": {
            "function": "to process sequential data in both forward and backward directions to capture context from both past and future states.",
            "absolute_position": "left-middle",
            "relative_position": "underneath 'ELMo' and above 'Dense'."
        },
        "Verb Lexicon": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.acl-long.284-Figure2-1.png": {
        "Only contains information that is mentioned in the current utterance": {
            "function": "to retain only the information that is mentioned in the current utterance within the program.",
            "absolute_position": "bottom",
            "relative_position": "right."
        },
        "Tapas Architecture": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/O02-1002-Figure5-1.png": {
        "NVEF sense- pair identifier": {
            "function": "",
            "absolute_position": "in the center of the figure",
            "relative_position": "between the \"LS-NVWF & EWL checking\" box and the \"sentence-NVEF tree\" box, with arrows pointing to the \"KR tree\" and \"HowNet\" boxes, and receiving an arrow from the \"sentence\" box."
        },
        "Hownet": {
            "function": "",
            "absolute_position": "the bottom right corner of the figure.",
            "relative_position": "below the \"sentence-NVEF tree\" module and to the right of the \"KR tree\" module."
        },
        "MOTORCYCLING-JAPANESE WIN BOTH ROUND NINE SUPERBIK ERACES": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        },
        "Plain Text": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y05-1025-Figure3-1.png": {
        "4.Compile Lexicon": {
            "function": "to compile the lexicon database for use in morphological analysis processes.",
            "absolute_position": "top right",
            "relative_position": "last tab on the right."
        },
        "metaphor seed set": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W09-4624-Figure3-1.png": {
        "SVM F-Structure Equation Tagging": {
            "function": "",
            "absolute_position": "in the center on the left side",
            "relative_position": "in the middle of the flowchart between 'SVM Function Tagging' and 'Constraint Solver'."
        },
        "Polar Expression": {
            "absolute_position": "",
            "relative_position": "",
            "function": "SVM F-Structure Equation Tagging."
        }
    },
    "/data_share/data/acl_parse/figure/2021.sigmorphon-1.2-Figure5-1.png": {
        "Apply rule (3)": {
            "function": "to transform the input tree structure by applying a specific transformation rule, numbered (3), to produce an altered output tree structure as part of a sequence of such transformations.",
            "absolute_position": "third from the left",
            "relative_position": "immediately to the right of the 'Apply rule (2)' module."
        },
        "Reference policy": {
            "absolute_position": "",
            "relative_position": "",
            "function": "unknown."
        }
    },
    "/data_share/data/acl_parse/figure/A97-1020-Figure1-1.png": {
        "DICTIONARY LOOKUP": {
            "function": "to search and retrieve the meaning or information of words from a dictionary resource.",
            "absolute_position": "bottom right corner of the figure",
            "relative_position": "to the right of the 'MORPHOLOGICAL ANALYSER DISAMBIGUATOR' module and above the 'CORPORA SEARCH' module."
        },
        "Text Scraping": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W13-1902-Figure1-1.png": {
        "ALI Learner": {
            "function": "to learn from training instances and assertion classes to inform the ALI Predictor.",
            "absolute_position": "lower center",
            "relative_position": "between the Assertion Classifier and the ALI Predictor."
        },
        "Bigrams Dictionary": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.findings-acl.55-Figure2-1.png": {
        "doctor 0.3 nurse 0.35 surgeon 0.1 receptionist 0.1": {
            "function": "to represent a modified distribution of probabilities for the given occupations.",
            "absolute_position": "in the bottom center of the figure",
            "relative_position": "below and slightly to the left of the middle of the figure."
        },
        "HYPHEN": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.nodalida-main.10-Figure1-1.png": {
        "IDFT": {
            "function": "to perform the Inverse Discrete Fourier Transform on the spectral components to reconstruct the time-domain signal.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Who discovered it?": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2003.mtsummit-papers.43-Figure1-1.png": {
        "Translation by Sub-sentence Patterns": {
            "function": "to translate sub-sentences based on identified patterns when translation by sentence patterns fails.",
            "absolute_position": "bottom right corner of the flowchart",
            "relative_position": "below the \"Translation by Sentence Patterns\" module, connected via a \"Fail\" path indicating a conditional workflow."
        },
        "Enriched sense based on refined enrichment": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.lrec-1.861-Figure1-1.png": {
        "Inter-rater agreement": {
            "function": "to measure the consistency or agreement between different annotators.",
            "absolute_position": "3rd from the left",
            "relative_position": "after 'Annotation' and before 'Merging annotations'."
        },
        "4.Sentence Categorizing &Display": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P17-1053-Figure2-1.png": {
        "Relation Representation": {
            "function": "to encode the semantic representation of a relation for comparison with a question representation using cosine similarity.",
            "absolute_position": "on the top right side of the figure",
            "relative_position": "to the right of the 'Relation-Level' and 'Word-Level' processing modules and above the 'cosine similarity' label."
        },
        "statistical decoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2019.rocling-1.10-Figure1-1.png": {
        "Segmentation": {
            "function": "to divide text into meaningful segments, such as sentences or words, to facilitate further processing.",
            "absolute_position": "second row, second column.",
            "relative_position": "in the 'Text Processing' section, the first module on the left."
        },
        "Pre-processing": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W09-3014-Figure3-1.png": {
        "form headword": {
            "function": "",
            "absolute_position": "third level from the top, second from the left on its level.",
            "relative_position": "to the right of the 'grammar_determiner' module and to the left of the 'orth' module within the 'form' category."
        },
        "Reward Shaping": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P06-2120-Figure1-1.png": {
        "Clinic Information Service": {
            "function": "",
            "absolute_position": "center",
            "relative_position": "center."
        },
        "PERSON1 <wed> PERSON2": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-0409-Figure1-1.png": {
        "Intelligence": {
            "function": "to process and understand the logical coherence and propositional density of a text.",
            "absolute_position": "bottom right corner of the figure.",
            "relative_position": "on the right side, aligned with the 'Reader' section, and below 'Knowledge' and 'Interest.'"
        },
        "Logical Incoherence Propositional Density": {
            "function": "",
            "absolute_position": "bottom center",
            "relative_position": "below 'Assumed Knowledge' and above 'Intelligence'."
        },
        "TERMINOLOGICAL DATABASE SYSTEM": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        },
        "Generator": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W15-2124-Figure1-1.png": {
        "seed URLs": {
            "function": "to provide initial web addresses from which a web crawl can be started to gather data for a web corpus.",
            "absolute_position": "third from the left in the top row",
            "relative_position": "after 'language detection' and before 'web crawl'."
        },
        "Science & Technology 2 subcategories": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-long.344-Figure2-1.png": {
        "Linda would you care for some candies or cookies?": {
            "function": "initiating the conversation or offering food.",
            "absolute_position": "1",
            "relative_position": "top."
        },
        "fr=Boule(solide)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W07-2424-Figure5-1.png": {
        "team komanda": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Compiled Transfer Grammar": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D18-1037-Figure4-1.png": {
        "Andrei when starving": {
            "function": "to represent the subject of the sentence in the syntactic structure.",
            "absolute_position": "bottom-left",
            "relative_position": "under NP (Noun Phrase)."
        },
        "Agglomerative Clusterer Tune on validation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2013.mtsummit-wmwumttt.7-Figure3-1.png": {
        "RDF Graph Matching": {
            "function": "to compare and align RDF (Resource Description Framework) graphs to ensure data interoperability and integration.",
            "absolute_position": "bottom center of the figure",
            "relative_position": "below \"Domain Concepts Mapping\" and above \"IR/IE\"."
        },
        "Tgt output": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P17-2067-Figure2-1.png": {
        "ConvNet": {
            "function": "to perform convolutional operations on the input data to extract features for further processing.",
            "absolute_position": "in the lower center of the image",
            "relative_position": "between the 'Meta data' on the left and the 'Bi-LSTM' on the right."
        },
        "Data Preprocessing": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/R19-1118-Figure1-1.png": {
        "RuSentiFrames lexicon": {
            "function": "to provide entries for sentiment analysis within the framework.",
            "absolute_position": "toward the bottom right corner of the figure",
            "relative_position": "between the \"frame entries\" module on the left and the \"RuAttitudes collection\" module on the right."
        },
        "Embedding": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W14-0107-Figure2-1.png": {
        "\"falsch machen/Fehler machen\" 'make a mistake'": {
            "function": "to represent the general concept of making a mistake, which is related to more specific mistakes depicted in the diagram, such as making a slip of the tongue, getting lost while driving, and miscalculating.",
            "absolute_position": "bottom center",
            "relative_position": "below the \"sich verfahren\" ('get lost while driving') and \"sich verrechnen\" ('miscalculate') modules, and at the bottom of the three connected boxes."
        },
        "KEYWORD TRAINING TRAINING SET KEYWORD DB": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/1995.mtsummit-1.10-Figure1-1.png": {
        "Wider range of documonts": {
            "function": "to handle or support a wider variety of document types or formats.",
            "absolute_position": "bottom center",
            "relative_position": "between \"Inclusion in new applications\" and \"New requirements\"."
        },
        "BERT-base (Chinese)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W16-5204-Figure1-1.png": {
        "translator": {
            "function": "to convert text or speech from one language into another language.",
            "absolute_position": "near the top center of the image, slightly to the right.",
            "relative_position": "between the \"re-speaking\" and \"TTS\" modules within the flowchart, directly above the \"MT\" module."
        },
        "Pre-processing": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W12-6303-Figure1-1.png": {
        "Code-switching corpus": {
            "function": "to provide data for language model training that includes examples of code-switching.",
            "absolute_position": "top left",
            "relative_position": "above the \"Non-code-switching corpus\" module and to the left of the \"Language Model Training\" module."
        },
        "Sentence-Level Pattern Matcher": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N03-1022-Figure1-1.png": {
        "Relaxation": {
            "function": "",
            "absolute_position": "between the 'Justification' module and the 'Answer Ranking' module",
            "relative_position": "in the middle of the flow, following the 'Justification' module and preceding the 'Answer Ranking' module."
        },
        "Transfer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W03-1206-Figure2-1.png": {
        "OUTLIERS": {
            "function": "to represent data points that differ significantly from other observations in a dataset.",
            "absolute_position": "top left",
            "relative_position": "outside the concentric circles, to the left."
        },
        "t:T": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2012.eamt-1.55-Figure1-1.png": {
        "sentence classifier": {
            "function": "to categorize sentences, likely based on their quality or characteristics, as part of a process to create a post-editing classification model.",
            "absolute_position": "towards the bottom right of the image",
            "relative_position": "to the right of the \"training set\" module and below the \"SPE\" and \"post-edited corpus\" modules."
        },
        "LSH Proj": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-6504-Figure1-1.png": {
        "Pseudo Parallel Corpus": {
            "function": "to combine back-translated target language data with source-side monolingual data to create a synthetic parallel corpus for training translation models.",
            "absolute_position": "bottom right corner of the figure",
            "relative_position": "below the \"Original Parallel Corpus\" and to the right of the \"Source-side Pseudo Monolingual Corpus (ja)\"."
        },
        "JSON Representation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2008.tc-1.5-Figure1-1.png": {
        "Translated files": {
            "function": "to store or represent the files that have been translated from the source files before they become final files.",
            "absolute_position": "center",
            "relative_position": "second from the left."
        },
        "CONSTRUCTORS (Semi-automatic)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.sdp-1.10-Figure1-1.png": {
        "Highly accurate (100%) annotated training data": {
            "function": "to provide a dataset with annotations that are 100% accurate for training machine learning models.",
            "absolute_position": "the second module from the left",
            "relative_position": "the module in the center at the top row."
        },
        "Generator Gθ": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W12-2910-Figure1-1.png": {
        "Original Text": {
            "function": "the input or source content for the text processing workflow illustrated in the diagram.",
            "absolute_position": "top",
            "relative_position": "above all other modules."
        },
        "NR2s": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.157-Figure2-1.png": {
        "Combined Input (1)": {
            "function": "",
            "absolute_position": "second from the left",
            "relative_position": "between 'Allosaurus' and 'Word Discovery FST'."
        },
        "Word speaker: Participant word: String startTime:Double": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-demos.8-Figure2-1.png": {
        "Entity/Relation/Event Extraction, Hypothesis Ranking and Evidence Mining": {
            "function": "to extract entities, relationships, and events from data, rank hypotheses, and mine evidence for information integration into a knowledge base.",
            "absolute_position": "on the right side of the figure",
            "relative_position": "between the 'Multimedia Knowledge Base' module and the 'Question Answering and Report Generation' module."
        },
        "Action Database": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/K19-1062-Figure1-1.png": {
        "claiming": {
            "function": "",
            "absolute_position": "bottom right corner of the image",
            "relative_position": "third in the sequence from the left in the lowermost flowchart."
        },
        "PARSER 1": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-long.462-Figure1-1.png": {
        "RL-Critic": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "girl": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P91-1004-Figure2-1.png": {
        "Plan3": {
            "function": "",
            "absolute_position": "third from the top within the outlined modules.",
            "relative_position": "immediately after Plan2 and before Plan4."
        },
        "Re-Weighted Semi-Supervised Data Programming": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-5545-Figure5-1.png": {
        "Distance Function": {
            "function": "to measure the similarity between the vector representations of the test query and the canonical utterance.",
            "absolute_position": "top-center",
            "relative_position": "between the outputs of the two Pooling modules."
        },
        "Build class-based language model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W11-3307-Figure5-1.png": {
        "DocumentReferenceAttribute <ReferenceAnnotation>": {
            "function": "",
            "absolute_position": "in the center towards the right side of the figure",
            "relative_position": "below 'DocumentAnnotation' and to the right of 'DocumentClassAnnotation', at the same level as 'DocumentValueAttribute'."
        },
        "pricerange": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W11-2915-Figure2-1.png": {
        "Re-ranked HPSG parses": {
            "function": "",
            "absolute_position": "at the bottom center of the figure",
            "relative_position": "below the \"Parse Re-ranking\" box which is in the middle of the diagram, following an arrow that points downwards from that box."
        },
        "Ranked List of Paragraphs": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.figlang-1.2-Figure3-1.png": {
        "Database": {
            "function": "text retrieval.",
            "absolute_position": "in the top center of figure (a)",
            "relative_position": "in between 'Response' on the left and 'Rank' on the right."
        },
        "sytactic tree of h": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W11-4407-Figure3-1.png": {
        "dizava_s": {
            "function": "",
            "absolute_position": "on the bottom diagram, on the far left-hand side.",
            "relative_position": "the first module from the left in the bottom diagram."
        },
        "Semantic Pooling": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.findings-emnlp.362-Figure1-1.png": {
        "Feed-Forward Layer (FFN)": {
            "function": "to apply non-linear transformations to the input data and integrate learned positional encodings in the context of neural network architectures, such as Transformers.",
            "absolute_position": "third from the left in a series of three diagrams",
            "relative_position": "in the center of the third diagram."
        },
        "Japanese-French French-Japanese Harmonized Dictionary": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.284-Figure2-1.png": {
        "Hypernym Information": {
            "function": "to provide hierarchical information or semantic relationships between concepts to assist other modules, such as normalization and ranking, in the processing of entities.",
            "absolute_position": "bottom center",
            "relative_position": "between the \"Hypernym Normalizer\" and the \"List-wise Ranker.\""
        },
        "Claim generation engin": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.emnlp-main.308-Figure1-1.png": {
        "(a) Expression fragmentation issue": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "NPe0": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W03-0312-Figure1-1.png": {
        "Autumn.": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Foreign Word Tagger": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.lrec-1.666-Figure2-1.png": {
        "Interactive module": {
            "function": "to generate a matching matrix using Q-A aware and self-attention mechanisms.",
            "absolute_position": "in the lower-right corner of the figure.",
            "relative_position": "adjacent to the right of the \"Pre-trained Bi-LSTM\" block and below the \"Local context jump dependencies\" block within the flow diagram."
        },
        "Source-Domain Data": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W11-2839-Figure1-1.png": {
        "Rule-based Model": {
            "function": "processing inputs using predefined rules to make decisions or perform actions.",
            "absolute_position": "in the bottom-center area of the figure.",
            "relative_position": "below the \"Statistical Model\" and \"Test Documents\" modules and above the \"Corrected Document\" in the workflow diagram."
        },
        "Word Embedding": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-0910-Figure1-1.png": {
        "Discover Candidate Slots and Fillers": {
            "function": "to identify potential slots (categories or types) and fillers (values or instances) from the input data.",
            "absolute_position": "second from the left on the top row",
            "relative_position": "to the right of 'Wiki Articles' and to the left of 'Slot Ranking'."
        },
        "Tag Assignment": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D11-1077-Figure1-1.png": {
        "DASH": {
            "function": "",
            "absolute_position": "bottom left",
            "relative_position": "below and to the left of PMI."
        },
        "Sentence Generation Module (SGM)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.acl-long.303-Figure4-1.png": {
        "Graph Builder": {
            "function": "to create a graph representation of the input data.",
            "absolute_position": "in the center, at the top.",
            "relative_position": "between the 'Distant Supervision Label Creator' and the 'ABCD Model (Train)' to the right and adjacent to the 'Training' text block on the left."
        },
        "Person": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.acl-short.85-Figure1-1.png": {
        "Task T task description": {
            "function": "",
            "absolute_position": "top center",
            "relative_position": "in the middle of the left side."
        },
        "Feature Transfer Model (Mandarin to English)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N19-1290-Figure2-1.png": {
        "Instance Selector": {
            "function": "to choose specific instances from the original bag based on certain criteria or rules.",
            "absolute_position": "in the lower left area of the figure",
            "relative_position": "below the 'Original Bag' and to the left of the 'Make Sequential Decisions' process."
        },
        "Triple Based Bi-gram MM with Viterbi Algorithm": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/1995.tmi-1.20-Figure1-1.png": {
        "X teimasu X wa Y": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Data Preprocessing": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.computerm-1.1-Figure1-1.png": {
        "Term Extraction TermoStat": {
            "function": "",
            "absolute_position": "on the left side, about midway down the figure.",
            "relative_position": "below the \"Reference Corpus\" and to the left of the \"Preprocessing\" and \"Term Candidates\" modules."
        },
        "configuration": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.wmt-1.6-Figure1-1.png": {
        "Baseline (train from scratch)": {
            "function": "to establish a reference point for performance comparison by training a model from the beginning without pre-existing data or weights.",
            "absolute_position": "on the top row, third from the left.",
            "relative_position": "after \"Clean by LASER-based scores\" and before \"Fine-tuning on mBART.\""
        },
        "File Filter Rebuild": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L18-1093-Figure1-1.png": {
        "BabelNet": {
            "function": "to provide a multilingual encyclopedic dictionary and a semantic network for natural language processing tasks.",
            "absolute_position": "in the center-top of the figure",
            "relative_position": "between the \"Learning proto-concepts\" box on the left and the \"Framester\" box on the right."
        },
        "POS TreeTagger": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-5322-Figure1-1.png": {
        "Update": {
            "function": "to modify or add new data to the system's database or knowledge base.",
            "absolute_position": "at the bottom center of the figure",
            "relative_position": "below the 'API' section and above the 'Path Queries' and 'Semantic Approximation' sections."
        },
        "Lexical items": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.calcs-1.5-Figure1-1.png": {
        "ENG HIN CM": {
            "function": "to perform code-mixing classification for English and Hindi languages.",
            "absolute_position": "bottom middle",
            "relative_position": "at the bottom, center-aligned with the 'Dictionary LID' module directly above it."
        },
        "Fission": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W04-0705-Figure2-1.png": {
        "SVM classifier to select correct names using coreference features": {
            "function": "to select correct names using coreference features.",
            "absolute_position": "bottom center of the diagram",
            "relative_position": "directly above the \"Output\" module, following the \"Coreference Rules to fix name\" module."
        },
        "NVEF-enclosed word template": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-acl.218-Figure2-1.png": {
        "ST Encoder": {
            "function": "",
            "absolute_position": "top middle",
            "relative_position": "between the Acoustic Encoder and the ST Decoder, within the speech translation system diagram."
        },
        "Transformer": {
            "absolute_position": "inside the blue dashed-line boxes under \"Block 1\" and \"Block 2&3\"",
            "relative_position": "inside the \"Acoustic Encoder\" as part of the ST Encoder module.",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S19-2027-Figure1-1.png": {
        "LSTM / BiLSTM": {
            "function": "to process sequential data and capture temporal relationships within the input data for sentiment analysis tasks.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Motion Parameters": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2014.iwslt-papers.11-Figure1-1.png": {
        "12E Phrase Table": {
            "function": "",
            "absolute_position": "on the right side of the image, towards the top.",
            "relative_position": "to the right of the \"Adaptation\" module and above the \"Adapted MT Output\" module."
        },
        "dobj": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P19-1023-Figure1-1.png": {
        "Encoder N-gram-based attention Decoder Triple classifier": {
            "function": "to encode the input sentence, focus on relevant parts using N-gram-based attention, decode the processed information, and classify it into triples for relation extraction.",
            "absolute_position": "top right in the figure",
            "relative_position": "in the Neural Relation Extraction Module, enclosed within a red box."
        },
        "Global- max-pooling": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-main.119-Figure2-1.png": {
        "Logistic Regression OR Feed Forward Neural Network Or Support Vector Machine": {
            "function": "to classify or predict detected cognates using either Logistic Regression, a Feed Forward Neural Network, or a Support Vector Machine.",
            "absolute_position": "second from the left and first from the right",
            "relative_position": "in between the module titled 'MUSE OR VecMap OR XLM-R' and the module titled 'Detected Cognates'."
        },
        "Loss (KL divergence)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P98-2168-Figure4-1.png": {
        "H believes S will not attend": {
            "function": "to represent the belief of H (a person or entity in this model) that S (another person or entity) will not attend an event or situation.",
            "absolute_position": "bottom center",
            "relative_position": "directly below 'H believes S is unappreciative'."
        },
        "BILINGUAL SUBTITLING": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.lrec-1.68-Figure1-1.png": {
        "Text Generation": {
            "function": "to produce natural language sentences suitable for speech synthesis from the structured or semi-structured data provided by dialogue management.",
            "absolute_position": "bottom-center",
            "relative_position": "directly below the \"Dialogue Management\" module and to the left of the \"Speech Synthesis\" module."
        },
        "component": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to generate textual output based on the input and context provided by other modules in the system."
        }
    },
    "/data_share/data/acl_parse/figure/2017.iwslt-1.5-Figure2-1.png": {
        "<eos>": {
            "function": "an end-of-sequence indicator in the diagram.",
            "absolute_position": "at the bottom of the diagram",
            "relative_position": "to the rightmost end of the sequence of modules at the bottom."
        },
        "soap": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2005.mtsummit-ebmt.2-Figure2-1.png": {
        "John went to the bank to get some cash.": {
            "function": "to represent the test input for a computational model or system being described in the diagram.",
            "absolute_position": "2nd row, 1st column",
            "relative_position": "immediately below the “Training Instances” label."
        },
        "Decoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W00-0501-Figure1-1.png": {
        "post-OCR doc in SL": {
            "function": "to represent the document in the source language after the Optical Character Recognition (OCR) process has been applied.",
            "absolute_position": "third box from the top in the central column",
            "relative_position": "below the \"OCR\" box and above the \"MT\" box."
        },
        "sentence parser": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-1629-Figure9-1.png": {
        "HELPING the flashlight to work properly?": {
            "function": "ensuring that the flashlight has a reliable and sufficient power source to operate correctly.",
            "absolute_position": "at the bottom center of the figure.",
            "relative_position": "below the \"the batteries power is lower\" module and to the left of the \"HURTING the flashlight to work properly\" module."
        },
        "Total": {
            "absolute_position": "bottom center",
            "relative_position": "below the central flowchart that describes the effects of battery power level on the flashlight's functionality.",
            "function": "evaluating factors that are either helping or hurting the flashlight to work properly."
        }
    },
    "/data_share/data/acl_parse/figure/H05-1125-Figure3-1.png": {
        "Signal Processing": {
            "function": "to extract features from the acoustic waveform for subsequent analysis or processing.",
            "absolute_position": "top-left",
            "relative_position": "between the \"Acoustic Waveform\" input on the left and the \"Features\" module on the right."
        },
        "Dynamic Programming": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-demo.18-Figure1-1.png": {
        "Data Collection": {
            "function": "to gather raw data for processing.",
            "absolute_position": "top center",
            "relative_position": "in between 'Training Data' on the left and 'Raw Data' on the right."
        },
        "Classifier": {
            "absolute_position": "top left",
            "relative_position": "before Prediction.",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D17-1296-Figure3-1.png": {
        "want a flight": {
            "function": "",
            "absolute_position": "top-left",
            "relative_position": "first in the sequence of modules at the top of the figure."
        },
        "phone": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C12-3055-Figure2-1.png": {
        "Invoke Bing- Ngrams Web service": {
            "function": "to query the Bing-Ngrams service for linguistic data or statistics.",
            "absolute_position": "the second to last on the bottom row",
            "relative_position": "to the right of the \"Wikipedia index lookup\" module and to the left of the \"Proposed Markov chain based ranking\" module."
        },
        "Tagger": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/1989.tc-1.6-Figure7-1.png": {
        "DICPET": {
            "function": "",
            "absolute_position": "on the bottom left part of the figure, between the \"XYZ\" module and the \"Total\" module.",
            "relative_position": "directly above the \"Total\" module and below the \"XYZ\" module."
        },
        "Feature Extraction (MFCC)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-3020-Figure1-1.png": {
        "Performance evaluation (macro F1,Precision, Recall)": {
            "function": "to assess the effectiveness of the trained classifiers by measuring their macro F1 score, precision, and recall.",
            "absolute_position": "near the bottom center of the figure.",
            "relative_position": "below the \"Trained classifiers (GB, RF, SVM, NB)\" module and to the right of the \"Oversampling\" module."
        },
        "RAIN": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/T78-1031-Figure4-1.png": {
        "SUPPORTS": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Classifiers": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W18-3022-Figure1-1.png": {
        "What is your age?": {
            "function": "to ask the user's age, which is semantically similar to the question \"How old are you?\" and expects an age-related response.",
            "absolute_position": "bottom center",
            "relative_position": "below \"How old are you?\" and to the left of \"I am 20 years old.\""
        },
        "RoBERT (large /base) BERT (large/base)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W14-1307-Figure1-1.png": {
        "\"aci\"": {
            "function": "",
            "absolute_position": "top-center",
            "relative_position": "first in the row of modules."
        },
        "KREME": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/T78-1018-Figure2-1.png": {
        "READING A LETTER": {
            "function": "to interpret the content of a written letter and understand its message.",
            "absolute_position": "bottom-right",
            "relative_position": "below 'CONVERSING OVER LINKED TELETYPE' and to the right of 'INTERACTION'."
        },
        "Tagged Corpus for Chunker": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2014.tc-1.25-Figure1-1.png": {
        "$Article:\"#Articles:ARTICLES\"": {
            "function": "to denote the presence of an article in a sentence structure.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Grammatical Rule Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.323-Figure1-1.png": {
        "Add & Layer Norm Position-wise Feed Forward Add &Layer Norm Multi-head Self-Attention": {
            "function": "to process input embeddings through multiple layers of self-attention and position-wise feed-forward neural networks, with each layer followed by a residual connection and layer normalization.",
            "absolute_position": "the right side of the figure",
            "relative_position": "the top module within the Masked Cross-modal Acoustic Modeling section."
        },
        "A-B": {
            "absolute_position": "",
            "relative_position": "",
            "function": "unknown."
        }
    },
    "/data_share/data/acl_parse/figure/W07-2313-Figure6-1.png": {
        "report generator": {
            "function": "to create reports from the data in the EPR database.",
            "absolute_position": "Center",
            "relative_position": "In the middle, to the right of the \"EPR database\" and to the left of \"report.xch\"."
        },
        "String Similarity": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W18-2401-Figure2-1.png": {
        "Output of GATE as GATExml": {
            "function": "converting the output from the GATE software into GATE XML format.",
            "absolute_position": "center bottom",
            "relative_position": "between 'GATExml to .ann' and 'Pipeline with JAPE Rules'."
        },
        "Inscription": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.acl-main.468-Figure1-1.png": {
        "Target Population": {
            "function": "to represent the group for which predictions are made using the model, highlighting the features and outcomes associated with this group, and it addresses the potential biases that might emerge when the model predictions are applied to this real-world population.",
            "absolute_position": "on the right side of the figure",
            "relative_position": "third from the left in the sequence of modules."
        },
        "SMT system": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/R15-1007-Figure1-1.png": {
        "TriggerWords": {
            "function": "",
            "absolute_position": "bottom-right corner of the diagram",
            "relative_position": "below and to the right of the center of the diagram."
        },
        "Language Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/O00-1006-Figure4-1.png": {
        "2.Similarity Calculation": {
            "function": "to calculate the similarity between sessions for clustering purposes.",
            "absolute_position": "center-right",
            "relative_position": "between \"1.Common Query Checking\" and \"3.Incremental Cluster Finding\"."
        },
        "source text": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y15-1061-Figure4-1.png": {
        "Query Translation": {
            "function": "to translate a search query from a source language to a target language.",
            "absolute_position": "center top",
            "relative_position": "between the \"Source Language Query\" and \"Target Language Query\" modules, above the \"Source Language IR\" and \"Target Language IR\" modules."
        },
        "CTRL": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2014.iwslt-papers.18-Figure1-1.png": {
        "that go around": {
            "function": "",
            "absolute_position": "top-right",
            "relative_position": "at the end of the dashed line to the right."
        },
        "Idiot": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.naacl-main.266-Figure6-1.png": {
        "subspace of continuous prompts that have the same projections but solve different tasks": {
            "function": "to represent a region within the continuous prompts space where different tasks can be solved despite having the same projections.",
            "absolute_position": "",
            "relative_position": ""
        },
        "particle": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/A00-1015-Figure2-1.png": {
        "OUTPUT:": {
            "function": "to execute a command that causes an object, likely on a graphical user interface such as a canvas, to move in an upward direction.",
            "absolute_position": "",
            "relative_position": ""
        },
        "TA:suggestion": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P13-3014-Figure1-1.png": {
        "NAMED ENTITY VEHICLE": {
            "function": "to identify and categorize the semantic type of the vehicle mentioned in the text.",
            "absolute_position": "bottom center of the image",
            "relative_position": "below the \"WordNet search\" result '{statek 1} ship'."
        },
        "Embeded Input Sequence": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-1631-Figure1-1.png": {
        "MetaMap": {
            "function": "",
            "absolute_position": "at the bottom right within the flow chart diagram",
            "relative_position": "below the NLTK module and to the right of the Aligner module."
        },
        "Prolog": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y10-1041-Figure1-1.png": {
        "Example-base": {
            "function": "",
            "absolute_position": "in the center of the figure",
            "relative_position": "between the \"Analogy Verifier\" and \"Analogy Solver\" modules on the 'Target Side'."
        },
        "Noise reduction/ Data correction/ Cross-validation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W18-5919-Figure1-1.png": {
        "Sentiment": {
            "function": "to analyze the emotional tone behind a series of words, used to gain an understanding of the attitudes, opinions and emotions expressed within an online mention.",
            "absolute_position": "in the lower-left corner of the flow diagram",
            "relative_position": "directly below the 'Drug Identification' process and to the left of the 'Linguistic Feature Generator'."
        },
        "Downstream Task": {
            "absolute_position": "",
            "relative_position": "",
            "function": "unknown."
        }
    },
    "/data_share/data/acl_parse/figure/2020.acl-main.193-Figure2-1.png": {
        "Consensus At": {
            "function": "to aggregate individual annotator predictions into a consensus prediction using a form of attention mechanism.",
            "absolute_position": "on the right side of the figure, in the center of the three modules within the 'Aggregation Phase' block",
            "relative_position": "directly to the left of the 'Weighted Voting' arrow and above the 'Attention (Q)' label."
        },
        "U1": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.paclic-1.27-Figure1-1.png": {
        "erroneous sentence I went for Toktyo .": {
            "function": "to represent the output sentence after processing by the prior modules, indicating an error in the sentence construction.",
            "absolute_position": "bottom left",
            "relative_position": "directly below the \"Stacked modules\" label."
        },
        "Parallel text based translation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.reinact-1.5-Figure1-1.png": {
        "What is the mustache made of?": {
            "function": "to ask what material the mustache depicted in the image is made of.",
            "absolute_position": "1st",
            "relative_position": "leftmost."
        },
        "Fission": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.bionlp-1.29-Figure2-1.png": {
        "Encoder": {
            "function": "to process and transform input data into a representation that can be utilized by the decoder in the autoregressive entity retrieval model.",
            "absolute_position": "on the right side of the figure, between the \"BioBERT\" module and the \"Decoder\" module.",
            "relative_position": "in the middle part of the auto-regressive entity retrieval model diagram, specifically the second module from the left within the three main modules shown in a sequence."
        },
        "Refresh OLiA": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-main.104-Figure3-1.png": {
        "Entailment scorer (RoBERTa)": {
            "function": "to compute the unnormalized scores indicating the degree to which a given premise entails multiple hypotheses, using the RoBERTa language model.",
            "absolute_position": "in the center of the figure",
            "relative_position": "directly below the 'Softmax' module and above the inputs \"<CLS> Premise <SEP> Hypothesis1 <SEP>\", \"<CLS> Premise <SEP> Hypothesis2 <SEP>\", and \"<CLS> Premise <SEP> Hypothesis3 <SEP>\"."
        },
        "Audio Server": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.isa-1.5-Figure3-1.png": {
        "Discourse relation recognition": {
            "function": "to identify the relationships between different parts of text within a discourse.",
            "absolute_position": "the lower center part of the figure",
            "relative_position": "between the \"EDU segmentation\" module on the left and the \"Argument recognition\" module on the right."
        },
        "{attack(E6),bombing(E7}": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/O07-3005-Figure1-1.png": {
        "Feature Extraction": {
            "function": "to extract relevant features from the input data for further processing and analysis.",
            "absolute_position": "on the left side of the figure, second box from the top in the middle column.",
            "relative_position": "directly below the 'Emotional Corpus' module and to the left of the 'Compensation Vector Estimation' module at the top of the 'Training Phase.'"
        },
        "effusion.": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-6501-Figure4-1.png": {
        "John and Mary live in London": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Regression Based Technique": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-3603-Figure3-1.png": {
        "Li et al.": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "English Spell Checker": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W05-1615-Figure1-1.png": {
        "Marfors Text Editor": {
            "function": "editing pre-edited text to produce post-edited text.",
            "absolute_position": "bottom center",
            "relative_position": "below the 'Pre-edited Text' module and to the left of the 'Post-edited Text' module."
        },
        "CLAUSAL STAGE": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/O07-2009-Figure1-1.png": {
        "Receiver": {
            "function": "to receive the speech waveform.",
            "absolute_position": "top-center",
            "relative_position": "to the right of \"speech waveform\" and to the left of \"A/D Converter\"."
        },
        "Gs": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P16-1164-Figure2-1.png": {
        "cue classifier": {
            "function": "to classify cues in a given system or dataset for subsequent detection and analysis.",
            "absolute_position": "top-center",
            "relative_position": "above all other modules in the diagram."
        },
        "ANT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-1310-Figure1-1.png": {
        "NCLR Clustering using UBM": {
            "function": "",
            "absolute_position": "at the bottom",
            "relative_position": "below \"Viterbi Resegmentation.\""
        },
        "strong negative connotation(O:N)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y09-1035-Figure1-1.png": {
        "w(f)": {
            "function": "",
            "absolute_position": "in the center of the figure",
            "relative_position": "to the right of the \"TST\" module and to the left of the \"DEV\" module."
        },
        "Speech Recognition Engine": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/O01-1010-Figure2-1.png": {
        "Spontaneous Conversations": {
            "function": "to handle or recognize spontaneous conversations.",
            "absolute_position": "third level, fourth box from the left.",
            "relative_position": "under 'Speaking variations', which is under 'Phonetically oriented'."
        },
        "Frankenbot": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P15-1142-Figure2-1.png": {
        "(4) Execution": {
            "function": "to produce the final answer y based on the input z.",
            "absolute_position": "bottom right",
            "relative_position": "after the \"Ranking\" module and before the output \"y\"."
        },
        "Mali": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L18-1728-Figure1-1.png": {
        "Hindi WordNet": {
            "function": "",
            "absolute_position": "in the center of the figure",
            "relative_position": "above the English WordNet and in the center among the other WordNets."
        },
        "Generation of Vocabulary Tagged Lists of Tokens": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.figlang-1.4-Figure2-1.png": {
        "Transformer Encoder Layer B": {
            "function": "to process the input embeddings through a series of self-attention and feed forward operations to encode the input into higher-level feature representations suitable for downstream tasks.",
            "absolute_position": "on the central right side of the figure",
            "relative_position": "above the Embedding Layer and below the Metaphor Discrimination Layer, second from the left among the Transformer Encoder layers depicted."
        },
        "Correction": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P06-1047-Figure1-1.png": {
        "benefit independence": {
            "function": "giving technological independence from Microsoft.",
            "absolute_position": "the sixth box from the left-hand side of the figure",
            "relative_position": "to the immediate right of \"Sun\" and to the immediate left of \"Microsoft\"."
        },
        "Lexical Ontology Server": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.hackashop-1.4-Figure1-1.png": {
        "Concatenate words": {
            "function": "to combine words into a single string or sequence.",
            "absolute_position": "",
            "relative_position": ""
        },
        "session classifier": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W12-5111-Figure3-1.png": {
        "UW Meaning Generated in natural language": {
            "function": "to output the meaning of the Universal Word (UW) in natural language.",
            "absolute_position": "bottommost",
            "relative_position": "last in the sequence."
        },
        "Document text with mentions": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/M91-1028-Figure1-1.png": {
        "Syntax Analysis": {
            "function": "to analyze the structure of the given input using grammatical rules to ensure that the text is well-formed.",
            "absolute_position": "second from the top on the right side",
            "relative_position": "below \"Lexical Analysis\" and above \"Semantic Analysis\"."
        },
        "BERT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W18-6557-Figure2-1.png": {
        "Context vector": {
            "function": "to aggregate the information from the encoder to be used by the decoder for generating the output sequence.",
            "absolute_position": "right side of the figure",
            "relative_position": "between the 'Average' module and the Decoder."
        },
        "Moteur d'annotation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.dravidianlangtech-1.47-Figure3-1.png": {
        "MLP": {
            "function": "as a component of an ensemble learning system, likely serving as a classifier using a Multi-Layer Perceptron architecture.",
            "absolute_position": "",
            "relative_position": ""
        },
        "NI-LOC": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D18-2009-Figure3-1.png": {
        "Train Model": {
            "function": "classification (target identification) and learning-to-rank (candidate suggestion).",
            "absolute_position": "bottom right",
            "relative_position": "below \"Extract Features\" and to the right of \"Prediction and Correction\"."
        },
        "English Hindi Dictionary": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2007.jeptalnrecital-poster.26-Figure1-1.png": {
        "Lexique phonetique": {
            "function": "",
            "absolute_position": "second from the top on the left column",
            "relative_position": "immediately below \"Correcteur orthographique : Aspell\"."
        },
        "Train": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-emnlp.13-Figure3-1.png": {
        "Score = f(u,v)": {
            "function": "to calculate a score representing the relationship or relevance between the two inputs u and v.",
            "absolute_position": "top right corner of figure (b).",
            "relative_position": "above the 'u' and 'v' pooling modules, within the multi-tower architecture diagram."
        },
        "Translate": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/I08-3015-Figure3-1.png": {
        "Dictionaries": {
            "function": "to provide a reference of words and their attributes necessary for the processing steps in the natural language processing engine, such as stemming, lexical analysis, and tagging.",
            "absolute_position": "right-center in the figure",
            "relative_position": "directly to the right of the 'Stemmer' module."
        },
        "Polarity Values": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/J03-2003-Figure2-1.png": {
        "although it contains gestodene.": {
            "function": "to express a contrasting point or condition to the main clause, indicating a concession.",
            "absolute_position": "on the right side of the diagram within the labeled section \"The FDA approves Elixir although it contains gestodene.\", under the \"SATELLITE\" part of the diagram for example (8b).",
            "relative_position": "at the end of the sentence within the box in diagram (8b), following the clause \"The FDA approves Elixir\"."
        },
        "what": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.nlpmc-1.3-Figure1-1.png": {
        "phase n": {
            "function": "",
            "absolute_position": "in the middle",
            "relative_position": "between Phase n-1 and Phase n+1."
        },
        "IIparis": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.naacl-main.47-Figure1-1.png": {
        "T5 / TO Filter Model": {
            "function": "to filter explanation candidates based on acceptability labels provided by crowdworkers.",
            "absolute_position": "lower center of the image",
            "relative_position": "in between the \"GPT-3 DaVinci\" module at the bottom and the \"Explanation-Level Evaluation\" module at the top."
        },
        "Fine-tuning (Bert, Roberta, and Electra)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/R11-1052-Figure1-1.png": {
        "offline linguistic annotation": {
            "function": "to provide an annotated corpus for the system, which is likely used for training or evaluating the performance of the linguistic models within the system.",
            "absolute_position": "top-center",
            "relative_position": "above the \"online server\" module and to the left of the \"gold standard database\" module."
        },
        "Bridge Reasoner": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-acl.176-Figure2-1.png": {
        "Bridget": {
            "function": "",
            "absolute_position": "central-lower part of the figure",
            "relative_position": "between Hicox and Sgt #1."
        },
        "sentence-level paraphrases": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W09-0705-Figure1-1.png": {
        "Evaluation Data": {
            "function": "to provide a set of data used to assess the performance of the chosen algorithm after it has been trained.",
            "absolute_position": "sixth from the top",
            "relative_position": "below \"Store Data in Memory\" and above \"Generate Lemma.\""
        },
        "GR1t": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.emnlp-main.540-Figure2-1.png": {
        "Charge Aware Fusion Law Aware Fusion": {
            "function": "to integrate and process information related to charges and laws for further analysis.",
            "absolute_position": "third from the left",
            "relative_position": "immediately following the 'Document-level Feature Extraction' module within the 'Feature Extraction' stage."
        },
        "DB Checker": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-industry.29-Figure3-1.png": {
        "Aggregator": {
            "function": "combining or processing information from multiple sources or layers before passing it to a subsequent level or module.",
            "absolute_position": "top-center of the figure",
            "relative_position": "above Layer 1, Layer 2, Layer 3, and Layer 4."
        },
        "Transformer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/K19-2005-Figure3-1.png": {
        "Word Embedding": {
            "function": "to transform words into numerical form to facilitate processing and pattern recognition by the model.",
            "absolute_position": "at the bottom center of the figure",
            "relative_position": "directly below the 'Node Prediction' module, at the lowest level of the depicted hierarchy."
        },
        "UGCL": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.474-Figure1-1.png": {
        "Translated Sentence": {
            "function": "to provide the output of a translation process, which is to be used in subsequent stages of the system depicted in the diagram.",
            "absolute_position": "bottom",
            "relative_position": "to the right of the \"Source Sentence\" module and at the bottom of the diagram."
        },
        "[CLS]": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/K15-2013-Figure1-1.png": {
        "Explicit Relation Parser": {
            "function": "to parse and analyze explicitly stated relations between elements within a text.",
            "absolute_position": "second from the top, on the left side.",
            "relative_position": "directly below the \"Discourse Relation Parser\" and to the left of the \"Non-Explicit Relation Parser\"."
        },
        "Corpora": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-main.56-Figure1-1.png": {
        "Token 2": {
            "function": "representing an individual word or subword unit in the input document to be processed by the transformer-based encoder in a neural network architecture.",
            "absolute_position": "second from the left",
            "relative_position": "immediately to the right of Token 1."
        },
        "URL extractor": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.icon-main.18-Figure2-1.png": {
        "English Content": {
            "function": "Unknown.",
            "absolute_position": "in the lower center area of the figure, within the set of boxes labeled \"Baseline Modules.\"",
            "relative_position": "below and slightly to the right of the \"Graphical Modules\" section, and to the left of the \"Output Analysis\" section within the diagram."
        },
        "Building emotion-provoking event corpus (section 3.2)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y14-1047-Figure1-1.png": {
        "Integration": {
            "function": "to combine the results of N-grams and the proposed features for further processing in the system.",
            "absolute_position": "fourth from the left on the second row of the chart.",
            "relative_position": "directly after the 'SVM classification' block and before the 'Output (Classification result)' in Module 4."
        },
        "Generator": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-emnlp.40-Figure3-1.png": {
        "Generator": {
            "function": "to generate text or data that fills in the masked part of the input text.",
            "absolute_position": "in the center of the figure",
            "relative_position": "to the left of the Discriminator module."
        },
        "Text Encoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-4341-Figure4-1.png": {
        "repeated apply-dialog-task-spec-update update-dialog-task-state(result_available)": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "786.09 Other (7/7)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y06-1010-Figure1-1.png": {
        "Parallel text based translation": {
            "function": "to retrieve and translate previously registered sentences using parallel texts.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Reperage des EN": {
            "absolute_position": "",
            "relative_position": "",
            "function": "unknown."
        }
    },
    "/data_share/data/acl_parse/figure/W15-5948-Figure8-1.png": {
        "Authentication": {
            "function": "",
            "absolute_position": "at the bottom center of the figure",
            "relative_position": "below the \"Cross-verification with SL and TL reference corpus\" module and at the center relative to the entire diagram."
        },
        "ADJUNCT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.ranlp-1.7-Figure1-1.png": {
        "Types of Noise in NLP": {
            "function": "to categorize different kinds of noise encountered in natural language processing (NLP).",
            "absolute_position": "in the center of the figure",
            "relative_position": "at the center connecting various categories of noise in NLP such as Grammatical Errors, Orthography, Disfluencies in Human (transcribed) Data, among others."
        },
        "Slot Fillers": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.naacl-srw.2-Figure1-1.png": {
        "Response (r)": {
            "function": "to generate the final output text based on the input utterance and the relevant information retrieved from the documents.",
            "absolute_position": "on the right side of the diagram, near the bottom corner.",
            "relative_position": "after the seq2seq Generator in the flow of the diagram, and before the final output phrase enclosed in quotes."
        },
        "Performance Evaluation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W14-5304-Figure1-1.png": {
        "Tagger 2 (4.7)": {
            "function": "",
            "absolute_position": "the second module from the top, on the right-hand side.",
            "relative_position": "immediately following the 'Cognate pair extraction using CSMT model' process."
        },
        "Arbitrate Information": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C04-1164-Figure5-1.png": {
        "VLiT": {
            "function": "",
            "absolute_position": "center top",
            "relative_position": "in the middle of the top row."
        },
        "keyword spotter": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-2604-Figure1-1.png": {
        "Y22": {
            "function": "",
            "absolute_position": "second row, second column.",
            "relative_position": "directly below Y12 and to the right of Y21."
        },
        "BERT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.eacl-main.287-Figure1-1.png": {
        "Construct Sentence-Level Graph": {
            "function": "to create a graph structure that represents the relationships and interactions between different sentences in the document.",
            "absolute_position": "second from the left in the top row.",
            "relative_position": "immediately to the left of the 'Compute the relationship between sentences' module."
        },
        "Class AbbreviationExpansion": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.deelio-1.3-Figure1-1.png": {
        "Lexical Resource": {
            "function": "to provide synonyms for the important words identified by the scoring function.",
            "absolute_position": "in the center, towards the right of the image",
            "relative_position": "between the \"Important Words\" module on the left and the \"Synonym sets\" and \"Input with words replacements\" modules on the right."
        },
        "TM (with aligned IMWE)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W07-1906-Figure6-1.png": {
        "Representation Feeds Forward": {
            "function": "to take the accumulated information from dialogue history, interaction history, affect towards the system, and familiarity with the system, and use it to inform future interactions and dialogue generation.",
            "absolute_position": "at the bottom-right corner of the figure.",
            "relative_position": "below the main diagram next to the text \"Dialogue History, Interaction History, Affect towards system, Familiarity with System\"."
        },
        "c,d": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-6717-Figure1-1.png": {
        "Member State Public Services": {
            "function": "",
            "absolute_position": "bottom-right",
            "relative_position": "within the bottom section of the overall diagram, specifically in the lower-right corner of the inner, central block (outlined in blue with dashed lines)."
        },
        "mGPT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L18-1121-Figure5-1.png": {
        "Kinect output Kinect v2": {
            "function": "motion tracking.",
            "absolute_position": "bottom right corner.",
            "relative_position": "at the end/bottom of the 'Motion tracking' column, beneath 'Mics (Tascam, headsets)'."
        },
        "Difficulty Context": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to assign dependence relations and rhetorical relations in context-dependent interpretation."
        }
    },
    "/data_share/data/acl_parse/figure/2022.findings-naacl.153-Figure2-1.png": {
        "Partial Label Learning": {
            "function": "to learn from data where each instance is associated with a set of candidate labels, only one of which is correct, to improve model training or prediction.",
            "absolute_position": "lower middle",
            "relative_position": "between the \"Unlabeled Dataset\" on the left and \"Selection\" on the right."
        },
        "Attention Distribution Translation Probabiity": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/I08-1060-Figure3-1.png": {
        "Classifier": {
            "function": "to take input data, apply an algorithm to categorize or predict outcomes, and produce classifications or predictions as output.",
            "absolute_position": "at the bottom center of the figure.",
            "relative_position": "to the right of the \"Development (Test) data\" section and below the \"Adjusting parameters\" section."
        },
        "Generation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P93-1021-Figure1-1.png": {
        "Discourse Source KB Knowledge": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "STUDY": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W14-5404-Figure2-1.png": {
        "Outlier elimination based on RF proximity matrix": {
            "function": "to remove outliers using a proximity matrix generated by a random forest algorithm.",
            "absolute_position": "fourth from the left in the top sequence of modules",
            "relative_position": "immediately after 'RF construction (textual features)'."
        },
        "Major Voting": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/O01-2003-Figure4-1.png": {
        "IMP-CART": {
            "function": "IMP boundary detecting.",
            "absolute_position": "the second box from the top, in the middle column of the diagram.",
            "relative_position": "below the \"PW-CART\" module and above the \"INP-CART\" module."
        },
        "Training data": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P13-1173-Figure2-1.png": {
        "display": {
            "function": "",
            "absolute_position": "bottom right",
            "relative_position": "below 'screen' and to the right of 'nice'."
        },
        "Conversational Dialog Manager": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-4626-Figure1-1.png": {
        "Weighted Average": {
            "function": "to combine different softmax outputs by assigning different weights to them before producing a final output score.",
            "absolute_position": "bottom center",
            "relative_position": "between \"Averaged Softmax\" output/connection and the \"Score\" module."
        },
        "NarrativeRole": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.acl-demos.11-Figure3-1.png": {
        "Textual Event Extraction": {
            "function": "to extract events from text using methods such as Bi-LSTM CRFs for Coarse-Grained Event Extraction and CNN for Argument Extraction, and further refine event typing through FrameNet & Dependency based Fine-Grained Event Typing and Rule-based Fine-Grained Event Typing.",
            "absolute_position": "in the bottom center of the figure, within the lower set of modules.",
            "relative_position": "immediately below 'Textual Entity Coreference' and above 'Textual KB', in between 'Textual Relation Extraction' on the right and 'Textual Mention Extraction' on the left."
        },
        "Hypertext planner": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.lrec-1.225-Figure3-1.png": {
        "DER": {
            "function": "",
            "absolute_position": "third from the left in the bottom row of modules.",
            "relative_position": "directly below the module labeled 'INF'."
        },
        "GR-bigrams extracted for lovely' 1. \"lovely holidays": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/U17-1015-Figure1-1.png": {
        "Error Detection": {
            "function": "to detect errors in the OCR output by preprocessing the data, extracting relevant features, and classifying possible errors.",
            "absolute_position": "bottom left corner of the figure",
            "relative_position": "immediately following the 'OCR Output' step, before the 'Error Correction' module on the right."
        },
        "m": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.semeval-1.111-Figure1-1.png": {
        "Gated Multimodal Unit (GMU)": {
            "function": "to integrate textual and visual features to produce a joint representation that can be used for making predictions.",
            "absolute_position": "in the center of the figure",
            "relative_position": "between the 'Textual Features' and 'Softmax Probabilities' modules."
        },
        "Fusion": {
            "absolute_position": "",
            "relative_position": "",
            "function": "combining textual and visual features to generate softmax probabilities for predictions."
        }
    },
    "/data_share/data/acl_parse/figure/R19-1146-Figure1-1.png": {
        "Score Inlts": {
            "function": "to evaluate the information items (InIts) based on some criteria.",
            "absolute_position": "right-lower quadrant of the figure",
            "relative_position": "to the right of 'Simplified Text' and below 'Generate Inlts'."
        },
        "Gazetteer Matcher": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-7417-Figure2-1.png": {
        "Consequence": {
            "function": "to describe the outcome or impact of a situation or event within the discursive categories.",
            "absolute_position": "on the bottom center of the figure.",
            "relative_position": "directly below the central title \"Discursive Categories\" and between the \"Recapitulation\" and \"Method\" modules."
        },
        "Final Result": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W19-6307-Figure3-1.png": {
        "Add success value": {
            "function": "to update the learning system with the positive outcome or successful recognition of an item by adding a success metric or incrementing a score associated with the item.",
            "absolute_position": "bottom-right corner of the figure",
            "relative_position": "after the decision diamond checking if the item has been [seen before] and before the next decision diamond in the sequence."
        },
        "Select by Index": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P06-2024-Figure3-1.png": {
        "Alignment": {
            "function": "",
            "absolute_position": "on the bottom center part of the image, inside the Structural Tier box.",
            "relative_position": "below the Media Tier and Locational Tier boxes and above the Featural Tier boxes."
        },
        "Conflict Resolution": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/E12-2013-Figure3-1.png": {
        "diagnostic": {
            "function": "to identify and possibly analyze problems within the routine processing flow.",
            "absolute_position": "in the middle of the diagram, centered vertically between the 'meta-layer processing' and 'routine processing' labels, and slightly to the left of center horizontally.",
            "relative_position": "between the first 'diagnostic' module on the left and the second 'diagnostic' module on the right within the 'meta-layer processing' layer."
        },
        "In linguistics, deixis is the use of general words and phrases to refer ...": {
            "absolute_position": "",
            "relative_position": "",
            "function": "unknown."
        }
    },
    "/data_share/data/acl_parse/figure/W18-4909-Figure3-1.png": {
        "Dense Layer": {
            "function": "to perform a linear transformation followed by an optional non-linear activation on the input data.",
            "absolute_position": "third from the left",
            "relative_position": "between the Embedding Layer and the Softmax Layer."
        },
        "DISCHARGE": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/E14-1050-Figure2-1.png": {
        "αs1+(1-α)s2": {
            "function": "to combine two scores, S1 and S2, using a weighted average where α is the weight for S1 and (1-α) is the weight for S2.",
            "absolute_position": "at the bottom-center of the figure",
            "relative_position": "directly above the \"Compositionality score\" label and below the two modules labeled \"S1\" and \"S2\"."
        },
        "Debt Instrument Convertible Conversion Price": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W13-3521-Figure1-1.png": {
        "Spanish DIHANA Corpus (Training Set)": {
            "function": "to provide data for training the semantic model in a speech translation system.",
            "absolute_position": "in the bottom right quadrant of the figure, below the central dashed line that separate \"TEST\" and \"TRAINING\" sections, and slightly to the right of the figure's center.",
            "relative_position": "immediately to the right of the \"Semantic Model Learning\" module and connected to it with an arrow pointing to the left, indicating that it is part of the \"TRAINING\" process for semantic model learning."
        },
        "cosine-sim (u,v)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-5016-Figure1-1.png": {
        "80% 20%": {
            "function": "",
            "absolute_position": "in the center-right part of the figure",
            "relative_position": "between the output layers (BERT (Cased), BERT (Uncased), BiLSTM, XGBoost) and the decision rule box leading to the Result."
        },
        "Arbitrary QA model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.louhi-1.14-Figure1-1.png": {
        "Data (Annotated) for Training Classifier": {
            "function": "to provide labeled data for the purpose of training a machine learning classifier.",
            "absolute_position": "third column, second row",
            "relative_position": "center left."
        },
        "Interaction Network ": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N18-1185-Figure1-1.png": {
        "Scene Sentence": {
            "function": "",
            "absolute_position": "in the center of the figure",
            "relative_position": "between the \"elastic\" logo on the left and \"Check Relevancy\" on the right."
        },
        "Adjudication": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.emnlp-main.294-Figure1-1.png": {
        "BERT Encoder": {
            "function": "to generate representations (feature vectors) for both the input document and the summary for further processing or evaluation.",
            "absolute_position": "the bottom center of the figure",
            "relative_position": "below the \"Evaluator\" module and above the \"contrastive loss\" annotation."
        },
        "Universal Prompt Encoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.naacl-srw.23-Figure2-1.png": {
        "Query": {
            "function": "to input the user's question or search term into the system for processing.",
            "absolute_position": "at the bottom center of the figure",
            "relative_position": "below the \"RoBERTa\" module and to the left of the \"Passages\" block."
        },
        "What do you think about the ostrich, where should that card be?": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-long.225-Figure1-1.png": {
        "PLM": {
            "function": "to generate by sampling.",
            "absolute_position": "on the bottom right within the grey dashed outline.",
            "relative_position": "to the right of the \"Prompt\" block and below the \"Knowledge 2\" block within the same outline."
        },
        "MITRE JDAS Audio": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2009.jeptalnrecital-court.10-Figure1-1.png": {
        "Extraction des passages": {
            "function": "the manual extraction of evaluative passages.",
            "absolute_position": "third from the left",
            "relative_position": "center."
        },
        "Backward Encoder Forward Encoder MTL System Soft-Decoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W15-5004-Figure2-1.png": {
        "morpheme-level reordering": {
            "function": "to reorder morphemes within a sentence or phrase to align with the grammatical or syntactical structure required by the target language.",
            "absolute_position": "at the bottom center of the figure, below the chunk-level reordering module.",
            "relative_position": "the second module from the top in the vertical arrangement of modules."
        },
        "Annotation Manager": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C16-1263-Figure1-1.png": {
        "PARENT": {
            "function": "Unknown.",
            "absolute_position": "bottom of Figure 2",
            "relative_position": "below SON and to the left of FATHER."
        },
        "N-Grammes de Mots": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.ecnlp-1.11-Figure2-1.png": {
        "Word context state in all reviews": {
            "function": "to maintain the context of words across all reviews in the model.",
            "absolute_position": "bottom-left",
            "relative_position": "below the \"Class-based word representation in all reviews\" module and to the left of the \"Last GRU state of review i\" module."
        },
        "MINIMIZE COSTS": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/1987.tc-1.3-Figure17-1.png": {
        "MOTORESCARACTERISTICAS DE SERVICIO": {
            "function": "",
            "absolute_position": "top of the page",
            "relative_position": "above all other elements on the page."
        },
        "landed(hurricane)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W09-2805-Figure1-1.png": {
        "Induction (Aleph)": {
            "function": "",
            "absolute_position": "third from the top and last in the sequence.",
            "relative_position": "directly below \"Bubble Examples\" and above \"Sentence Reduction Rules\"."
        },
        "Extended Query": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-5105-Figure1-1.png": {
        "who spend their Christmases manning soup kitchens": {
            "function": "to provide an example of people who engage in charitable activities during the holiday season.",
            "absolute_position": "center top",
            "relative_position": "between \"who are major benefactors\" and \"Think about Bill Gates and all the wonderful things that his money is doing.\""
        },
        "ILP": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S19-1004-Figure1-1.png": {
        "sentence encoder": {
            "function": "to encode sentences S1 and S2 into representations h1 and h2.",
            "absolute_position": "bottom right corner.",
            "relative_position": "below the 'relation representation' module and to the right of the first 'sentence encoder' module."
        },
        "Word vectors per document": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P17-1084-Figure6-1.png": {
        "LSTM": {
            "function": "to process sequential data, maintain information over time, and make predictions or decisions based on both the current input and the information it has retained from previous inputs.",
            "absolute_position": "fifth from the left",
            "relative_position": "last on the left before the ellipsis and arrows pointing rightward."
        },
        "Edge Types Virtual Types Node Types Text": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-long.146-Figure2-1.png": {
        "Xn": {
            "function": "Unknown.",
            "absolute_position": "at the bottom right corner of the diagram, within the Sequence Encoder section.",
            "relative_position": "the last module in the sequence of inputs from X_1 to X_n shown in the Sequence Encoder."
        },
        "grammar basec LM": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y08-1017-Figure4-1.png": {
        "Trigram Score Reinforcement": {
            "function": "to reinforce the significance or reliability of trigram scores in the evaluation process.",
            "absolute_position": "bottom center",
            "relative_position": "directly below the 'n-gram Look-Up and Trigram Score Computation' module."
        },
        "PERSON wife of PERSON": {
            "absolute_position": "",
            "relative_position": "",
            "function": "unknown."
        }
    },
    "/data_share/data/acl_parse/figure/W11-2311-Figure3-1.png": {
        "Google Tashkeel": {
            "function": "adding diacritics to Arabic text.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Cherbourg, FR": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.aacl-main.79-Figure6-1.png": {
        "discriminator": {
            "function": "to determine whether the inputs it receives are authentic or artificially generated.",
            "absolute_position": "bottom right corner",
            "relative_position": "at the end of the process flow, after 'generate'."
        },
        "Pseudo Knowledge": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.eacl-main.134-Figure1-1.png": {
        "Germany :: country": {
            "function": "",
            "absolute_position": "bottom left",
            "relative_position": "below the \"album :: m item\" module and to the left of the \"Vector Concatenation\" label."
        },
        "sfn:dangerous": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.dravidianlangtech-1.5-Figure1-1.png": {
        "Transliteration": {
            "function": "to convert text from one script to another.",
            "absolute_position": "in the lower center part of the image, between \"Data Preprocessing\" and \"Combine Datasets\" modules.",
            "relative_position": "it is the second module in the process flow starting from \"Code-mixed data\" and is directly above the \"Combine Datasets\" module."
        },
        "786.09 Other (7/7)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W15-2609-Figure2-1.png": {
        "Machine learning": {
            "function": "to analyze and interpret data that has been pre-processed to support automatic coding.",
            "absolute_position": "top right corner.",
            "relative_position": "after 'Pre-processing' and before 'Automatic coding'."
        },
        "fluffy": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2014.iwslt-evaluation.12-Figure2-1.png": {
        "Gender and Bandwitdth detection": {
            "function": "to determine the gender of the speaker and the bandwidth of the audio signal within an audio processing system.",
            "absolute_position": "bottom center",
            "relative_position": "below \"Speech Detection\" and to the left of \"Speaker clustering (GMM based)\"."
        },
        "Web-search using template (Vr+NP) by (Va+*)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N16-1159-Figure1-1.png": {
        "Shallow Parser": {
            "function": "to analyze the grammatical structure of a sentence up to a certain level of depth without fully parsing it, typically identifying phrases and some grammatical relationships between them.",
            "absolute_position": "bottom center",
            "relative_position": "below the \"POS Tagger\" and to the left of the \"Output\"."
        },
        "NMT Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.conll-1.46-Figure1-1.png": {
        "ALT": {
            "function": "",
            "absolute_position": "bottom right",
            "relative_position": "below all other modules in the figure."
        },
        "Extractions from the main dictionary": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W99-0203-Figure2-1.png": {
        "Language module": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Analysis and insertion of TM matches": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-4326-Figure1-1.png": {
        "Language Model": {
            "function": "to predict discourse connectives based on training data and sense frequency.",
            "absolute_position": "top right",
            "relative_position": "to the right of \"Training data\" and above \"Predicted Discourse Connectives\"."
        },
        "training set containing 9 entity types (counts for MN and TN are both 8)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-1547-Figure2-1.png": {
        "Actuator": {
            "function": "Natural Language Question Generation.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Affix nin": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-1556-Figure2-1.png": {
        "self-Attention": {
            "function": "to weigh the importance of different tokens within the input sequence to focus on more relevant parts when processing data.",
            "absolute_position": "on the left side of the figure, in the center.",
            "relative_position": "between the 'Independent GRUs' at the bottom and the 'MFN' at the top."
        },
        "Docunent collection": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W13-4411-Figure1-1.png": {
        "Fetcher": {
            "function": "to retrieve and possibly store data from a variety of sources as input for the module named 'Pattern Matcher'.",
            "absolute_position": "",
            "relative_position": ""
        },
        "end": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C00-2154-Figure4-1.png": {
        "Expansion slot": {
            "function": "Unknown.",
            "absolute_position": "bottom-left",
            "relative_position": "below \"Knowledge-Based MT.\""
        },
        "Generate: 5-letter code (toneless) Code-to-item index": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2018.gwc-1.6-Figure3-1.png": {
        "Manual evaluation and correction": {
            "function": "to manually evaluate and correct the automatic mapping process.",
            "absolute_position": "center",
            "relative_position": "between 'mapping' on the left side and 'corpus statistics: most frequent terms*' on the right side."
        },
        "Pre-processing": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.cl-3.16-Figure1-1.png": {
        "Writing Systems": {
            "function": "to categorize different types of writing systems.",
            "absolute_position": "top-center",
            "relative_position": "root of the diagram."
        },
        "lettre voyelle": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/J15-1005-Figure4-1.png": {
        "transfer classifier": {
            "function": "to classify data by applying knowledge learned from a source domain to a target domain.",
            "absolute_position": "the bottom center of the figure",
            "relative_position": "below the \"source classifier\" and \"transformed target corpus\" modules."
        },
        "FILTER": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/O06-4001-Figure5-1.png": {
        "Queue": {
            "function": "to hold and manage data or tasks waiting to be processed in a specific order.",
            "absolute_position": "in the center towards the bottom left of the figure",
            "relative_position": "between the 'New Seed' module and the 'Wrapper' module, below 'An NE' and 'NE Ontology' modules."
        },
        "Target - Target": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-acl.425-Figure2-1.png": {
        "Channel Selector": {
            "function": "to select specific channels (features) from the output of a neural network layer, typically for the purpose of enhancing certain signal features while attenuating others, as part of dimensionality reduction or feature refinement processes.",
            "absolute_position": "in the lower half of the image, centered horizontally within the bottom diagram.",
            "relative_position": "between the multi-colored vertical bars on the left and the 'W1' representation to its immediate right."
        },
        "Machine Learning Model.": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W17-7406-Figure5-1.png": {
        "communicative function": {
            "function": "",
            "absolute_position": "it is near the bottom right of the figure.",
            "relative_position": "it is directly connected beneath the \"dimension\" box and is adjacent to the \"qualifier\" box on the right."
        },
        "Result": {
            "absolute_position": "",
            "relative_position": "",
            "function": "unknown."
        }
    },
    "/data_share/data/acl_parse/figure/I08-7016-Figure2-1.png": {
        "Tagged Text Corpus": {
            "function": "to store texts where words have been annotated with their corresponding parts of speech or other grammatical information.",
            "absolute_position": "bottom left corner of the diagram",
            "relative_position": "after the 'Tagger' module and before the 'Parser' module."
        },
        "LINKS": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.acl-main.613-Figure1-1.png": {
        "NMT Model EN -> Target": {
            "function": "to translate text from English to a target language within a neural machine translation system.",
            "absolute_position": "bottom right corner of the diagram.",
            "relative_position": "directly below the 'CLEF eHealth Collection (EN)' module and to the right of the 'NMT Model Source -> EN' module on the bottom."
        },
        "S-Classifier": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N19-1009-Figure1-1.png": {
        "Decoder Attention": {
            "function": "to focus on specific parts of the input sequence when decoding the output sequence, thereby allowing the model to produce more accurate results by considering the context of the input.",
            "absolute_position": "near the top center of the figure.",
            "relative_position": "above the \"Encoder Last Layer\" and to the left of the \"Phoneme CTC\"."
        },
        "C2": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W03-0316-Figure1-1.png": {
        "about": {
            "function": "",
            "absolute_position": "fourth from the left, top row",
            "relative_position": "in the middle of the top row."
        },
        "Multi-head Attention Layer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/H05-1075-Figure2-1.png": {
        "Data Cleaner Sentence breaker Topic Identification": {
            "function": "to clean web page data, segment it into sentences, and identify the topics of those sentences.",
            "absolute_position": "center-left",
            "relative_position": "between \"Web Pages\" and \"Clean Topic Sentences\"."
        },
        "Transformer-Based Answer Set": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/I08-3008-Figure2-1.png": {
        "PARSER 1": {
            "function": "to parse the 'Swedish Acquis' as indicated by the input arrow from 'Swedish Acquis 1,' producing output that is used in the 'Swedish test' and fed back into 'RESTUFF.'",
            "absolute_position": "lower-central part of the image",
            "relative_position": "below 'Swedish Acquis 1' and to the left of 'RESTUFF'."
        },
        "Candidate Parallel Sentences": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L18-1173-Figure5-1.png": {
        "Cleaning step using SPLIT tool": {
            "function": "to clean the raw data as the first step in the data processing workflow.",
            "absolute_position": "second from the top",
            "relative_position": "below 'Raw Data' and above 'Automatic tagging step (Named entities tokens, latin tokens...etc) using AIDA2'."
        },
        "TFIDF Vectorizer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.crac-1.1-Figure1-1.png": {
        "Text Prediction": {
            "function": "",
            "absolute_position": "bottom center",
            "relative_position": "at the end of the process flow within the larger module."
        },
        "soft prediction1": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.acl-long.361-Figure2-1.png": {
        "Encoder": {
            "function": "to transform sentences into embeddings or vector representations that can be used to compute similarity for ranking and contrastive loss purposes.",
            "absolute_position": "on the bottom right side of the figure",
            "relative_position": "below and to the right of the \"Label\" and \"Contrastive Loss\" elements, and to the left of \"Ranking Loss\"."
        },
        "Joan Laporta": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W11-0505-Figure6-1.png": {
        "Airbus A320 family": {
            "function": "",
            "absolute_position": "top-left",
            "relative_position": "above and to the left of the \"2009 flu pandemic by country\" module."
        },
        "Sentences": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/U03-1013-Figure6-1.png": {
        "Answer": {
            "function": "to provide the result of a process or to output a decision based on earlier steps in the flowchart.",
            "absolute_position": "bottom right corner of the diagram",
            "relative_position": "just to the right of the \"Select the Most Frequent Sense\" module."
        },
        "Feature Computation Module": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/I08-2095-Figure4-1.png": {
        "abcd": {
            "function": "",
            "absolute_position": "at the top center of the figure.",
            "relative_position": "it is the parent node or root node for all other modules shown in the figure."
        },
        "has-property": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/1989.mtsummit-1.27-Figure4-1.png": {
        "Clause 1": {
            "function": "",
            "absolute_position": "top center of the figure",
            "relative_position": "above all the other elements in the diagram."
        },
        "Teacher Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W14-4713-Figure6-1.png": {
        "axeme UNL": {
            "function": "",
            "absolute_position": "near the top right corner of the figure.",
            "relative_position": "to the right of 'axeme FRA' and above 'axeme RUS'."
        },
        "Claim: David Beckham is an american scientist": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W15-4727-Figure2-1.png": {
        "Query evaluator": {
            "function": "to process and assess user queries and preferences against data sources to facilitate the generation of textual summaries.",
            "absolute_position": "in the center",
            "relative_position": "between the 'Persistent data' on the left and the 'Textual summaries generator' on the right."
        },
        "SMT": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-3209-Figure1-1.png": {
        "Feature-Based Opinion Mining": {
            "function": "",
            "absolute_position": "on the right side of the figure, middle height.",
            "relative_position": "to the right of \"Lexicons\" within the flow chart diagram."
        },
        "Latent representation z": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W10-1003-Figure4-1.png": {
        "Grammar checking": {
            "function": "to analyze and correct grammatical errors in a text.",
            "absolute_position": "top right corner of the figure",
            "relative_position": "to the right of \"Spell checking\" module and above the \"Exercise-specific lexicon.\""
        },
        "Backend": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C16-1190-Figure1-1.png": {
        "SPORT": {
            "function": "",
            "absolute_position": "5th from the left",
            "relative_position": "immediately after \"'S\" and before \"?\"."
        },
        "Chinese Electronic Dictionary": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W16-4502-Figure1-1.png": {
        "Output": {
            "function": "to display the final translated and reassembled sentence after processing through the various translation and selection modules in the diagram.",
            "absolute_position": "lower right.",
            "relative_position": "to the right of the \"Sentence recomposition\" and \"Translation with different MT systems\" modules and below the \"Sentence tokenization\" module."
        },
        "Action Application MLPapply": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.ranlp-1.148-Figure2-1.png": {
        "Compute OT distance": {
            "function": "to calculate the optimal transport distance between two distributions.",
            "absolute_position": "near the top, center of the figure",
            "relative_position": "above the \"Weight of each word\" and \"Softmax\" layers, and below the \"A regression based training objective\" text."
        },
        "Vowel Decoder (GRU)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P07-2004-Figure2-1.png": {
        "subjIdx=I": {
            "function": "to indicate the index of the subject in the sentence or clause structure.",
            "absolute_position": "in the center of the figure",
            "relative_position": "between the left and right modules."
        },
        "XLM RoBERTa XLNI": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W12-3622-Figure2-1.png": {
        "Community Manager": {
            "function": "to manage the association between annotators and tasks.",
            "absolute_position": "in the center of the figure",
            "relative_position": "between the annotators and task servers, above the Task Manager."
        },
        "obj1 1": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W13-3201-Figure1-1.png": {
        "semantic parsing": {
            "function": "to convert natural language input into logical form.",
            "absolute_position": "at the center of the figure",
            "relative_position": "between the 'Input' and the 'Log. Form' blocks."
        },
        "Tail MLP": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P03-2017-Figure3-1.png": {
        "output text": {
            "function": "to generate the final text product that results from the given input text, semantics, grammar, and subsequent processing.",
            "absolute_position": "center-right",
            "relative_position": "to the right of the \"semantics\" module and below the \"author\" module."
        },
        "2. C2 creates nugget group (1st Round)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D18-1398-Figure1-1.png": {
        "MetaTrain": {
            "function": "to train the model on a variety of learning tasks, each intended to simulate an episode of few-shot learning, as part of the meta-learning process.",
            "absolute_position": "roughly in the center of the image",
            "relative_position": "in the center of the Meta Learning section."
        },
        "Sample Data and Train Match Function": {
            "absolute_position": "center-left",
            "relative_position": "between \"Universal Lexical Representation\" and \"Translation Task Generator.\"",
            "function": "to train the model on a variety of learning tasks, enabling it to generalize from the training tasks to new tasks with fast adaptation."
        }
    },
    "/data_share/data/acl_parse/figure/C12-3013-Figure1-1.png": {
        "Paradigm Selector": {
            "function": "",
            "absolute_position": "at the bottom center of the figure.",
            "relative_position": "below the \"FSA\" and \"Verb Paradigm Repository\" modules and above the \"Verb Lexicon\" and between the \"Corpus\" and \"VPL: Verb Paradigm List\" modules."
        },
        "Cleaning": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S15-2111-Figure1-1.png": {
        "Word embedding": {
            "function": "to convert words into numerical vectors that capture semantic meaning, which can be used for processing in machine learning models.",
            "absolute_position": "bottom center",
            "relative_position": "within the 'Topical sentiment distribution' section, specifically in the lower left corner inside the 'Formal text feature' box."
        },
        "Averaged Perceptron": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.ranlp-1.181-Figure1-1.png": {
        "BERTstudent (to be trained)": {
            "function": "to learn from the BERT teacher model and improve its understanding of data representations for better performance on a specific task.",
            "absolute_position": "in the lower right quadrant of the figure.",
            "relative_position": "to the right of the 'BERT_teacher (trained)' module and below the 'L_hard(Ps, y)' diagram."
        },
        "SRoBERTa": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W13-3001-Figure5-1.png": {
        "marie :: <d>1": {
            "function": "",
            "absolute_position": "the third row from the bottom",
            "relative_position": "the second box from the left in its row."
        },
        "LSTM": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-main.199-Figure2-1.png": {
        "LaserTagger": {
            "function": "to perform sequence editing operations in text, such as rephrasing, grammatical corrections, or formatting changes.",
            "absolute_position": "the second from the left in the bottom row of modules.",
            "relative_position": "immediately after the input ('In') and before a 'Transformer' module in a sequence that appears to represent a process flow from left to right in the heterogeneous edit to translate context (indicated by label (d) under the quadrant)."
        },
        "Task specific model": {
            "absolute_position": "top left",
            "relative_position": "between the 'In' and 'Out' modules in figure (a).\n\n2. Its absolute position is: bottom left",
            "function": "to perform sequence labeling tasks to edit text."
        }
    },
    "/data_share/data/acl_parse/figure/W18-2305-Figure1-1.png": {
        "Noise Filtering with PU learning": {
            "function": "to purify U by finding P-like outliers.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Action Seed Vocabulary": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.semeval-1.189-Figure1-1.png": {
        "Model": {
            "function": "",
            "absolute_position": "in the center of the lower section of the figure.",
            "relative_position": "between the \"NOT\" and \"OFF\" indicators, just above the dashed horizontal line."
        },
        "Decoding with Baseline System for SAT transforms": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.findings-emnlp.293-Figure3-1.png": {
        "Regularization Module": {
            "function": "to regularize the outputs of the teacher components before they're used to generate the soft target distribution for the student model.",
            "absolute_position": "top center",
            "relative_position": "in the center of the 'Teacher' section, between the 'LM-type Assistant'/'Copy-type Assistant' and 'Student' components."
        },
        "Core Services": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.gebnlp-1.11-Figure1-1.png": {
        "Global Competency Score": {
            "function": "to quantify an overall assessment of competency within the context depicted by the diagram, likely related to evaluations in an educational or professional training setting.",
            "absolute_position": "second from the top",
            "relative_position": "directly below \"Categorical Evaluations (of medical skills)\" and above \"Free text comments.\""
        },
        "cat": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.findings-acl.39-Figure1-1.png": {
        "I need to book a hotel in the east that has 4 stars,": {
            "function": "to express the user's request to the system to find a 4-star hotel in the east.",
            "absolute_position": "second from the top on the left-hand side",
            "relative_position": "directly below the first module on the left-hand side."
        },
        "Positional Embedding": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C08-2013-Figure2-1.png": {
        "m": {
            "function": "",
            "absolute_position": "α-0-δ-0-s-1-d-0-m",
            "relative_position": "left-right-right-left."
        },
        "(3) Generation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/R19-1058-Figure1-1.png": {
        "Cosine Neural difference Absolute Differenc Muitiplicatior": {
            "function": "to compute different measures of similarity and interaction between vectors, such as the cosine similarity, neural network-based difference, element-wise absolute difference, and element-wise multiplication.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Question Encoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S14-2047-Figure1-1.png": {
        "Negated Sentence Pairs": {
            "function": "to process patterns involving negated sentences for evaluating semantic relatedness.",
            "absolute_position": "top-right",
            "relative_position": "above the \"Existential Negation Patterns\" and to the right of the \"T.E. baseline (NEUTRAL ENTAILMENT)\"."
        },
        "Human Annotation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P10-2018-Figure1-1.png": {
        "p": {
            "function": "",
            "absolute_position": "on the second level from the top, third module from the left.",
            "relative_position": "in the center of the hierarchical structure, directly connected to all modules on the third level."
        },
        "Input": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W13-0207-Figure1-1.png": {
        "EPR": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Al System": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D17-1186-Figure1-1.png": {
        "Multi-Instances Learning CNN": {
            "function": "to process multiple instances or variations of input data through a Convolutional Neural Network (CNN) for learning and extracting relevant features to improve the performance of the model in predictive tasks.",
            "absolute_position": "in the center",
            "relative_position": "in the middle of the figure."
        },
        "Visual Encoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P10-1094-Figure1-1.png": {
        "English Sentences": {
            "function": "",
            "absolute_position": "top-center",
            "relative_position": "above all other elements."
        },
        "Lexicon-Based Polarity Classifier": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.nlposs-1.2-Figure1-1.png": {
        "Cleaning": {
            "function": "to prepare the data by removing irrelevant or erroneous content before further processing.",
            "absolute_position": "bottom center",
            "relative_position": "below \"Processors\" and to the left of \"Tokenizers\"."
        },
        "Domain Expert (Movie Search)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.emnlp-main.845-Figure1-1.png": {
        "Exaggerating?": {
            "function": "",
            "absolute_position": "bottom-left",
            "relative_position": "directly below the right module and to the left of the bottom-right module."
        },
        "Vector Representation of Tweet": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.emnlp-main.316-Figure1-1.png": {
        "##able": {
            "function": "",
            "absolute_position": "top row, third from the right.",
            "relative_position": "in the top row, after the second module from the right."
        },
        "identification of biases": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y18-1087-Figure2-1.png": {
        "Time": {
            "function": "",
            "absolute_position": "Second from the left in the third row from the top, between 'IsInThing' and 'entitynode2'.",
            "relative_position": "Directly below '1: IsInEntity' and to the left of 'entitynode2'."
        },
        "NL Gemini Parser and Generator": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P14-3013-Figure2-1.png": {
        "BCS": {
            "function": "",
            "absolute_position": "at the bottom center of the image, below \"SUMO\" and \"Synset\" nodes.",
            "relative_position": "directly connected below the \"SUMO\" node, which is in turn connected to the \"Synset\" node."
        },
        "Malais": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W14-2202-Figure1-1.png": {
        "Prepare L2 scenes": {
            "function": "",
            "absolute_position": "bottom center",
            "relative_position": "on the left within the bottom row of modules."
        },
        "m": {
            "absolute_position": "bottom row, second from the left",
            "relative_position": "to the left of 'Verify with informant' and to the right of 'Modify & add vignettes'.",
            "function": "to prepare L2 scenes."
        }
    },
    "/data_share/data/acl_parse/figure/P86-1024-FigureI-1.png": {
        "Character Recognition": {
            "function": "to recognize and interpret the individual characters from an image after it has been scanned.",
            "absolute_position": "second from the top",
            "relative_position": "below 'Image Scanning' and above 'Sentence Parsing'."
        },
        "FB-SEC-C": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.emnlp-main.208-Figure1-1.png": {
        "Attention": {
            "function": "to focus on different parts of the input sequence when decoding the output sequence, thereby helping the decoder to select which input elements to concentrate on at each step of the translation.",
            "absolute_position": "in the upper-middle part of the figure between the \"Encoder\" and \"Decoder\" boxes.",
            "relative_position": "between the encoder and decoder within the translation model structure."
        },
        "Vectorization": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.dravidianlangtech-1.3-Figure3-1.png": {
        "DRAVIDIAN LANGUAGES": {
            "function": "to represent the group of languages from the Dravidian family, specifically Tamil, Malayalam, and Telugu, which are being used in the context of the diagram, possibly for natural language processing tasks.",
            "absolute_position": "in the bottom center of the figure",
            "relative_position": "in between the left and right modules at the bottom of the diagram, directly below the mBERT QA Model in the center."
        },
        "la norma que": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C90-3038-Figure7-1.png": {
        "Results": {
            "function": "to display or store the outcome of the Recognition and Error Correction processes in the diagram.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Attention Layer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-main.303-Figure4-1.png": {
        "[CLS] Target [SEP]": {
            "function": "to act as an input token sequence representing the target text for processing by the BERT model.",
            "absolute_position": "the top right module in the bottom figure.",
            "relative_position": "the second from the bottom in the right column."
        },
        "SUMTIME- MOUSAM": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.ccl-1.88-Figure3-1.png": {
        "LSTM": {
            "function": "processing sequential information for tasks such as alignment or representation in the context of a machine learning model.",
            "absolute_position": "top center",
            "relative_position": "above the Knowledge Aligner and to the right of the Concepts Encoding section."
        },
        "Visual Attention": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y18-1046-Figure2-1.png": {
        "Substitution Injection Deletion": {
            "function": "to generate artificial error data by performing substitution, injection, and deletion operations on text data.",
            "absolute_position": "lower center of the figure",
            "relative_position": "below the 'Word + Japanese functional expression + Word' module and above the 'Artificial Error Data' module."
        },
        "nicotine \"I run on BBQ nachos and nicotine tbh\"": {
            "absolute_position": "",
            "relative_position": "",
            "function": "unknown."
        }
    },
    "/data_share/data/acl_parse/figure/L16-1599-Figure11-1.png": {
        "DAY-OF-WEEK TYPE=FRIDAY Friday": {
            "function": "to specify events or actions that should occur on Fridays.",
            "absolute_position": "second from the right",
            "relative_position": "last."
        },
        "Classification Model": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D10-1060-Figure5-1.png": {
        "like": {
            "function": "to represent an example of a transitive verb within the family of transitive verbs in the diagram.",
            "absolute_position": "bottom middle",
            "relative_position": "on the left side under the 'Family Transitive' category."
        },
        "l2 : red(2)": {
            "absolute_position": "bottom center of the figure, inside the \"Family Transitive\" box",
            "relative_position": "below the VB module tree and to the left of the \"hate\" module within the \"Family Transitive\" group.",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W13-4005-Figure2-1.png": {
        "Update Rules": {
            "function": "to dictate how the dialogue management system updates the task, linguistic, and grounded contexts during an interaction.",
            "absolute_position": "top center of the diagram",
            "relative_position": "to the right of \"Dialogue Management\" and above \"Grammar.\""
        },
        "S2S": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/S15-1003-Figure2-1.png": {
        "PPR": {
            "function": "",
            "absolute_position": "on the far right side of the figure, aligned horizontally with the center.",
            "relative_position": "to the right of the branching modules labeled with \"car.n.01,\" \"car.n.02,\" etc., and it appears to be associated with the last branch on the right side of the diagram."
        },
        "UD-Fi": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W15-5504-Figure3-1.png": {
        "hashtag:Pheme_I exicon": {
            "function": "",
            "absolute_position": "top-right",
            "relative_position": "to the right of the \"ontolex: Lexicon\" module."
        },
        "support_vector_machine; support_vector_machines; SVM;SVMs": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.constraint-1.3-Figure3-1.png": {
        "Sentiment Polarity calculation": {
            "function": "to determine the positive, negative, or neutral sentiment of linked terms associated with entities.",
            "absolute_position": "right center",
            "relative_position": "between \"Entity Sentence Linking\" and \"Role assignment.\""
        },
        "y4": {
            "absolute_position": "",
            "relative_position": "",
            "function": "sentiment polarity calculation."
        }
    },
    "/data_share/data/acl_parse/figure/W17-5005-Figure1-1.png": {
        "lexis:LanguageItem": {
            "function": "",
            "absolute_position": "",
            "relative_position": ""
        },
        "Retire (<6yrs)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2015.mtsummit-users.19-Figure1-1.png": {
        " Multi-layer Quality Controlling": {
            "function": "to provide automatic proofreading, consistency checking, and simplified English checking in the translation process.",
            "absolute_position": "at the bottom center of the figure",
            "relative_position": "below the \"Multi-aspect Translation Collaboration\" and \"Multi-channel Knowledge Pushing,\" inside the \"Careful Post-translation Management\" section."
        },
        "Classifierd": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.naacl-industry.24-Figure1-1.png": {
        "BERTBASE_CLS": {
            "function": "",
            "absolute_position": "near the center of the figure, slightly towards the top.",
            "relative_position": "between the \"Smaller dataset (gold)\" on the left and \"Larger dataset (silver)\" with two \"TinyBERT_CLS\" modules on the right."
        },
        "W-RST Discourse Evaluation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-main.146-Figure2-1.png": {
        "Entity-Aware Word Embedding": {
            "function": "to generate word embeddings that are sensitive to the entities present in the text.",
            "absolute_position": "",
            "relative_position": ""
        },
        "Recognizing textual entailment": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2009.jeptalnrecital-court.36-Figure1-1.png": {
        "Compression": {
            "function": "to reduce the size of audio or data files.",
            "absolute_position": "Near the top center of the figure, slightly to the right.",
            "relative_position": "In the upper portion of the central column, directly below the \"Conversion\" module and above \"Segmentation et suivi du locuteur.\""
        },
        "Shijiebei FIFA": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/R11-1108-Figure2-1.png": {
        "Generate N-arams": {
            "function": "to create unigrams, bigrams, and trigrams from the text data.",
            "absolute_position": "in the lower central part of the image, towards the right side.",
            "relative_position": "after the \"Stem words\" step and before the \"Filter tokens by length\" step in the flowchart, within the \"Review processing\" section."
        },
        "Review processing": {
            "function": "to tokenize the text, filter out stop words, stem words, and filter tokens by length where the length of the token is greater than 2.",
            "absolute_position": "top-right corner of the figure",
            "relative_position": "after 'Preprocessing' and before 'Generate N-grams'."
        },
        "Language Modeling": {
            "absolute_position": "the middle right of the image",
            "relative_position": "to the right of the 'Review processing' flow and below the 'Online translation' process.",
            "function": "to create sequences of one, two, or three words from text data for analysis."
        },
        "English Ontologies": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C10-2034-Figure2-1.png": {
        "SVM": {
            "function": "to find translation equivalents from bilingual web pages.",
            "absolute_position": "",
            "relative_position": ""
        },
        "infiation": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2007.tmi-papers.20-Figure3-1.png": {
        "the": {
            "function": "a determiner.",
            "absolute_position": "5th module from the left",
            "relative_position": "after the word \"specify\" and before the word \"maximum.\""
        },
        "Existing Domains": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.semeval-1.28-Figure1-1.png": {
        "Training": {
            "function": "to perform R-Drop and train the classifier.",
            "absolute_position": "third from the left",
            "relative_position": "in the middle."
        },
        "Music Transformer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.argmining-1.7-Figure2-1.png": {
        "RoBERTa with classification layer": {
            "function": "to classify the combined input text into categories such as 'Sufficient' or 'Insufficient'.",
            "absolute_position": "at the bottom center of the figure",
            "relative_position": "below the \"Fine-tuned BART generation model\" and \"combine\" modules and directly above the \"Sufficient / Insufficient Output\"."
        },
        "ATTITUDE-STYLE DISTINCTIONS": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.dravidianlangtech-1.27-Figure2-1.png": {
        "Data Preprocessing": {
            "function": "to prepare and clean memes and input texts for further processing such as feature extraction.",
            "absolute_position": "in the center left of the figure",
            "relative_position": "between the input sources (Memes and Input Texts) and the feature extraction modules (Visual Feature Extraction and Textual Feature Extraction)."
        },
        "Transformer Encoder": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.ngt-1.12-Figure1-1.png": {
        "Baseline Teacher": {
            "function": "",
            "absolute_position": "on the right side in the upper half of the figure.",
            "relative_position": "between the \"GD Teacher\" and \"Adapted Teacher\" modules towards the top of the figure."
        },
        "ASR_1": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D13-1066-Figure1-1.png": {
        "Positive Sentiment Phrases": {
            "function": "to identify or collect phrases that convey positive sentiment.",
            "absolute_position": "bottom left",
            "relative_position": "bottom center."
        },
        "Tens2": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.sigdial-1.19-Figure4-1.png": {
        "Converting the human judgments into reference scores": {
            "function": "converting the human judgments into reference scores.",
            "absolute_position": "the bottom module of the figure",
            "relative_position": "underneath \"Collecting human judgments on the speakers of the utterances\" within the Reference score preparation section."
        },
        "Documents": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.jeptalnrecital-taln.8-Figure1-1.png": {
        "Corpus de test 1": {
            "function": "",
            "absolute_position": "second from the left in the top row",
            "relative_position": "immediately to the right of 'Corpus de test 0'."
        },
        "Converting the human judgments into reference scores": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.coling-main.281-Figure2-1.png": {
        "Semantic Reconstruction": {
            "function": "to reconstruct the semantic information from the encoded features and inputs to enhance the generation of coherent output sequences in the language model.",
            "absolute_position": "at the center of the figure, slightly towards the top.",
            "relative_position": "between the 'Pointer Network' module on the left and the 'Encoder' module on the right."
        },
        "Pool training": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P19-1183-Figure2-1.png": {
        "Instance Generator": {
            "function": "to generate instances from the input video that are relevant to the input sentence for further processing by the Attentive Interactor.",
            "absolute_position": "in the center left of the figure",
            "relative_position": "between the \"Input Video\" and the \"Instances\" elements."
        },
        "Attention (Q)": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W14-0145-Figure1-1.png": {
        "HWN": {
            "function": "",
            "absolute_position": "second",
            "relative_position": "middle."
        },
        "What makes the second world war happen": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/R09-1062-Figure1-1.png": {
        "SUBJ1": {
            "function": "subject.",
            "absolute_position": "middle of the figure, on the lower left side",
            "relative_position": "directly to the right of the 'Jean' module and below the 'S1' module."
        },
        "TM": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.eacl-main.282-Figure2-1.png": {
        "Expression Representation": {
            "function": "to encode the input expressions into vector representations which capture the semantic meaning of the expressions.",
            "absolute_position": "in the left half, third block from the top within the \"Word Representation\" block.",
            "relative_position": "immediately to the right of the \"Word Representation\" within the same enclosing block."
        },
        "Selection Mechanism": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/P19-1507-Figure1-1.png": {
        "Ridge Regression": {
            "function": "to predict the brain response from deep neural network model representation features using model weights learned by Ridge Regression.",
            "absolute_position": "in the center, towards the bottom of the figure.",
            "relative_position": "between the 'Representation' stage and the 'MEG Recording' stage."
        },
        "Process Overview": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to predict the brain response from deep neural network model representation features using model weights learned by Ridge Regression."
        }
    },
    "/data_share/data/acl_parse/figure/C10-2113-Figure2-1.png": {
        "pass": {
            "function": "to represent an event or action in the context of the diagram, likely related to a football play.",
            "absolute_position": "",
            "relative_position": ""
        },
        "RPDR Raw Text": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N07-2055-Figure2-1.png": {
        "2. C2 creates nugget group (1st Round)": {
            "function": "to create a nugget group in the first round by participant C2.",
            "absolute_position": "Top right",
            "relative_position": "Second from the top."
        },
        "Food": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/X98-1022-Figure1-1.png": {
        "Negative Feature Vector": {
            "function": "to represent features that are not associated with the primary topic of interest, likely used to distinguish between relevant and non-relevant content or topics in a machine learning context.",
            "absolute_position": "in the bottom right quadrant of the figure",
            "relative_position": "to the right of the Positive Feature Vector module and below the Training Module."
        },
        "TRE Calculator": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/L16-1393-Figure1-1.png": {
        "FLAT Deposition Service (Doorkeeper)": {
            "function": "",
            "absolute_position": "on the bottom center of the figure.",
            "relative_position": "directly below the \"SIP\" module and to the left of the \"Workspace\" module, also connected to the \"Fedora Commons\" module towards the bottom left."
        },
        "Temporal [tao]": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2022.acl-long.119-Figure2-1.png": {
        "Fingerspelling Visual Encoder": {
            "function": "to encode the visual information of fingerspelling from video frames into a representation that can be used for further processing or classification.",
            "absolute_position": "top",
            "relative_position": "between the \"Positive samples P_z\" module and the \"Visual & Textual Embeddings\" on the right side of the figure."
        },
        "ST ENCODER": {
            "absolute_position": "",
            "relative_position": "",
            "function": "to encode fingerspelling representations from visual data for recognition or translation tasks."
        }
    },
    "/data_share/data/acl_parse/figure/2022.naacl-srw.11-Figure3-1.png": {
        "3.Sampling weighted on kernel density": {
            "function": "to select samples from the data based on their distribution as determined by the kernel density estimation.",
            "absolute_position": "bottom left",
            "relative_position": "after '2. Kernel density estimation' and before 'sampled sentences'."
        },
        "prev_context": {
            "absolute_position": "third in the workflow sequence",
            "relative_position": "after \"Kernel density estimation\" and before \"annotate.\"",
            "function": "sampling weighted on kernel density."
        }
    },
    "/data_share/data/acl_parse/figure/2020.emnlp-main.371-Figure2-1.png": {
        "Learned embedding (echar)": {
            "function": "to provide character-level embeddings for the input sequence.",
            "absolute_position": "at the bottom center of the figure",
            "relative_position": "just above the text that reads \"I + h a v e *** 3\"."
        },
        "Named entity detection and extraction of drug and conditions which occur together in a sentence": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/D19-6106-Figure2-1.png": {
        "CCA": {
            "function": "",
            "absolute_position": "middle right side of the figure",
            "relative_position": "between the second and third module from the left in the lower row of modules."
        },
        "Contiguity Loss": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W12-2904-Figure3-1.png": {
        "SPACE": {
            "function": "to insert a space character.",
            "absolute_position": "at the bottom center of the left keyboard labeled 'the 12-key phoneme keyboard' (a).",
            "relative_position": "in the third row from the top, second column from the left if counting only the marked keys, or the fourth column if counting all boundaries in the grid including the empty spaces on the left and right sides."
        },
        "Systeme de reconnaissance de termes": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/N15-1011-Figure4-1.png": {
        "region size s2": {
            "function": "to define the scope or area over which pooling is performed in a convolutional neural network layer to reduce dimensionality and extract key features.",
            "absolute_position": "third from the bottom",
            "relative_position": "middle layer among the convolution layers."
        },
        "Foreign Word List": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/R13-1093-Figure11-1.png": {
        ":sensecRelation label=synonymx": {
            "function": "to indicate a synonym relationship between senses or meanings of words.",
            "absolute_position": "the bottom center of the diagram.",
            "relative_position": "below the second '.LexicalEntry' block from the left."
        },
        "Logistic regression": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W11-2822-Figure1-1.png": {
        "Semantic role labeling": {
            "function": "to assign roles to entities within a sentence to understand who did what to whom.",
            "absolute_position": "second from the right",
            "relative_position": "between \"Named Entity Recognition\" and \"Selecting relevant sentences.\""
        },
        "Multi-Head Self-Attention": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.emnlp-main.705-Figure2-1.png": {
        "Caption: A bus is boarding passengers at a stop.": {
            "function": "to provide a descriptive caption of the image processed by the Captioning Model.",
            "absolute_position": "the top-right section of the figure",
            "relative_position": "to the right of the Captioning Model and above the Question Answering Model."
        },
        "Set of Chinese characters": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/W12-3609-Figure1-1.png": {
        "Speech Recognizer (Sphinx)": {
            "function": "to convert spoken words into text using models for understanding language and acoustic sounds.",
            "absolute_position": "in the center of the figure",
            "relative_position": "between the Language Model and Acoustic Model, and above the Transcription crowdsourcing web application."
        },
        "Parallel training data": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2010.jeptalnrecital-demonstration.12-Figure1-1.png": {
        "Medical Problem": {
            "function": "to represent an entity that can be diagnosed by medical tests, can have signs or symptoms, may be treated or prevented by therapeutic procedures, can be caused by drugs, and can complicate or cause other medical problems.",
            "absolute_position": "center",
            "relative_position": "in the middle of the figure."
        },
        "Ci,1 Ci,2 Ci,3": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.sigdial-1.29-Figure1-1.png": {
        "Player": {
            "function": "to play audio or video content for the user.",
            "absolute_position": "inside the \"User Interface\" container",
            "relative_position": "on the left side within its container, next to \"User Account\" and \"Recorder\"."
        },
        "structural transfer": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/Y18-1025-Figure1-1.png": {
        "Vectorization": {
            "function": "obtaining dense vector representations using Skip-Gram, CBOW, PV-DM and PV-DBOW algorithms.",
            "absolute_position": "center",
            "relative_position": "second (in a sequence of three modules from left to right)."
        },
        "Selector": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/I17-4005-Figure2-1.png": {
        "Dense": {
            "function": "to provide a fully connected layer that combines features linearly using learned weights.",
            "absolute_position": "top-center",
            "relative_position": "above the LSTM modules and below the \"Attention\" header within the diagram."
        },
        "Xk-1": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C18-1007-Figure1-1.png": {
        "Gradient Reversal Layer": {
            "function": "to reverse the gradient flow during backpropagation to help in domain adaptation by making the feature distributions over two domains similar.",
            "absolute_position": "on the right side of the figure, towards the bottom.",
            "relative_position": "after the 'Joint Feature Extractor (CNN)' and before the 'Language Classifier (MLP)'."
        },
        "Sentence Parsing. SRL,NER.": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C10-1130-Figure2-1.png": {
        "Someone": {
            "function": "subject noun.",
            "absolute_position": "second tree, second level, first node from the left.",
            "relative_position": "under the VP (Verb Phrase) node, leftmost child of the NP (Noun Phrase) node that is itself under the VP."
        },
        "SPACE": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/C18-1242-Figure2-1.png": {
        "wind": {
            "function": "",
            "absolute_position": "second from the top and in the center column.",
            "relative_position": "between 'onshore' and 'farm' and above the 'translations' module."
        },
        "unseen types": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2021.cinlp-1.7-Figure1-1.png": {
        "Confounder(s)": {
            "function": "to represent variables that may affect both the treatment and the outcome, potentially biasing the estimated effect of the treatment on the outcome if not properly controlled for.",
            "absolute_position": "in the center",
            "relative_position": "between \"Research Entities from Full Text,\" \"Author Properties,\" \"Co-Authorship Network Properties,\" \"Retire/Maintain/Adopt Causal,\" and \"Publish on Causal.\""
        },
        "Evaluation CodaLab": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/O08-5006-Figure4-1.png": {
        "Bi-lingual corpus": {
            "function": "",
            "absolute_position": "the bottom right corner of the figure",
            "relative_position": "below the \"Optimal Phoneme Set Acoustic Model\" and to the right of the \"Context Dependent Phoneme Acoustic Model\"."
        },
        "(0,2,3) (2,4, ) (3,4, )": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    },
    "/data_share/data/acl_parse/figure/2020.wnut-1.46-Figure2-1.png": {
        "W2": {
            "function": "",
            "absolute_position": "second in the sequence from the left.",
            "relative_position": "immediately after 'W1' and before 'W3'."
        },
        "Expand by adding next arc": {
            "absolute_position": "",
            "relative_position": "",
            "function": ""
        }
    }
}